{"paper": {"title": "Hallucinating brains with artificial brains", "authors": ["Peiye Zhuang", "Alexander G. Schwing", "Oluwasanmi Koyejo"], "authorids": ["py_zhuang@bupt.edu.cn", "aschwing@illinois.edu", "sanmi@illinois.edu"], "summary": "Two novel GANs are constructed to generate high-quality 3D fMRI brain images and synthetic brain images greatly help to improve downstream classification tasks.", "abstract": "Human brain function as measured by functional magnetic resonance imaging\n(fMRI), exhibits a rich diversity. In response, understanding the individual variability\nof brain function and its association with behavior has become one of the\nmajor concerns in modern cognitive neuroscience. Our work is motivated by the\nview that generative models provide a useful tool for understanding this variability.\nTo this end, this manuscript presents two novel generative models trained\non real neuroimaging data which synthesize task-dependent functional brain images.\nBrain images are high dimensional tensors which exhibit structured spatial\ncorrelations. Thus, both models are 3D conditional Generative Adversarial networks\n(GANs) which apply Convolutional Neural Networks (CNNs) to learn an\nabstraction of brain image representations. Our results show that the generated\nbrain images are diverse, yet task dependent. In addition to qualitative evaluation,\nwe utilize the generated synthetic brain volumes as additional training data to improve\ndownstream fMRI classifiers (also known as decoding, or brain reading).\nOur approach achieves significant improvements for a variety of datasets, classifi-\ncation tasks and evaluation scores. Our classification results provide a quantitative\nevaluation of the quality of the generated images, and also serve as an additional\ncontribution of this manuscript.", "keywords": ["3D fMRI data", "Deep Learning", "Generative Adversarial Network", "Classification"]}, "meta": {"decision": "Reject", "comment": "The submission proposes to use GANs to learn a generative model of fMRI scans that can then be used for downstream classification tasks.  Although there was some appreciation from the reviewers of the approach, there were several important remaining concerns:\n\n1) From Reviewer 1: \"Generating high resolution images with GANs even on faces for which there is almost infinite data is still a challenge. Here a few thousand data points are used. So it raises too concerns: First is it enough?\"\n\nand\n\n2) R1 and R2 both raised concerns about the significance of the improvements.  Looking through the tables, there are many reported differences that are reasonably small, and no error bars or significance are given.  This should be a requirement for an empirical paper about fMRI."}, "review": {"rJirqFBgz": {"type": "review", "replyto": "BJaU__eCZ", "review": "Quality\n\nThis is a very clear contribution which elegantly demonstrates the use of extensions of GAN variants in the context of neuroimaging.\n\nClarity\n\nThe paper is well-written. Methods and results are clearly described. The authors state significant improvements in classification using generated data. These claims should be substantiated with significance tests comparing classification on standard versus augmented datasets.\n\nOriginality\n\nThis is one of the first uses of GANs in the context of neuroimaging. \n\nSignificance \n\nThe approach outlined in this paper may spawn a new research direction.\n\nPros\n\nWell-written and original contribution demonstrating the use of GANs in the context of neuroimaging.\n\nCons\n\nThe focus on neuroimaging might be less relevant to the broader AI community.", "title": "GANS on neuroimaging data", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "B1LfYs_gf": {"type": "review", "replyto": "BJaU__eCZ", "review": "This paper proposes to use 3D conditional GAN models to generate\nfMRI scans. Using the generated images, paper reports improvement\nin classification accuracy on various tasks.\n\nOne claim of the paper is that a generative model of fMRI\ndata can help to caracterize and understand variability of scans\nacross subjects.\n\nArticle is based on recent works such as Wasserstein GANs and AC-GANs\nby (Odena et al., 2016).\n\nDespite the rich literature of this recent topic the related work\nsection is rather convincing.\n\nModel presented extends IW-GAN by using 3D convolution and also\nby supervising the generator using sample labels.\n\nMajor:\n\n- The size of the generated images is up to 26x31x22 which is limited\n(about half the size of the actual resolution of fMRI data). As a\nconsequence results on decoding learning task using low resolution\nimages can end up worse than with the actual data (as pointed out).\nWhat it means is that the actual impact of the work is probably limited.\n\n- Generating high resolution images with GANs even on faces for which\nthere is almost infinite data is still a challenge. Here a few thousand\ndata points are used. So it raises too concerns: First is it enough?\nUsing so-called learning curves is a good way to answer this. Second\nis what are the contributions to the state-of-the-art of the 2\nmethods introduced? Said differently, as there\nis no classification results using images produced by an another\nGAN architecture it is hard to say that the extra complexity\nproposed here (which is a bit contribution of the work) is actually\nnecessary.\n\nMinor:\n\n- Fonts in figure 4 are too small.\n", "title": "Interesting idea with some potential contribution on GAN architectures to generate fMRI scans", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rJw8PuhxM": {"type": "review", "replyto": "BJaU__eCZ", "review": "The work is motivated by a real challenge of neuroimaging analysis: how to increase the amount of data to support the learning of brain decoding.\nThe contribution seems to mix two objectives: on one hand to prove that it is possible to do data augmentation for fMRI brain decoding, on the other hand to design (or better to extend) a new model (to be more precise two models).\nConcerning the first objective the empirical results do not provide meaningful support that the generative model is really effective. The improvement is really tiny and a statistical test (not included in the analysis) probably wouldn't pass a significant threshold.  This analysis is missing a straw man. It is not clear whether the difference in the evaluation measures is related to the greater number of examples or by the specific generative model.\nConcerning the contribution of the model, one novelty is the conditional formulation of the discriminator. The design of the empirical evaluation doesn't address the analysis of the impact of this new formulation. It is not clear whether the supposed improvement is related to the conditional formulation. \nFigure 3 and Figure 5 illustrate the brain maps generated for Collection 1952 with ICW-GAN and for collection 503 with ACD-GAN. It is not clear how the authors operated the choices of these figures. From the perspective of neuroscience a reader,  would expect to look at the brain maps for the same collection with different methods. The pairwise brain maps would support the interpretation of the generated data. It is worthwhile to remember that the location of brain activations is crucial to detect whether the brain decoding (classification) relies on artifacts or confounds.\n\nMinor comments\n- typos: \"a first application or this\" => \"a first application of this\" (p.2)\n- \"qualitative quality\" (p.2)", "title": "Relevant hard problem and poor evidence for proposed solution", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "SJx6w-67M": {"type": "rebuttal", "replyto": "B1LfYs_gf", "comment": "Thank you for the clear review.\n\n- w.r.t. size of generated brain maps: Decreasing the resolution of the imaging data is common practice in the neuroimaging analysis, e.g., it is built into the Nilearn python package. Interestingly and in contrast to the reviewer comment, we observe benefits by including synthetic data with higher resolution.\n\n- w.r.t. effectiveness of generative model(s): To highlight the effectiveness of the proposed models, we have added additional results for two generative models to the revised manuscript, the AC-GAN (Tab. 4) and Gaussian Mixture Model (Tab. 6). Our results show that both AC-GAN and GMM achieve much worse results. To further evaluate the generative model, we experimented with using only generated data to train the classifiers (Fig. 8). Our results in the revised manuscript suggest that using several hundred artificial images per class is comparable to using real images.\n\n- w.r.t. stability of GAN: To demonstrate the stability we added training loss curves to the revised manuscript (Fig. 7). We did not observe any issues which we attribute to the stability of Wasserstein variants. \n", "title": "Rebuttal"}, "S1cT_-6XG": {"type": "rebuttal", "replyto": "rJirqFBgz", "comment": "Thank you for your strong review. \n\n- w.r.t. relevance to the AI community: We think neuroscience is an integral part of the larger AI community, benefiting both sides when seeking inspiration. Further, we expect that many of the techniques we propose are directly applicable to more common computer vision tasks.", "title": "Rebuttal"}, "S1FBv-6QG": {"type": "rebuttal", "replyto": "rJw8PuhxM", "comment": "Thank you for your valuable comments on our paper. \n\n- w.r.t. goals of the manuscript: From a neuroscience perspective, the paper develops a mechanism addressing two concerns: (i) how to generate synthetic samples which help address the shortage of data that is common in neuroimaging, and can be used to analyze inter-individual variability, among other applications; (ii) how to evaluate artificially generated neuroimaging data. \n\n- w.r.t. effectiveness of generative models: To highlight the effectiveness of the proposed models, we have added additional results for two generative models to the revised manuscript, the AC-GAN (Tab. 4) and Gaussian Mixture Model (Tab. 6). Our results show that both AC-GAN and GMM achieve much worse results. To further evaluate the generative model, we experimented with using only generated data to train the classifiers (Fig.8). Our results in the revised manuscript suggest that using several hundred fake images per class is comparable to using real images.\n\n- w.r.t. improvements to classification performance: We point the reviewer to Tab. 4 for a comparison of different GAN architectures. Also, we mention that for the results reported in Tab. 1-3, both SVM and deep net classifiers are compared with and without artificially generated data. We think this clearly demonstrates the benefits of adding data obtained from GANs. The high performance of the baselines, resulting from careful tuning, are easily on par with typically reported numbers in the literature. Moreover, we point out that the reported improvements are consistent across a variety of metrics. This experimental evaluation suggests that the reported improvements aren\u2019t small and are hard to achieve. In Tab. 5 of the revised manuscript, we provide the variance of the cross-validated performance. The small variances suggest the significance of the performance differences. \n\n- w.r.t. illustrated brain maps and brain decoding: We refer the reviewer to Fig. 5 in the manuscript and Fig. 11-13 in the supplementary material for additional results. We have clarified details as requested, for instance, Fig. 5 and Fig. 13 show the synthetic images with label \u20187\u2019 in collection 503 by the ACD-GAN and ICW-GAN respectively.\n\n", "title": "Rebuttal"}, "By-5yr6mf": {"type": "rebuttal", "replyto": "BJaU__eCZ", "comment": "We thank all reviewers for their constructive feedback and address their comments in the following. We  will release all code soon. \n", "title": "To all reviewers: Thank you for the valuable comments!"}}}