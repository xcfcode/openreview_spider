{"paper": {"title": "Spherical CNNs", "authors": ["Taco S. Cohen", "Mario Geiger", "Jonas K\u00f6hler", "Max Welling"], "authorids": ["taco.cohen@gmail.com", "geiger.mario@gmail.com", "jonas.koehler.ks@gmail.com", "m.welling@uva.nl"], "summary": "We introduce Spherical CNNs, a convolutional network for spherical signals, and apply it to 3D model recognition and molecular energy regression.", "abstract": "Convolutional Neural Networks (CNNs) have become the method of choice for learning problems involving 2D planar images. However, a number of problems of recent interest have created a demand for models that can analyze spherical images. Examples include omnidirectional vision for drones, robots, and autonomous cars, molecular regression problems, and global weather and climate modelling. A naive application of convolutional networks to a planar projection of the spherical signal is destined to fail, because the space-varying distortions introduced by such a projection will make translational weight sharing ineffective.\n\nIn this paper we introduce the building blocks for constructing spherical CNNs. We propose a definition for the spherical cross-correlation that is both expressive and rotation-equivariant. The spherical correlation satisfies a generalized Fourier theorem, which allows us to compute it efficiently using a generalized (non-commutative) Fast Fourier Transform (FFT) algorithm. We demonstrate the computational efficiency, numerical accuracy, and effectiveness of spherical CNNs applied to 3D model recognition and atomization energy regression.", "keywords": ["deep learning", "equivariance", "convolution", "group convolution", "3D", "vision", "omnidirectional", "shape recognition", "molecular energy regression"]}, "meta": {"decision": "Accept (Oral)", "comment": "This work introduces a trainable signal representation for spherical signals (functions defined in the sphere) which are rotationally equivariant by design, by extending CNNs to the corresponding group SO(3). The method is implemented efficiently using fast Fourier transforms on the sphere and illustrated with compelling tasks such as 3d shape recognition and molecular energy prediction.\n\nReviewers agreed this is a solid, well-written paper, which demonstrates the usefulness of group invariance/equivariance beyond the standard Euclidean translation group in real-world scenarios. It will be a great addition to the conference. "}, "review": {"rySumKdhz": {"type": "rebuttal", "replyto": "Sy5OgaB2G", "comment": "This is a good point. The network is equivariant if all the layers are equivariant, so that is what we must show. It was shown in the paper \"Group Equivariant Networks\" (section 6.2) that arbitrary pointwise nonlinearities are equivariant to the action of the group. This is true for the so-called regular representations, which act by permuting the neurons, whereas other (steerable / induced) representations may require special equivariant nonlinearities.\n\nThe regular representation is what we denote by L_R in this paper:\nL_R f = f R^{-1},\nwhere juxtaposition means composition. Applying a pointwise nonlinearity s to a feature map f can be written mathematically as:\nC_s f = s f\n\nSince L_R acts by composing on the right and C_s acts by composing from the left, we have:\nL_R C_s f = L_R (s f) = (s f) R^{-1} = s (f R^{-1}) = C_s L_R f.\nThat is, the regular representation L_R and the nonlinear operator C_s commute.\n\nThis is the continuous theory. In practice, the numerical implementation results in a tiny loss of equivariance per linear layer (Fig. 3, top right). When ReLUs are used between each layer, we see in Fig 3. bottom right that the error is substantially larger, but does not increase meaningfully with depth. The reason for this is as follows: in order to measure the equivariance error Delta, we have to rotate the feature maps. Rotation of feature maps is exact (up to floating point error) only for band-limited signals, but the ReLU will introduce many high-frequency signals that cannot be exactly rotated with sub-pixel precision. So as soon as we use one layer of ReLU's, the error jumps. However, this appears to be an artefact of the measurement procedure (the numerical rotation step, to be precise) and does not seem to get worse with depth. This is mentioned in the last section before section 5.2: \"This indicates that the error is not due to the network layers, but due to the feature map rotation, which is exact only for bandlimited functions\".\n\nBatch normalization is exactly equivariant, as long as one uses one mean and std per feature map on SO(3). This is because both the mean and std are \"scalars\" in the geometrical sense that they are invariant under rotation. So we can multiply by them without affecting the equivariance.\n\nBeyond the equivariance error (Delta) experiments, the generalization results for spherical MNIST provide further support for the numerical accuracy of our implementation. If the numerical problems were severe, we would not expect to see such good generalization from a non-rotated training set to a rotated test set.\n\nIn my ICLR talk, I will show a figure showing the feature maps for a rotated and non-rotated input. This allows you to easily see that the network is properly equivariant.", "title": "Good point"}, "Skrq4BAHM": {"type": "rebuttal", "replyto": "r1VD9T_SM", "comment": "The paper [1] is a preliminary 4-page paper reporting on the same project, published in the ICML workshop on principled approaches to deep learning. The existence of this workshop paper was mentioned in our original submission under footnote 0. Please note that the ICLR dual submission policy explicitly allows publishing articles that have previously appeared in workshops (https://iclr.cc/Conferences/2018/CallForPapers).\n\n[1] T.S. Cohen, M. Geiger, J. Koehler, M. Welling, Convolutional Networks for Spherical Signals. In Principled Approaches to Deep Learning Workshop ICML 2017.", "title": "Workshop paper"}, "SJ3LYkFez": {"type": "review", "replyto": "Hkbd5xZRb", "review": "Summary:\n\nThe paper proposes a framework for constructing spherical convolutional networks (ConvNets) based on a novel synthesis of several existing concepts.  The goal is to detect patterns in spherical signals irrespective of how they are rotated on the sphere.  The key is to make the convolutional architecture rotation equivariant.\n\nPros:\n\n+ novel/original proposal justified both theoretically and empirically\n+ well written, easy to follow\n+ limited evaluation on a classification and regression task is suggestive of the proposed approach's potential\n+ efficient implementation\n\nCons:\n\n- related work, in particular the first paragraph, should compare and contrast with the closest extant work rather than merely list them\n- evaluation is limited; granted this is the nature of the target domain\n\nPresentation:\n\nWhile the paper is generally written well, the paper appears to conflate the definition of the convolutional and correlation operators?  This point should be clarified in a revised manuscript.  \n\nIn Section 5 (Experiments), there are several references to S^2CNN.  This naming of the proposed approach should be made clear earlier in the manuscript.  As an aside, this appears a little confusing since convolution is performed first on S^2 and then SO(3). \n\nEvaluation:\n\nWhat are the timings of the forward/backward pass and space considerations for the Spherical ConvNets presented in the evaluation section?  Please provide specific numbers for the various tasks presented.\n\nHow many layers (parameters) are used in the baselines in Table 2?  If indeed there are much less parameters used in the proposed approach, this would strengthen the argument for the approach.  On the other hand, was there an attempt to add additional layers to the proposed approach for the shape recognition experiment in Sec. 5.3 to improve performance?\n\nMinor Points:\n\n- some references are missing their source, e.g., Maslen 1998 and Kostolec, Rockmore, 2007, and Ravanbakhsh, et al. 2016.\n\n- some sources for the references are presented inconsistency, e.g., Cohen and Welling, 2017 and Dieleman, et al. 2017\n\n- some references include the first name of the authors, others use the initial \n\n- in references to et al. or not, appears inconsistent\n\n- Eqns 4, 5, 6, and 8 require punctuation\n\n- Section 4 line 2, period missing before \"Since the FFT\"\n\n- \"coulomb matrix\" --> \"Coulomb matrix\"\n\n- Figure 5, caption: \"The red dot correcpond to\" --> \"The red dot corresponds to\"\n\nFinal remarks:\n\nBased on the novelty of the approach, and the sufficient evaluation, I recommend the paper be accepted.\n\n", "title": "Spherical CNNs", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "B1gQIy9gM": {"type": "review", "replyto": "Hkbd5xZRb", "review": "The focus of the paper is how to extend convolutional neural networks to have built-in spherical invariance.  Such a requirement naturally emerges when working with omnidirectional vision (autonomous cars, drones, ...).\n\nTo get invariance on the sphere (S^2), the idea is to consider the group of rotations on S^2 [SO(3)] and spherical convolution [Eq. (4)]. To be able to compute this convolution efficiently, a generalized Fourier theorem is useful. In order to achieve this goal, the authors adapt tools from non-Abelian [SO(3)] harmonic analysis.  The validity of the idea is illustrated on 3D shape recognition and atomization energy prediction. \n\nThe paper is nicely organized and clearly written; it fits to the focus of ICLR and can be applicable on many other domains as well.\n", "title": "Non-Abelian Harmonic Analysis to Get Spherical Invariance in CNNs", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "Bkv4qd3bG": {"type": "review", "replyto": "Hkbd5xZRb", "review": "First off, this paper was a delight to read.  The authors develop an (actually) novel scheme for representing spherical data from the ground up, and test it on three wildly different empirical tasks: Spherical MNIST, 3D-object recognition, and atomization energies from molecular geometries.  They achieve near state-of-the-art performance against other special-purpose networks that aren't nearly as general as their new framework.  The paper was also exceptionally clear and well written.\n\nThe only con (which is more a suggestion than anything)--it would be nice if the authors compared the training time/# of parameters of their model versus the closest competitors for the latter two empirical examples.  This can sometimes be an apples-to-oranges comparison, but it's nice to fully contextualize the comparative advantage of this new scheme over others.  That is, does it perform as well and train just as fast?  Does it need fewer parameters?  etc.\n\nI strongly endorse acceptance.", "title": "Added Late Reviewer", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "r1CVE6O7f": {"type": "rebuttal", "replyto": "Bkv4qd3bG", "comment": "Thank you for the kind words, we're glad you like our work! \n\nOur models for SHREC17 and QM7 both use only about 1.4M parameters. On a machine with 1 Titan X GPU, training the SHREC17 model takes about 50 hours, while the QM7 model takes only about 3 hours. Memory usage is 8GB for SHREC (batchsize 16) and 7GB for QM7 (batchsize 20).\n\nWe have studied the SHREC17 paper [1], but unfortunately it does not state the number of parameters or training time for the various methods. It does seem likely that each of the competition participants did their own cross validation, and arrived at an appropriate model complexity for their method. It is thus unlikely that the strong performance of our model relative to others can be explained by its size (especially since 1.4M parameters is not considered very large anymore).\n\nFor QM7, it looks like Montavon et al. used about 760k parameters (we have deduced this from the description of their network architecture). Since the model is a simple multi-layer perceptron applied to a hand-designed feature representation, we expect that it is substantially faster to train than our model (though indeed comparing a spherical CNN to an engineered features+MLP approach is a bit of an apples-to-oranges comparison). Raj et al. use a non-parametric method, so there is no parameter count or training time to compare to.\n\n[1] M. Savva et al. SHREC\u201917 Track Large-Scale 3D Shape Retrieval from ShapeNet Core55, Eurographics Workshop on 3D Object Retreival (2017).", "title": "Spherical CNNs"}, "Sy9FmTuQM": {"type": "rebuttal", "replyto": "SJ3LYkFez", "comment": "Thank you for the detailed and balanced review.\n\nRE Related work: we have expanded the related work section a little bit in order to contrast with previous work. (Unfortunately there is no space for a very long discussion)\n\nRE Convolution vs correlation: thank you for pointing this out. Our reasoning had been that:\n1) Everybody in deep learning uses the word \"convolution\" to mean \"cross-correlation\".\n2) In the non-commutative case, there are several different but essentially equivalent convolution-like integrals that one can define, with no really good reason to prefer one over the other.\n\nBut we did not explain this properly. We think a reasonable approach is to call something group convolution if, for the translation group it specializes to the standard convolution, and similarly for group correlations. This seems to be what several others before us have done as well, so we will follow this convention. Specifically, we will define the (group) cross-correlation as:\n  psi \\star f(g) = int psi(g^{-1} h) f(h) dh.\n\nRE The S^2CNN name: we have now defined this term in the introduction, but not changed it, because the paper is called \"Spherical CNN\" and S^2-CNN is just a shorthand for that name.\n\nRE Timings: we have added timings, memory usage numbers, and number of parameters to the paper. It is not always possible to compare the number of parameters to related work because those numbers are not always available. However, we can reasonably assume that the competing methods did their own cross-validation to arrive at an optimal model complexity for their architecture. (Also, in deep networks, the absolute number of parameters can often vary widely between architectures that have a similar generalization performance, making this a rather poor measure of model complexity.)\n\nRE References and other minor points: we have fixed all of these issues. Thanks for pointing them out.", "title": "Spherical CNNs"}, "ryi-Q6_Xf": {"type": "rebuttal", "replyto": "B1gQIy9gM", "comment": "Thank you very much for taking the time to review our work.", "title": "Thanks"}, "HkZy7TdXM": {"type": "rebuttal", "replyto": "S1rz4yvGf", "comment": "Thank you for these references, they are indeed very relevant and interesting*. We will add them and change the text.\n\nWe agree that the cross-correlation is the right term, and have fixed it in the paper. We have added further discussion of this issue in reply to reviewer 2, who raised a similar concern.\n\n* We do not have access to Rafaely's book through our university library, so we cannot comment on it.\n", "title": "Thanks"}}}