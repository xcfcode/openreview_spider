{"paper": {"title": "Quantifying uncertainty with GAN-based priors", "authors": ["Dhruv V. Patel", "Assad A. Oberai"], "authorids": ["dhruvvpa@usc.edu", "aoberai@usc.edu"], "summary": "Quantifying uncertainty in inference via GAN priors", "abstract": "Bayesian inference is used extensively to quantify the uncertainty in an inferred field given the measurement of a related field when the two are linked by a mathematical model. Despite its many applications, Bayesian inference faces challenges when inferring fields that have discrete representations of large dimension, and/or have prior distributions that are difficult to characterize mathematically. In this work we demonstrate how the approximate distribution learned by a generative adversarial network (GAN) may be used as a prior in a Bayesian update to address both these challenges. We demonstrate the efficacy of this approach by inferring and quantifying uncertainty in inference problems arising in computer vision and  physics-based applications. In both instances we highlight the role of computing uncertainty in providing a measure of confidence in the solution, and in designing successive measurements to improve this confidence. ", "keywords": ["Bayesian inference", "Uncertainty quantification", "Generative adversarial networks"]}, "meta": {"decision": "Reject", "comment": "This paper suggests a Bayesian approach to make inference about latent variables for image inference tasks. While the idea in the paper seems elegant and simple, reviewers pointed out a few concerns, including lack of comparisons, missing references, and requested for more extensive validations. While a few comments might have been misunderstandings (eg lack of quantification - seems to be resolved by author\u2019s comments), other comments are not (eg equation (8) needs further justification even if the final results don\u2019t use it). We encourage authors to carefully review comments and edit the manuscript (perhaps some appendix items should be in the main to reduce confusion) for resubmitting to future conferences. "}, "review": {"rklmUH52sH": {"type": "rebuttal", "replyto": "HyeAPeBFwS", "comment": "Based on all the reviewer's response we have recognized that we were remiss in not clarifying our main contributions in the manuscript. We have done so in the revised version and repeat them below. \n\nThe main contribution of this paper can be summarized as follows:\n\u2022\tA novel method for performing Bayesian inference involving complex priors and high dimensional posterior. In the proposed method we utilize the distribution learned by a GAN as a surrogate for the prior distribution and reformulate the inference problem in the low-dimensional latent space of the GAN. \n\n\u2022\tA theoretical analysis of the weak convergence of the posterior density learned by the proposed method to the true posterior density.\n\n\u2022\t Novel unsupervised image denoising and inpainting algorithms with quantitative measures of uncertainty through pixel-wise variance. \n\n\u2022\tApplication of the proposed method to physics-based inference problems.\n\n\u2022\tDemonstration of the utility of uncertainty quantification to facilitate active learning. \n", "title": "tl;dr"}, "BkexChE3jS": {"type": "rebuttal", "replyto": "rJxFqsV3jr", "comment": "\"It is not clear how the HMC parameters are fixed.\"\n\n** We have included concise description of this in section 3 of the revised version. **\n-----\n\"The experiments do not have error bars (Figure 4.) This questions the significance of the results.\"\n\n** This was an oversight on our part. We have included error bars in the revised version. **\n-----\n\"My overall impression is that there is little novelty in the proposed approach. Namely, using a GAN to learn the prior distribution, and then very well known techniques to infer the original input image.\"\n\nWe agree that the approach is simple; on the other hand, it is quite novel. We are not aware of any other work that performs uncertainty quantification using this combination of techniques in an unsupervised fashion. In contrast to other approaches [3, 4, 5], which use pairs of desired and measured images (x,y) to train the network, our approach only requires desired images (x). Furthermore, our work uniquely demonstrates the use of quantified uncertainty in active learning setup - finding the optimal location of sensors (successive measurement location) in an unsupervised fashion, which again is not reported before and has many potential applications.\n**We have made this clear in a new subsection titled \"Our contributions\"**\n-----\n\"I have missed some references to related work on inverse problems. An example is:\nhttps://arxiv.org/pdf/1712.03353.pdf\"\n\n** This is an interesting, related work. We have included a reference to it in the revised version. **\n-----\n\"Is the original figure contained in the training set used to infer the GAN. If so that can lead to biased results.\"\n\nNo, the original figures were not used in training the GAN in all examples. We studiously avoided this bias. \n** We have mentioned in Section 3 of the revised version.  **\n-----\nI have missed a simple baseline in which one simply finds the training image that is closest to the corrupted observed or partially observed image.\n\n** We have included this result (figure 10) in Appendix C. **\n---\n\n[3]. A. Kendall and Y. Gal, \u201cWhat Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?\u201d, NIPS (2017).\n [4]. Kohl, S.A., Romera-Paredes, B., Meyer, C., Fauw, J.D., Ledsam, J.R., Maier-Hein, K.H., Eslami, S.M., Rezende, D.J., & Ronneberger, O. \u201cA Probabilistic U-Net for Segmentation of Ambiguous Images\u201d, NeurIPS (2018).\n[5]. Hu, S., Worrall, D., Knegt, S.J., Veeling, B., Huisman, H.J., & Welling, M., \u201cSupervised Uncertainty Quantification for Segmentation with Multiple Annotations\u201d. MICCAI (2019).", "title": "Final response to reviewer 1 -- Part (2/2)"}, "rJxFqsV3jr": {"type": "rebuttal", "replyto": "BygwEyIPKB", "comment": "Thank you for your valuable feedback! After carefully reviewing it, we have modified manuscript as discussed below (description of changes is enclosed within ** ... **). \n\n----\n\"Eq. (8) is expected to give very bad results. The reason is that it is very unlikely to sample from the prior configurations for z that are compatible with y.\"\n\nWe agree that it is in general a bad idea to use this equation, especially when the likelihood is very informative. However, we have found that for likelihoods that are not very informative this method is still useful. Regardless, we would like to point out that we do not use this equation for the results shown in the manuscript, but  rather use MCMC (eq. (9)) for all the results. \n** We have included this discussion in the revised manuscript in subsection 2.1. **\n-----\n\n\"The paper does not address learning any model parameters. e.g. the amount of noise.\"\n\nYou are right, we do not learn parameters associated with the noise in this work. We do however learn the parameters associated with the forward model by mapping them back to the latent space of the GAN. This is most clear in the context of the physics-based model (Section 3.2), where we parameterize forward model using pixel-wise values of the initial temperature, and then learn these parameters using the proposed method. \n\nWe note that the proposed approach can easily be extended to regime where likelihood is also unknown by incorporating likelihood-free inference methods like ABC or meta-learning approaches. \n** We have included this discussion in the Conclusion section of the revised version **. \n-----\n\"A more principled approach would be to estimate the prior parameters using maximum likelihood estimation. That has already been done in the case of the variational autoencoder.\nThe variational autoencoder is an already known method that can be used to solve the problem formulated by the authors. It also automatically proposes an inference network that can be used for recognition. If the likelihood is Gaussian and p(x|z) is also Gaussian, one can directly marginalize x and work with p(y|z) and p(z). The authors should at leas discuss the potential use of this method alongside with the BIGAN model which also provides a recognition model.\"\n\nWe agree that we were lacking a proof that demonstrated the convergence of the proposed method for computing point estimates of the posterior. \n** We have now derived this proof and  included it Appendix A** \nIn a nutshell, this proof establishes that with increasing the expressivity of the generator and the discriminator (increasing number weights) the posterior density of the proposed method weakly converges to the true posterior density. \n\nWe agree that using a variational autoencoder (VAE) in lieu of a GAN is an interesting extension of the proposed approach and that this can be accomplished in different ways.  However, we would like to point out that for image recovery tasks GANs have consistently demonstrated better performance than VAEs, as the latter tend to smear out images due to their maximum likelihood loss [1].\n\nWhile the idea of using corrupted images to train the VAE and inferring the latent variable, which would be the  - un-corrupted image is very interesting and using VAE with max. likelihood loss is an intriguing option, there are some major drawbacks of using it in the proposed Bayesian inference setting. \n\u2022 It is well-known that image samples produced by VAEs are quite blurry and of poorer quality than GAN and fail to match the true data distribution. It is shown in earlier studies that they fail to match marginal distribution not only in visible space but also in latent space [2]. Since, the focus of our paper is to use these distributions as priors, we believe that it is better to select a model for these distributions and hence GAN is our preferred choice. \n\u2022 Furthermore, VAEs are explicit density model and we have to select a model family (like Gaussian) for the latent variables. Therefore, in a setting where we treat un-corrupted images as latent variables (as suggested by the reviewer), and use max. likelihood as our loss function, we are forcing the latent variables to be close to that chosen family of distributions. This, might fail to capture complex inferred joint probability distribution seen in the examples considered in this manuscript, which is far from Gaussian (or any other simple distribution). It is also against the spirit of this work, where we want to make as few assumption as possible for our prior and use data to guide its final form.\n\n[1] R. A. Yeh, C. Chen, T. Yian Lim, A. G. Schwing, M. Hasegawa-Johnson, and M. N. Do, \u201cSemantic image inpainting with deep generative models,\u201d in Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, 2017, vol. 2017\u2013January, pp. 6882\u20136890.\n[2]. Rosca, M., Lakshminarayanan, B., & Mohamed, S. (2018). Distribution Matching in Variational Inference. ArXiv, abs/1802.06847.\n", "title": "Final response to reviewer 1 -- Part (1/2)"}, "r1xXycN3jB": {"type": "rebuttal", "replyto": "rJghfrNnKS", "comment": "Thank you for your valuable feedback! After carefully reviewing it, we have modified manuscript as discussed below (description of changes is enclosed within ** ... **). \n\n\"Though the Bayesian inference using GAN is a natural idea, learning algorithms proposed in this paper are simple and are not intensively developed. In numerical experiments, there is no comparison with major competitors besides random sampling in the active learning setup. Hence, the effectiveness and advantage of the proposed methods are not clear.\"\n\nWe have addressed this by responding to the specific questions below. \n\n\"- In active learning, the proposed method should be compared with other methods such as Bayesian DNN using dropout, etc. \"\n\nWe are not aware of any other methods for computing uncertainty in recovered images that have been used to drive an active learning task in image inpainting. While methods based on dropout (\\cite{Kendall2017a, Kendall2019}) or variational inference (\\cite{Kohl2018a}) could be extended to accomplish this, this has not been done thus far.\n**We have added this comment in Section 3.1**\n\nAnother big difference between the methods mentioned above and our approach is that while they require image pairs (true and corrupted images) for training, our approach only requires uncorrupted images. Thus while our algorithm relies on unsupervised learning, the other algorithms fall under the category of supervised learning. \n**We have also clarified this within the \"Our Contributions\" Section**\n\n\n\"- How does the estimation accuracy of GAN relate to the estimation accuracy of the proposed method? Showing a quantitative description would be nice.\"\n\nWe thank the reviewer for raising this important question.\n**We have addressed it thoroughly in Appendix A. We have provided a proof that demonstrates the weak convergence of the posterior density calculated using our method to the true posterior density as the number of weights in the discriminator and generator components of the GAN is increased.**\n", "title": "Final response to reviewer 2"}, "HJgn1YNnsr": {"type": "rebuttal", "replyto": "SJlld01kcS", "comment": "Thank you for your valuable and constructive feedback! After carefully reviewing it, we have modified the manuscript as discussed below (description of changes is enclosed within ** ... **). \n\n\"A big issue of this paper is the deviation of purpose and method. As the paper claims to quantify the uncertainty, the paper is supposed to give specific quantitative metric or values to probe the uncertainty. However, the paper demonstrates to us only the ability, not exactly 'quantification'. I\u2019d like to see a specific metric of uncertainty that could only be calculated through the proposed method.\" \n\nYou are right, the main purpose of the method is to quantify uncertainty in the task of  image inference. In fact, to our knowledge the method we describe is the only unsupervised learning method for quantifying uncertainty in a deep-learning based image-recovery task. We treat the inference as a stochastic problem, and develop an expression for the probability density function of the inferred image (i.e. joint pdf for each pixel of the inferred image). Once this is done, we sample from this distribution and compute any appropriate point estimate that can quantify the uncertainty in the inference. In our work, we have chosen the \"pixel-wise\" variance as this metric. Note that this metric is a field and not a scalar quantity and is plotted as an image. We have computed this metric for every example in the manuscript (see last row of figure 2, 3, 5 etc). \n** However, we have been remiss in not highlighting, or bringing the reader\u2019s attention to it. In the revised version of the paper we have done this by highlighting this field in the images and its description in the text. **\n\nSome more things to note:\n1. In one example (Figure 4) we compute a scalar metric (that is the average variance/per pixel over the entire image) for the  inferred images, and show that this measure increases with increasing noise in the input, as it should. \n** In the revised version, we have drawn the reader's attention to this example. **\n\n2. We note that our method of inferring the desired image from the measured image is an unsupervised method; in that for training we only need a set of desired images to construct the prior. We are not aware of any other unsupervised learning approach for solving these types of problems with quantified uncertainty. In that regards, the calculation of pixel-wise variance (our metric of uncertainty) in an unsupervised setting is possible only using our approach. \n** We have clarified this unique aspect in the revised version of the manuscript by listing it under a new subsection titled \"Our Contribution\" **  \n\n3. We note that there has been recent work on computing the uncertainty in an inferred image within a supervised learning framework where pairs of measured and desired images are used for training the network. In these articles the authors have used methods like Bayesian dropout to compute uncertainty in the inferred images [1]. Similar to what we have done, these authors have also plotted the point-wise variance as a quantitative metric of uncertainty. \n** We have referred to these works in the \"Related Work\" subsection of the revised version of the manuscript. **\n\n4. We note that we have gone beyond just computing the metric of uncertainty (point-wise variance) and also described how it might be useful in making the subsequent measurement in the context of an active learning approach, which to the best of our knowledge has not been done previously in Bayesian deep learning applied to image inference. \n** We have clarified this unique aspect in the revised version of the manuscript by listing it under a new subsection titled \"Our Contribution\" ** \n\n\"There are some grammar issues in the paper. For example. '\u2026we the MAP\u2026' in the 7th page.\"\n\n** We have done a through scrub of manuscript in order to catch these.  **\n\n\n[1]. A. Kendall and Y. Gal, \u201cWhat Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?\u201d, NIPS (2017).", "title": "Final response to reviewer 3"}, "SyxQvoKmjS": {"type": "rebuttal", "replyto": "BygwEyIPKB", "comment": "\"It is not clear how the HMC parameters are fixed.\"\n\n** We will include a concise description of this in the revised version. **\n-----\n\"The experiments do not have error bars (Figure 4.) This questions the significance of the results.\"\n\n** This was an oversight on our part. We will include error bars in the revised version. **\n-----\n\"My overall impression is that there is little novelty in the proposed approach. Namely, using a GAN to learn the prior distribution, and then very well known techniques to infer the original input image.\"\n\nWe agree that the approach is simple; on the other hand, it is quite novel. We are not aware of any other work that performs uncertainty quantification using this combination of techniques in an unsupervised fashion. In contrast to other approaches [2, 3, 4], which use pairs of desired and measured images (x,y) to train the network, our approach only requires desired images (x). Furthermore, our work uniquely demonstrates the use of quantified uncertainty in active learning setup - finding the optimal location of sensors (successive measurement location) in an unsupervised fashion, which again is not reported before and has many potential applications.\n-----\n\"I have missed some references to related work on inverse problems. An example is:\nhttps://arxiv.org/pdf/1712.03353.pdf\"\n\n** This is an interesting, related work. We will include it in the revised version, along with a description of how it relates to our approach. **\n-----\n\"Is the original figure contained in the training set used to infer the GAN. If so that can lead to biased results.\"\n\nNo, the original figures were not used in training the GAN in all examples. We studiously avoided this bias. ** We will mention this in the revised version.  **\n-----\nI have missed a simple baseline in which one simply finds the training image that is closest to the corrupted observed or partially observed image.\n\n** We do not have this baseline but will include it in the revised version. **\n---\n\n[2]. A. Kendall and Y. Gal, \u201cWhat Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?\u201d, NIPS (2017).\n [3]. Kohl, S.A., Romera-Paredes, B., Meyer, C., Fauw, J.D., Ledsam, J.R., Maier-Hein, K.H., Eslami, S.M., Rezende, D.J., & Ronneberger, O. \u201cA Probabilistic U-Net for Segmentation of Ambiguous Images\u201d, NeurIPS (2018).\n[4]. Hu, S., Worrall, D., Knegt, S.J., Veeling, B., Huisman, H.J., & Welling, M., \u201cSupervised Uncertainty Quantification for Segmentation with Multiple Annotations\u201d. MICCAI (2019).\n\n", "title": "Initial response to reviewer 1 -- Part (2/2)"}, "HJenV_FQjr": {"type": "rebuttal", "replyto": "BygwEyIPKB", "comment": "Thank you for your valuable feedback! After carefully reading your comments we plan to modify the manuscript as discussed below (the planned changes are shown by ** \u2026 **). We would appreciate it if you could let us know whether the proposed changes address your concerns, or whether we have misinterpreted your comments.\n-----\n\"Eq. (8) is expected to give very bad results. The reason is that it is very unlikely to sample from the prior configurations for z that are compatible with y.\"\n\nWe agree that it is in general a bad idea to use this equation, especially when the likelihood is very informative. However, we have found that for likelihoods that are not very informative this method is still useful. Furthermore, we would like to point out that we do not use this equation for the results shown in the manuscript, but  rather use MCMC (eq. (9)) for all the results. ** We will include this discussion in the revised manuscript. **\n-----\n\"The paper does not address learning any model parameters. e.g. the amount of noise.\"\n\nYou are right, we do not learn parameters associated with the noise in this work. We do however learn the parameters associated with the forward model by mapping them back to the latent space of the GAN. This is most clear in the context of the physics-based model (Section 3.2), where we parameterize forward model using pixel-wise values of the initial temperature, and then learn these parameters using the proposed method. \n\nWe note that the proposed approach can easily be extended to regime where likelihood is also unknown by incorporating likelihood-free inference methods like ABC or meta-learning approaches. ** We will include this discussion the revised version **. \n-----\n\"A more principled approach would be to estimate the prior parameters using maximum likelihood estimation. That has already been done in the case of the variational autoencoder.\nThe variational autoencoder is an already known method that can be used to solve the problem formulated by the authors. It also automatically proposes an inference network that can be used for recognition. If the likelihood is Gaussian and p(x|z) is also Gaussian, one can directly marginalize x and work with p(y|z) and p(z). The authors should at leas discuss the potential use of this method alongside with the BIGAN model which also provides a recognition model.\"\n\nWe agree that we were lacking a proof that demonstrated the convergence of the proposed method for computing point estimates of the posterior. ** We have now derived this proof and will include it in the Appendix. ** In a nutshell, this proof establishes that with increasing the expressivity of the generator and the discriminator (increasing number weights) the point estimates computed using the proposed approach converges to the true point estimates of the posterior. \n\nWe agree that using a variational autoencoder (VAE) in lieu of a GAN is an interesting extension of the proposed approach and that this can be accomplished in different ways. ** We are working on writing a concise description of these ideas and will include in the revised manuscript. ** However, we would like to point out that for image recovery tasks GANs have consistently demonstrated better performance than VAEs, as the latter tend to smear out images due to their maximum likelihood loss.\n\nWhile the idea of using corrupted images to train the VAE and inferring the latent variable, which would be the  - un-corrupted image is very interesting and using VAE with max. likelihood loss is an intriguing option, there are some major drawbacks of using it in the proposed Bayesian inference setting. \n\u2022\tIt is well-known that image samples produced by VAEs are quite blurry and of poorer quality than GAN and fail to match the true data distribution. It is shown in earlier studies that they fail to match marginal distribution not only in visible space but also in latent space [1]. Since, the focus of our paper is to use these distributions as priors, we believe that it is better to select a model for these distributions and hence GAN is our preferred choice. \n\u2022\tFurthermore, VAEs are explicit density model and we have to select a model family (like Gaussian) for the latent variables. Therefore, in a setting where we treat un-corrupted images as latent variables (as suggested by the reviewer), and use max. likelihood as our loss function, we are forcing the latent variables to be close to that chosen family of distributions. This, might fail to capture complex inferred joint probability distribution seen in the examples considered in this manuscript, which is far from Gaussian (or any other simple distribution). It is also against the spirit of this work, where we want to make as few assumption as possible for our prior and use data to guide its final form.\n\n[1]. Rosca, M., Lakshminarayanan, B., & Mohamed, S. (2018). Distribution Matching in Variational Inference. ArXiv, abs/1802.06847.\n\n", "title": "Initial response to reviewer 1 -- Part (1/2)"}, "r1lA7pumoH": {"type": "rebuttal", "replyto": "rJghfrNnKS", "comment": "Thank you for your valuable feedback! After carefully reading it, we plan to modify the manuscript as discussed below (the planned changes are shown by ** \u2026 **). We would appreciate it if you could let us know whether the proposed changes address your concerns, or whether we have misinterpreted your comments.\n\n\u2022\tYou have raised an interesting question about how the accuracy of the GAN impacts the accuracy of the proposed method. In order to address this, we have developed analytical estimates for the error in the point estimates computed using the proposed approach and show that these are intimately tied to error in computing the point estimates for the prior using the GAN. We have also demonstrated that as the generator and the discriminator of the GAN become more expressive this error tends to zero, and the exact point estimates, for both the prior and the posterior, are recovered. ** In the revised manuscript, we will include this mathematical analysis in the Appendix and refer to it in the main text. **\n\n\u2022\tWe note that our method of inferring the desired image from the measured image is an unsupervised method; for training we only need a set of desired images  to construct the prior. We are not aware of any other unsupervised learning approach for solving these types of problems with quantified uncertainty. In that regard, the calculation of point-wise variance (our metric of uncertainty) is possible only using our approach, and therefore a direct comparison is not possible, since other supervised methods (explained below) cannot work in this setting where only set of desired images are available. ** We will clarify this unique aspect in the revised version of the manuscript. **\n\n\u2022\tThere has been some work on computing the uncertainty in an inferred image within a supervised learning framework where pairs of measured and desired images are used for training the network [1, 2]. In these articles the authors have used methods like Bayesian dropout and variational autoencoder to compute uncertainty in the inferred images.  ** We will refer to these works in the revised version to better orient reader. **\n\n\n[1]. A. Kendall and Y. Gal, \u201cWhat Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?\u201d, NIPS (2017).\n [2]. Kohl, S.A., Romera-Paredes, B., Meyer, C., Fauw, J.D., Ledsam, J.R., Maier-Hein, K.H., Eslami, S.M., Rezende, D.J., & Ronneberger, O. \u201cA Probabilistic U-Net for Segmentation of Ambiguous Images\u201d, NeurIPS (2018).\n\n", "title": "Initial response to reviewer 2"}, "Hker4juXsH": {"type": "rebuttal", "replyto": "SJlld01kcS", "comment": "Thank you for your valuable feedback! After carefully reviewing it, we plan to modify the manuscript as discussed below (the planned changes are shown by ** ... **). We would appreciate it if you could let us know whether the proposed changes address your concerns, or whether we have misinterpreted your comments. \n\n\"A big issue of this paper is the deviation of purpose and method. As the paper claims to quantify the uncertainty, the paper is supposed to give specific quantitative metric or values to probe the uncertainty. However, the paper demonstrates to us only the ability, not exactly 'quantification'. I\u2019d like to see a specific metric of uncertainty that could only be calculated through the proposed method.\" \n\nYou are right, the main purpose of the method is to quantify uncertainty in the task of  image inference. Given this, we treat the inference as a stochastic problem, and develop an expression for the probability density function of the inferred image (i.e. joint pdf for each pixel of the inferred image). Once this is done, we sample from this distribution and compute any appropriate point estimate that can quantify the uncertainty in the inference. In our work, we have chosen the \"pixel-wise\" variance as this metric. Note that this metric is a field and not a scalar quantity and is plotted as an image. We have computed this metric for every example in the manuscript (see last row of figure 2, 3, 5 etc). ** However, we have been remiss in not highlighting, or bringing the reader\u2019s attention to it. In the revised version of the paper we will do this. **\n\nSome more things to note:\n1.\tIn one example (Figure 4) we compute a scalar metric (that is the average variance/per pixel over the entire image) for the  inferred images, and show that this measure increases with increasing noise in the input, as it should. ** In the revised version, we will draw the reader's attention to this example. **\n\n2. \tWe note that our method of inferring the desired image from the measured image is an unsupervised method; in that for training we only need a set of desired images to construct the prior. We are not aware of any other unsupervised learning approach for solving these types of problems with quantified uncertainty. In that regards, the calculation of pixel-wise variance (our metric of uncertainty) in an unsupervised setting is possible only using our approach. ** We will clarify this unique aspect in the revised version of the manuscript. **  \n\n3.\tWe note that there has been recent work on computing the uncertainty in an inferred image within a supervised learning framework where pairs of measured and desired images are used for training the network. In these articles the authors have used methods like Bayesian dropout to compute uncertainty in the inferred images [1]. Similar to what we have done, these authors have also plotted the point-wise variance as a quantitative metric of uncertainty. ** We will refer to these works in the revised version to better orient the readers. **\n\n4.\tWe note that we have gone beyond just computing the metric of uncertainty (point-wise variance) and also described how it might be useful in making the subsequent measurement in the context of an active learning approach, which to the best of our knowledge has not been done previously in Bayesian deep learning applied to image inference. \n\n\n\"There are some grammar issues in the paper. For example. '\u2026we the MAP\u2026' in the 7th page.\"\n\n** We are doing a through scrub of manuscript in order to catch these.  **\n\n\n[1]. A. Kendall and Y. Gal, \u201cWhat Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?\u201d, NIPS (2017).\n", "title": "Initial response to reviewer 3"}, "BygwEyIPKB": {"type": "review", "replyto": "HyeAPeBFwS", "review": "Summary of the paper:\n  \n        The paper proposes a Bayesian approach to make inference about latent variables such as un-corrupted images. The prior distribution plays a key role in this task. The authors use a GAN to estimate this prior distribution. Then, standard Bayesian techniques such a Hamilton Monte Carlo are used to make inference about the latent variables.\n\nDetailed comments:\n\nEq. (8) is expected to give very bad results. The reason is that it is very unlikely to sample from the prior configurations for z that are compatible with y.\n\nThe paper does not address learning any model parameters. e.g. the amount of noise.\n\nA more principled approach would be to estimate the prior parameters using maximum likelihood estimation. That has already been done in the case of the\nvariational autoencoder.\n\nThe variational autoencoder is an already known method that can be used to solve the problem formulated by the authors. It also automatically proposes\nan inference network that can be used for recognition. If the likelihood is Gaussian and p(x|z) is also Gaussian, one can directly marginalize x and work\nwith p(y|z) and p(z). The authors should at leas discuss the potential use of this method alongside with the BIGAN model which also provides a recognition model.\n\nIt is not clear how the HMC parameters are fixed.\n\nThe experiments do not have error bars (Figure 4.) This questions the significance of the results.\n\nMy overall impression is that there is little novelty in the proposed approach. Namely, using a GAN to learn the prior distribution, and then very well known\ntechniques to infer the original input image.\n\nI have missed some references to related work on inverse problems. An example is:\n\nhttps://arxiv.org/pdf/1712.03353.pdf\n\n\nIs the original figure contained in the training set used to infer the GAN. If so that can lead to biased results.\n\nI have missed a simple baseline in which one simply finds the training image that is closest to the corrupted observed or partially observed image.\n\nMy overall impression is that there is not much novelty in the paper as it is simply a combination of well known techniques. E.g. GANs and Bayesian inference with Monte Carlo methods.\n\n", "title": "Official Blind Review #1", "rating": "3: Weak Reject", "confidence": 2}, "rJghfrNnKS": {"type": "review", "replyto": "HyeAPeBFwS", "review": "The paper studies the Bayesian inferences with the generative adversarial network (GAN). In the first half of the paper, the general framework of the Bayes estimation is introduced. Then, The authors proposed how to incorporate GAN to the Bayesian inference. Some computational methods for calculating the mean of the statistic under the posterior distribution are described. Then, numerical experiments using MNIST and Celeb-A datasets are presented. \n\nThough the Bayesian inference using GAN is a natural idea, learning algorithms proposed in this paper are simple and are not intensively developed. In numerical experiments, there is no comparison with major competitors besides random sampling in the active learning setup. Hence, the effectiveness and advantage of the proposed methods are not clear.\n- In active learning, the proposed method should be compared with other methods such as Bayesian DNN using dropout, etc. \n- How does the estimation accuracy of GAN relate to the estimation accuracy of the proposed method? Showing a quantitative description would be nice.\n", "title": "Official Blind Review #2", "rating": "3: Weak Reject", "confidence": 2}, "SJlld01kcS": {"type": "review", "replyto": "HyeAPeBFwS", "review": "This paper proposes to use a trained GAN model as the prior distribution for Bayesian inference to quantify the uncertainty. As for me, the best application of this paper is to restore a corrupted image, which shares a lot of common properties in image restoration, denoising and image reconstruction. I do like the extension of applying the idea in physics problems. And the results demonstrate at some extent, the proposed method could evaluate some uncertainty. \n\nThe idea is pretty simple and the paper is easy to read.  Nonetheless, there are some issues:\n\nA big issue of this paper is the deviation of purpose and method. As the paper claims to quantify the uncertainty, the paper is supposed to give specific quantitative metric or values to probe the uncertainty. However, the paper demonstrates to us only the ability, not exactly \u201cquantification\u201d. I\u2019d like to see a specific metric of uncertainty that could only be calculated through the proposed method. \n\nThere are some grammar issues in the paper. For example. \u201c\u2026we the MAP\u2026\u201d in the 7th page.\n\nGiven my major issue seems to be quite problematic, I currently would weakly reject this paper. But I don\u2019t have a full picture over this area, I\u2019ll read the rebuttal and see if I could raise the score.", "title": "Official Blind Review #3", "rating": "3: Weak Reject", "confidence": 3}}}