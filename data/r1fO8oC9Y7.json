{"paper": {"title": "Multi-Task Learning for Semantic Parsing with Cross-Domain Sketch", "authors": ["Huan Wang", "Yuxiang Hu", "Li Dong", "Feijun Jiang", "Zaiqing Nie"], "authorids": ["odile.wh@alibaba-inc.com", "yuxiang.hyx@alibaba-inc.com", "li.dong@ed.ac.uk", "feijun.jiangfj@alibaba-inc.com", "zaiqing.nzq@alibaba-inc.com"], "summary": "General-to-detailed neural network(GDNN)  with Multi-Task Learning by incorporating cross-domain sketch(CDS) for semantic parsing", "abstract": "Semantic parsing which maps a natural language sentence into a formal machine-readable representation of its meaning, is highly constrained by the limited annotated training data. Inspired by the idea of coarse-to-fine, we propose a general-to-detailed neural network(GDNN) by incorporating cross-domain sketch(CDS) among utterances and their logic forms. For utterances in different domains, the General Network will extract CDS using an encoder-decoder model in a multi-task learning setup. Then for some utterances in a specific domain, the Detailed Network will generate the detailed target parts using sequence-to-sequence architecture with advanced attention to both utterance and generated CDS. Our experiments show that compared to direct multi-task learning, CDS has improved the performance in semantic parsing task which converts users' requests into meaning representation language(MRL). We also use experiments to illustrate that CDS works by adding some constraints to the target decoding process, which further proves the effectiveness and rationality of CDS.", "keywords": ["semantic parsing", "natural language understanding", "machine learning"]}, "meta": {"decision": "Reject", "comment": "Interesting approach aiming to leverage cross domain schemas and generic semantic parsing (based on meaning representation language, MRL) for language understanding. Experiments have been performed on the recently released SNIPS corpus and comparisons have been made with multiple recent multi-task learning approaches. Unfortunately, the proposed approach falls short in comparison to the slot gated attention work by Goo et al.\n\nThe motivation and description of the cross domain schemas can be improved in the paper, and for replication of experiments it would be useful to include how the annotations are extended for this purpose.\n\nExperimental results could be extended to the other available corpora mentioned in the paper (ATIS and GEO).\n"}, "review": {"H1xfPpkdR7": {"type": "rebuttal", "replyto": "rke8DKIKhm", "comment": "Thank you for your reviews!\n\n1, CDS definition and value\nIn the revisioned paper, we add a subsection 3.1 to describe CDS definition in detail. We also list the attributes that can form CDS since actions are very few due to the limitation of the dataset. Besides, we do some statistics on the dataset and reveal the percent that CDS can share.\nCDS is an extraction of cross-domain features. CDS based ontology can be generalized to other semantic parsing datasets, as long as there are common expressions in the utterances, which can be manifested from the target side such as some logic form. In the dataset used in our work, we convert the target logic form into CDS by some pre-defined rules. As for other datasets, we can do the same process. The main concern is that we should know the dataset very well and find the common shared things (in our case, action/attribute) which put high demands on datasets' amount and quality.\n\n2, evaluation accuracy\nWe use the logic form accuracy as the evaluation metric. Since the logic form is in a tree structure, we compare the predict tree and ground truth tree which is the accuracy.\n\n3, some clarifications\nThe \u201cirrelevant to domain\u2019\u2019 means  \u201cdomain-general\u2019\u2019, since we focus on the features across the domains. In the future work, we would like to explore more ways to make CDS work such as constraint decoding or other more direct ways since now we use the attention mechanism to incorporate CDS into the network.", "title": "Response to Reviewer3"}, "H1x0ST1_AX": {"type": "rebuttal", "replyto": "BklT1yJs27", "comment": "Thanks for bringing the idea of SRL and other reviews.\n\n1, CDS definition\nIn the revisioned paper, we add a subsection 3.1 to describe CDS definition in detail. We also list the attributes that can form CDS since actions are very few due to the limitation of the dataset. Besides, we do some statistics on the dataset and reveal the percent that CDS can share.\nCDS is an extraction of cross-domain features. Compared to FrameNet or VerbNet, CDS is more abstract and more like a schema composition since it is an extraction of common info of language expressions and it is across the domains. In the dataset used in our work, we convert the target logic form into CDS by some pre-defined rules. As for other datasets, we can do the same process. \n\n2, why not SRL\nThough SRL and semantic parsing seem very similar, SRL focuses more on syntax analysis while we try to get the intent and slots. For semantic parsing task using the dataset Snips, the sentences, which are users' requests collected from voice assistants, are usually imperative sentences without subjects, which are not suitable for SRL task. SRL is meant to label the predicates\u2018 arguments with given predicates, however, for this work, we should convert the whole sentence including predicates/objects into normalized pre-defined actions/attributes.\n\n3, grammar and format\nMoreover, we did some refinements in grammar and formatting. ", "title": "Response to Reviewer1"}, "r1eYVpJ_C7": {"type": "rebuttal", "replyto": "HJeYN9r63Q", "comment": "Thanks for the thoughtful review! We respond as follows.\n\n1, CDS definition\nIn the revisioned paper, we add a subsection 3.1 to describe CDS definition in detail. We also list the attributes that can form CDS since actions are very few due to the limitation of the dataset. We do some statistics on the dataset and reveal the percent that CDS can share.\n\n2, why not choose ATIS or GEO \nIn subsection 4.1 experiments, we explain why we do not choose ATIS or GEO because they collect data only from one domain and have a limited amount which is not suitable for cross-domain experiments. \n\n3, multi-task learning\nFor dataset Snips, each domain can be seen as a task, so we regard this experiment as multi-task learning. Since we suffer a lot from existed datasets, in the future, we would like to construct more suitable datasets, proposing the idea of CDS.\n\n4, experiments\nWe do MRL parsing task on the same conditions and compare our model(74.6) with Seq2Seq(one-to-one, 71.4). Compared to direct multi-task learning, our model improves the performance.\n", "title": "Response to Reviewer2"}, "SkeFlTk_A7": {"type": "rebuttal", "replyto": "r1fO8oC9Y7", "comment": "Thank you all for the valuable reviews. Based on your suggestions, we have made some updates to our paper and have uploaded it on openreview.net.\n\n1, CDS definition\nIn the revisioned paper, we add a subsection 3.1 to describe CDS definition in detail. We also list the attributes that can form CDS since actions are very few due to the limitation of the dataset. Moreover, we do some statistics on the dataset and reveal the percent that CDS can share.\n\n2, CDS value\nCDS is an extraction of cross-domain features. Since CDS is defined from language ontology itself, it can be generalized to other semantic parsing tasks.\n\n3, paper structure\nWe compressed the space for the two-layer encoder-decoder network and paid more attention to CDS. Our intuition is to propose the idea of CDS, so we focus on how it is defined and how it works by experimental analysis.\n\nFurthermore, we add responses to different reviewers separately as follows.", "title": "Summary of revisions"}, "HJeYN9r63Q": {"type": "review", "replyto": "r1fO8oC9Y7", "review": "Overall Score 3\n\nThis paper introduces \u201cCross domain schemas\u201d (CDS) for semantic parsing of utterances made to a virtual assistant. CDS captures similarities in requests according to the underlying actions or attributes being discussed, regardless of the user\u2019s high-level intent. Also introduced is a model which leverages CDS to improve semantic parsing of utterances to a meaning representation language (MRL). This model first parses an utterance to CDS, then uses an encoding of the CDS jointly with the utterance encoding to decode a meaning representation. By treating different intents as separate domains, the authors construct a multi-task learning setup for CDS and MRL parsing. Results are provided for the Snips dataset of virtual assistant queries. \n\nUnfortunately, this paper fails to sufficiently explain its main proposal, the CDS. The stated goal is to explicitly define the cross-domain features that would otherwise be implicitly learned by the parameters of a neural network, yet no explicit definition is given. No rough quantification of how many or what percent of features appear across domains is provided. Rather, significant time and space is given to describing a fairly unsophisticated two-decoder model for inserting the mysterious CDS representation into the final decoding task. \n\nThe paper ignores standard semantic parsing datasets (GeoQuery and ATIS) due to their size and scope. However, comparable models (Goo et al. 2018) are trained and tested on ATIS. Moreover, an evaluation on a small, unseen target domain would be the perfect justification for the kind of cross-domain learning proposed here. \n\nInstead, this paper opts only to evaluate on the recent Snips dataset. This dataset seems to be best suited to evaluating intent classification and slot filling (intent-slot), but the current work fails to improve over what Goo et al. 2018 report on this data. In the current work, the Snips dataset is used to evaluate MRL parsing, where the CDS model shows improvements over other seq2seq models. However, since MRL can be parsed from intent-slot format by predefined rules, it is uncertain whether the CDS model outperforms the Goo et al. model at even the task of MRL parsing (no such comparison is provided). \n\nOverall, the paper suffers from some clarity issues especially regarding the definition and value of CDS. The model provided may be slightly original but is quite similar to the model of Dong and Lapata 2018. The significance of this work is questionable due to the poor comparison with recently released baseline models for the more common intent-slot task. \n\nPros\n\nIntroduces \u201cCross Domain Schemas\u201d (CDS) for semantic parsing, which help improve robustness of semantic parsers by allowing models to learn patterns in one domain for use in another. \n\nThrough the use of CDS, train semantic parsers in a multi-task learning setup\n\nCons\n\nCDS is not described in sufficient detail. In particular, the possible actions and attributes are not defined. \n\nThe model is described as \u201cmulti-task learning\u201d, however all tasks are parsing requests made of a virtual assistant. \n\nResults on standard data for semantic parsing such as GEO or ATIS are not reported.\n\nThe model does not appear to improve the results on the Snips dataset compared to the paper that introduces this dataset. Thus, the value of CDS is difficult to judge. \n\nNo per-domain analysis of the impact of CDS is provided.", "title": "Overall score 3", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "BklT1yJs27": {"type": "review", "replyto": "r1fO8oC9Y7", "review": "This is a wonderful paper as it seems to have brougth Semantic Role Labelling (SRL) in the context of DL and in the context of voice search. \nResults are interesting but the paper has some major limitations. In fact, the paper totally disregard the work on Semantic Role Labelling and on languages for expressing the general meaning of language in terms of relations and in terms of concepts. \n\nThe first limitation is on the key idea. The key idea of the paper seems to be the existence of an intermediate representation language to encode meaning for utterances. Yet, this intermediate language seems to be the final language with the same relation types (for example, SearchAction) and without representations for the involved concepts (Type that becomes alternatively Film or Weather according to the target final language). This seems to be SRL where the first step is to recognize the relation and, then, the second step is to recognize the roles even if roles are slot filler types in the case of this papers.\n\nThe second limitation is on how the intermediate language has been choosen. What is the relation with FrameNet or VerbNet? Why the authors have not choosen something similar? What are the limitations of these two resources that have forced the authors to disregard them?\n\nMinor problems\n====\n- Why there are not spaces between characters and opening brackets?\n- \"compositional graph based .... language\" is a really large noun compound\n", "title": "Where's SRL?", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rke8DKIKhm": {"type": "review", "replyto": "r1fO8oC9Y7", "review": "This paper describes a two-stage encoder-decoder model for semantic parsing. The model first decodes a cross-domain schema (CDS) representation from the input utterance, then decodes the final logial form from both the utterance and CDS. The model outperforms other multitask Seq2Seq models on the Snips (Goo et al., 2018) dataset, but is still behind the traditional slot-filling models (Goo et al., 2018).\n\nMy main concern is that it is unclear to me how CDS (cross-domain schema) can be generalized to the other semantic parsing datasets, e.g., the Overnight dataset (Wang et al., 2015), which also contains multiple domains. \n\nI think it would be nice to have some details about the CDS in the paper. For example, I\u2019m wondering 1) how is this CDS designed? 2) how are the CDS annotations derived from the target output? \n\nThere are other details missing regarding the comparisons and the evaluation metrics. In 4.2, the authors mentioned \u201cWe use accuracy as the evaluation metric\u2019\u2019, does \u201caccuracy\u201d mean full logical form accuracy or accuracy on execution results?\n\n* More minor comments:\nIn the first paragraph of Section 3, \u201cirrelevant to domain\u2019\u2019 -> \u201cdomain-general\u2019\u2019 or \u201cdomain-agnostic\u2019\u2019?\n\nIt will be nice to write something more specific than \u201cexplore more ways to make it work better\u201d in the future work.\n\nThis paper has some grammatical errors and formatting issues (e.g. missing space before punctuations).\n\n* Missing references:\nNeural semantic parsing over multiple knowledge-bases, Herzig and Berant, ACL 2017 <- This paper explores shared encoder/decoder for multi-domain semantic parsing, which is very related.\n\n(Concurrent) Decoupling Structure and Lexicon for Zero-Shot Semantic Parsing, Herzig and Berant, EMNLP 2018 \n", "title": "Semantic parsing model with a domain-agnostic intermediate decoding step", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}