{"paper": {"title": "Generative Multi-Adversarial Networks", "authors": ["Ishan Durugkar", "Ian Gemp", "Sridhar Mahadevan"], "authorids": ["idurugkar@cs.umass.edu", "imgemp@cs.umass.edu", "mahadeva@cs.umass.edu"], "summary": "GANs with multiple discriminators accelerate training to more robust performance.", "abstract": "Generative adversarial networks (GANs) are a framework for producing a generative model by way of a two-player minimax game.  In this paper, we propose the \\emph{Generative Multi-Adversarial Network} (GMAN), a framework that extends GANs to multiple discriminators. In previous work, the successful training of GANs requires modifying the minimax objective to accelerate training early on. In contrast, GMAN can be reliably trained with the original, untampered objective. We explore a number of design perspectives with the discriminator role ranging from formidable adversary to forgiving teacher.  Image generation tasks comparing the proposed framework to standard GANs demonstrate GMAN produces higher quality samples in a fraction of the iterations when measured by a pairwise GAM-type metric.", "keywords": ["Deep learning", "Unsupervised Learning", "Games"]}, "meta": {"decision": "Accept (Poster)", "comment": "Using an ensemble in the discriminator portion of a GAN is a sensible idea, and it is well explored and described in this paper. Further clarification and exploration of how the multiple discriminators are combined (max versus averaging versus weighted averaging) would be good. The results are fairly strong, across a variety of datasets."}, "review": {"BJYjhPGwl": {"type": "rebuttal", "replyto": "r1KSQIbwx", "comment": "Thank you for your feedback! We changed the captions to the relevant figures (3,4,10,11,12,13) to emphasize the difference between the two plots.  We also made the distinction clearer in Section 5.2.1.  Please let us know if more clarification is required.\n\nAnd thank you for clarifying what you meant by \"convergence of the GAN game\".  We understand your point.", "title": "Re: Reviewer 3"}, "HyMVqDAUl": {"type": "rebuttal", "replyto": "BkPT7URIl", "comment": "Thank you for reviewing our new figures.\n\nWith regards to the GMAM metric, we are not sure what you mean by convergence of the GAN game.  If you are referring to convergence of the weights of the nets, then true, we have not shown convergence.  However, if you're referring to the convergence of the minimax objective, we've clearly shown that in Figures 3, 10, and 12.  With respect to the latter, the game has converged and learning has reached equilibrium at which point it seems reasonable to compare different models against each other.\n    That all being said, the GMAM metric is not the focus of the paper - it is only one of the ways we evaluated our models.  We also evaluate the quality of the learned models using Inception scores and illustrative generated images as well as supplementary evidence of the learned model's quality.\n\nWith regards to Figures 12 and 13, no, these plots are not contradictory.  Figure 13 is produced by the following algorithm:\n\"\nFor run=1:5:\n   Measure standard deviation of the minimax objective over a sliding window of width 500 iterations\nPlot mean of these 5 measurements\n\"\nTherefore, low values indicate low standard deviation over a window which implies steady-state.  In short, Figure 12 displays standard deviation over runs (with the fill plot), whereas Figure 13 displays standard deviation over time.\n", "title": "Re: Reviewer 3"}, "HyfkdtULg": {"type": "rebuttal", "replyto": "S1ZU-6YNg", "comment": "Please check the Appendix (SPECIFICALLY A.1 AND A.2) for additional results!", "title": "Re: Reviewer 3"}, "rkUt3_8Ue": {"type": "rebuttal", "replyto": "HkYCUhr4g", "comment": "Thank you for your comments. We did not compare against GAN with DAE because it is a parallel submission in this conference. However, that paper contains Inception scores for their model on CIFAR-10 which can be directly compared against our model (SEE TABLE 6 IN APPENDIX A.3).", "title": "Re: Reviewer 1"}, "S1ZU-6YNg": {"type": "rebuttal", "replyto": "B1Ob_V4Ne", "comment": "Thank you for the review and the insights!\nWe agree that the GMAM metric is not an absolute score for evaluating GANs. However, we do feel that it is an appropriate method to compare GAN models against each other. It is also an unsupervised method to evaluate GANs that are not limited to the domain of images. More detailed results for CIFAR and MNIST using the GMAM metric are included in the Appendix to show this. We have also included Inception scores for the CIFAR dataset in the Appendix to show that the GMAM metric compares well with how the score evaluates Generated images.\n\nFigure 3 and Figure 4 plot the dynamics of the different models while learning. With multiple discriminators it is evident that variance in the Generator objective is reduced and the convergence to equilibrium is achieved up to twice as fast.\nFurther, the using the original unmodified objective with a single discriminator leads to saturation early on in the training process with the generator not getting meaningful signals. Using multiple discriminators mitigates this issue as well.\nFigures 10 and 11 in the Appendix plot the same dynamics as Figures 3 and 4 on the CelebA dataset. Here training with the original unmodified objective and a single discriminator was not possible due to the saturation problem, while with multiple discriminators we could use the original objective.\n\nFor more empirical results, we have shall include plots similar to figures 3 and 4 (and 10, 11) for the CIFAR dataset as well. We shall also include results on one more dataset soon.", "title": "Review Response"}, "S1nh03KNe": {"type": "rebuttal", "replyto": "r1D00RZNl", "comment": "Thank you for the review and the feedback!\nFigure 1 was meant to depict the idea of multiple Discriminators providing feedback to the Generator, with the caption giving an example by specifying F:= max in section 3.1.\nWe will modify the caption so that the complete idea is more evident and less misleading.\nWe have also modified the layout of the paper to avoid the misunderstanding that was pointed out. We will be uploading the same soon.", "title": "Review Response"}, "SkIPwMQXl": {"type": "rebuttal", "replyto": "r1k1fC1me", "comment": "Thank you for your comment. We explore both extremes through the perspective of multiple adversaries: training against the best discriminator vs worst (or at least more lenient).  Each extreme focuses on a different issue.\n\nTraining against the best discriminator focuses on optimality of the GAN solution.\n1) GAN Solution Optimality: The original GAN proof was formulated around training against the best discriminator.  This means that we don't have any optimality guarantees when training against a suboptimal discriminator.  In practice, we never have access to the optimal discriminator, so we must train without these guarantees, however training against a better discriminator should bring us closer to the case where we DO have optimality guarantees.\n\nTraining against a more lenient discriminator focuses on GAN convergence to equilibrium.\n2) GAN Convergence to Equilibrium: As you say, it is difficult to train a generator against a strong discriminator.  For this reason and others, in Section 3.3, we explore training against a more lenient discriminator (or ensemble).", "title": "Re: Pre-review Question (Reviewer 1)"}, "Sy4xNzQQg": {"type": "rebuttal", "replyto": "SJ9mtW1Qx", "comment": "Thank you for your comment.  To be clear, Sections 3.1 and 3.2 discuss training against the best discriminator, however, the rest of the paper largely focuses on relaxing this assumption and exploring the exact train of thought you outline above.\n\n1) Section 3.3 asks the question, \"Is max too harsh a critic?\".  Section 3.3.1 discusses replacing the max with a softmax.  3.3.2 discusses the effect that the arithmetic mean has on early training.  As you state in your example above, the training signals received from the deep model would be nearly zero, however, those of the linear classifier, while maybe not as accurate, might still be helpful to training.  The arithmetic mean returns (0+linear_signal)/2, allowing training signals to flow to the generator.  3.3.3 discusses this intuition from a probability density perspective.\n\n2) We also explore the harmonic (HM, eqn5) and geometric means (GM, eqn4) in addition to the arithmetic (AM, eqn3).  It is known that min <= HM <= GM <= AM <= max.  This means that HM encourages training against the weakest discriminator (relative to the arithmetic mean).  However, we found that HM and GM did not perform as well as AM in our experiments.", "title": "Re: Training against the best discriminator (Reviewer 2)"}, "HJ8MMX17l": {"type": "rebuttal", "replyto": "r170IgRMl", "comment": "1. The max is over the N players and is taken at each time step.  For example, at time t, each discriminator receives a loss, V_i(t), after assigning probabilities to the samples generated by the generator and those from the real dataset.  Let's say N=3 and the losses are V_1(t),V_2(t),V_3(t) = -2,-1,-3.  We then compute the max: \\max\\{ V_1(t),V_2(t),V_3(t) \\} = \\max\\{ -2,-1,-3 \\} = -1.  This means we backpropagate the loss of discriminator_2 to update the generator weights.\n\nYou can think of the standard GAN as following this same procedure, but computing the max over a single discriminator, which trivially returns the single discriminator: \\max{ V_1(t) \\} = V_1(t).\n\n2. The primes are meant to distinguish between two instantiations of the discriminator and it's associated loss.  We will make this more clear.\n\nThe point we were trying to make is imagine you use a standard single-discriminator GAN with the discriminator and generator initialized with weights w_d and w_g respectively.  Assume we are NOT using dropout, so the training is entirely deterministic.  Let's run training to convergence and record the loss of the discriminator at each time step t.  Call this loss V'_1(t) as in the paper.\n\nNow, let's use GMAN with N discriminators.  Initialize the generator weights to w_g and discriminator_1's weights to w_d just as in the previous experiment.  The N-1 other discriminators can be initialized randomly.  We still are NOT using dropout.  Let's run training to convergence and record the loss of each discriminator at time step t.  Call these losses V_1(t), ..., V_N(t) as in the paper.\n\nThe only difference between these two training runs is that the second run includes N-1 other discriminators.  The point that we are trying to make is that the mere existence of the N-1 discriminators changes the dynamics of the game because of the complex interactions between all the players.  This means that V_1(t) does not equal V'_1(t).  In fact, it's hard to make any claims on how much V_1(t) and V'_1(t) differ, therefore, it's hard to make any claims on how much \\max\\{ V_1(t), ..., V_N(t) \\} and \\max\\{ V'_1(t) \\} = V'_1(t) differ *(the max is over the players, not over time).\n\nThis argument is simply to say that, unfortunately, we CANNOT claim that taking the max over N discriminators returns a strictly higher loss than using a single discriminator.  Maybe this is obvious and we've only confused readers more, but we thought it was an important point to make.\n\n", "title": "Re: Section 3.1 questions (Reviewer 3)"}, "r1k1fC1me": {"type": "review", "replyto": "Byk-VI9eg", "review": "This is interesting work which train multiple discriminators simultaneously. It is known that if discriminator is too strong generator will be hard to converge. Why to choose to train against the best discriminator? This work brings multiple discriminators into GAN. From the result, multiple discriminators is useful for stabilizing. \n\nThe main problem of stabilizing seems is from gradient signal from discriminator, the authors motivation is using multiple discriminators to reduce this effect.\n\nI think this work indicates the direction is promising, however I think the authors may consider to add more result vs approach which enforce discriminator gradient, such as GAN with DAE (Improving Generative Adversarial Networks with Denoising Feature Matching), to show advantages of multiple discriminators.", "title": "Pre-review Question", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "HkYCUhr4g": {"type": "review", "replyto": "Byk-VI9eg", "review": "This is interesting work which train multiple discriminators simultaneously. It is known that if discriminator is too strong generator will be hard to converge. Why to choose to train against the best discriminator? This work brings multiple discriminators into GAN. From the result, multiple discriminators is useful for stabilizing. \n\nThe main problem of stabilizing seems is from gradient signal from discriminator, the authors motivation is using multiple discriminators to reduce this effect.\n\nI think this work indicates the direction is promising, however I think the authors may consider to add more result vs approach which enforce discriminator gradient, such as GAN with DAE (Improving Generative Adversarial Networks with Denoising Feature Matching), to show advantages of multiple discriminators.", "title": "Pre-review Question", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "Bk2Z-z1Qe": {"type": "rebuttal", "replyto": "HkpjWFife", "comment": "Thank you for your interest!\n\nWe specifically used a variant of boosting, AdaBoost.OL (Algorithm 2 in http://jmlr.org/proceedings/papers/v37/beygelzimer15.pdf), which is actually hyperparameter-free.  This algorithm predicts 1's and 0's (binary classification), so we changed a few parts of the algorithm to enable the boosted-discriminator to output probabilities [0-1].  We can include a formal description of the algorithm in the Appendix, but in short, we made the following changes to Algorithm 2 to derive a continuous relaxation of AdaBoost.OL (please refer to beygelzimer15).\n\n1) Line 5: remove \"sign\"\n2) Lines 7,8: predict weighted average of \\hat{y}^{i_t}_t with weights proportional to v^i_t\n3) Line 12: we clip s^i_t to [-4,4] to avoid under/overflow of exponential in Line 13\n4) Line 15: instead of using the indicator function (y_t \\ne \\hat{y}^i_t), we use a sigmoid so that the computation remains differentiable\n\nThe range to clip s^i_t (Line 12) is the only hyperparameter we introduce ([-4,4]) and the algorithm is not very sensitive to it.  The weak learners we used as part of AdaBoost.OL, however, are deep neural networks, which obviously, have many hyperparameters.  These are described in Appendix A.6 of the paper.", "title": "Re: setup of boosting (Yaodong Yang)"}, "SJ9mtW1Qx": {"type": "review", "replyto": "Byk-VI9eg", "review": "In the paper the generator is trained against the best discriminator. Would it also make sense to train the generator against the worst discriminator early on in some circumstances? For example, consider we have two discriminators: a linear one and a powerful deep network. Early on, the generator produces very different samples from real data. The deep model will perfectly classify fake vs. real, and training signals/derivatives would be close to 0. The linear model on the other hand may not be able to exactly classify fake from real, but it will still do something meaningful. Moving along the derivative of the linear classifier will roughly try to align the means of real and fake data.\n\nThe point I'm trying to address here is that if you have an ensemble of differently complex discriminators, you may not always want to follow the best one... Could the authors comment on this observation?In this interesting paper the authors explore the idea of using an ensemble of multiple discriminators in generative adversarial network training. This comes with a number of benefits, mainly being able to use less powerful discriminators which may provide better training signal to the generator early on in training when strong discriminators might overpower the generator.\n\nMy main comment is about the way the paper is presented. The caption of Figure 1. and Section 3.1 suggests using the best discriminator by taking the maximum over the performance of individual ensemble members. This does not appear to be the best thing to do because we are just bound to get a training signal that is stricter than any of the individual members of the ensemble. Then the rest of the paper explores relaxing the maximum and considers various averaging techniques to obtain a \u2019soft-discriminator\u2019. To me, this idea is far more appealing, and the results seem to support this, too. Skimming the paper it seems as if the authors mainly advocated always using the strongest discriminator, evidenced by my premature pre-review question earlier.\n\nOverall, I think this paper is a valuable contribution, and I think the idea of multiple discriminators is an interesting direction to pursue.", "title": "Training against the best discriminator", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "r1D00RZNl": {"type": "review", "replyto": "Byk-VI9eg", "review": "In the paper the generator is trained against the best discriminator. Would it also make sense to train the generator against the worst discriminator early on in some circumstances? For example, consider we have two discriminators: a linear one and a powerful deep network. Early on, the generator produces very different samples from real data. The deep model will perfectly classify fake vs. real, and training signals/derivatives would be close to 0. The linear model on the other hand may not be able to exactly classify fake from real, but it will still do something meaningful. Moving along the derivative of the linear classifier will roughly try to align the means of real and fake data.\n\nThe point I'm trying to address here is that if you have an ensemble of differently complex discriminators, you may not always want to follow the best one... Could the authors comment on this observation?In this interesting paper the authors explore the idea of using an ensemble of multiple discriminators in generative adversarial network training. This comes with a number of benefits, mainly being able to use less powerful discriminators which may provide better training signal to the generator early on in training when strong discriminators might overpower the generator.\n\nMy main comment is about the way the paper is presented. The caption of Figure 1. and Section 3.1 suggests using the best discriminator by taking the maximum over the performance of individual ensemble members. This does not appear to be the best thing to do because we are just bound to get a training signal that is stricter than any of the individual members of the ensemble. Then the rest of the paper explores relaxing the maximum and considers various averaging techniques to obtain a \u2019soft-discriminator\u2019. To me, this idea is far more appealing, and the results seem to support this, too. Skimming the paper it seems as if the authors mainly advocated always using the strongest discriminator, evidenced by my premature pre-review question earlier.\n\nOverall, I think this paper is a valuable contribution, and I think the idea of multiple discriminators is an interesting direction to pursue.", "title": "Training against the best discriminator", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "r170IgRMl": {"type": "review", "replyto": "Byk-VI9eg", "review": "1. How is the max value computed? Is it approximated with a finite number of samples?\n\n2. In Section 3.1's second paragraph, the \"prime\" functions (D', V') don't appear to be mentioned anywhere else. What are they?The paper extends the GAN framework to accommodate multiple discriminators. The authors motivate this from two points of view:\n\n(1) Having multiple discriminators tackle the task is equivalent to optimizing the value function using random restarts, which can potentially help optimization given the nonconvexity of the value function.\n\n(2) Having multiple discriminators can help overcome the optimization problems arising when a discriminator is too harsh a critic. A generator receiving signal from multiple discriminators is less likely to be receiving poor gradient signal from all discriminators.\n\nThe paper's main idea looks straightforward to implement in practice and makes for a good addition to the GAN training toolbelt.\n\nI am not very convinced by the GAM (and by extension the GMAM) evaluation metric. Without evidence that the GAN game is converging (even approximately), it is hard to make the case that the discriminators tell something meaningful about the generators with respect to the data distribution. In particular, it does not inform on mode coverage or probability mass misallocation.\n\nThe learning curves (Figure 3) look more convincing to me: they provide good evidence that increasing the number of discriminators has a stabilizing effect on the learning dynamics. However, it seems like this figure along with Figure 4 also show that the unmodified generator objective is more stable even with only one discriminator. In that case, is it even necessary to have more than one discriminator to train the generator using an unmodified objective?\n\nOverall, I think the ideas presented in this paper show good potential, but I would like to see an extended analysis in the line of Figures 3 and 4 for more datasets before I think it is ready for publication.\n\nUPDATE: The rating has been revised to a 7 following discussion with the authors.", "title": "Section 3.1 questions", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "B1Ob_V4Ne": {"type": "review", "replyto": "Byk-VI9eg", "review": "1. How is the max value computed? Is it approximated with a finite number of samples?\n\n2. In Section 3.1's second paragraph, the \"prime\" functions (D', V') don't appear to be mentioned anywhere else. What are they?The paper extends the GAN framework to accommodate multiple discriminators. The authors motivate this from two points of view:\n\n(1) Having multiple discriminators tackle the task is equivalent to optimizing the value function using random restarts, which can potentially help optimization given the nonconvexity of the value function.\n\n(2) Having multiple discriminators can help overcome the optimization problems arising when a discriminator is too harsh a critic. A generator receiving signal from multiple discriminators is less likely to be receiving poor gradient signal from all discriminators.\n\nThe paper's main idea looks straightforward to implement in practice and makes for a good addition to the GAN training toolbelt.\n\nI am not very convinced by the GAM (and by extension the GMAM) evaluation metric. Without evidence that the GAN game is converging (even approximately), it is hard to make the case that the discriminators tell something meaningful about the generators with respect to the data distribution. In particular, it does not inform on mode coverage or probability mass misallocation.\n\nThe learning curves (Figure 3) look more convincing to me: they provide good evidence that increasing the number of discriminators has a stabilizing effect on the learning dynamics. However, it seems like this figure along with Figure 4 also show that the unmodified generator objective is more stable even with only one discriminator. In that case, is it even necessary to have more than one discriminator to train the generator using an unmodified objective?\n\nOverall, I think the ideas presented in this paper show good potential, but I would like to see an extended analysis in the line of Figures 3 and 4 for more datasets before I think it is ready for publication.\n\nUPDATE: The rating has been revised to a 7 following discussion with the authors.", "title": "Section 3.1 questions", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "HkpjWFife": {"type": "rebuttal", "replyto": "Byk-VI9eg", "comment": "Thanks for presenting the great paper.\nIn your experiments, you mentioned using boosting ad D didn't work very well. Could you please add more details of what parameters settings you had tried for the boost OL?", "title": "setup of boosting"}, "S1EaDy2Zg": {"type": "rebuttal", "replyto": "HJ04Yh1bl", "comment": "Thank you for the feedback!  We're glad you enjoyed the paper.  We apologize for the delay.  Our machine went down temporarily.  \n\n1) We've added CIFAR-10 GMAM metrics to the appendix (A.1.3 Table 3).  We also added Inception scores for CIFAR-10 (A.1.3 Table 4).  GMAN-0 (which averages discriminator losses) performed best in this case.  GMAN* did not perform as well as it did on MNIST, but self-regulating the difficulty of the game is an interesting avenue for future research.\n\n2) From our understanding, the Inception Score is computed using a deep net resulting from supervised training on ImageNet with class labels.  In that sense, it implicitly requires labels.  It's not clear if the authors of the Inception Score suggest using the same Inception model trained on ImageNet for generating Inception Scores on any possible image dataset (e.g., CIFAR-10); it seems natural to assume an Inception model is trained anew for each new image dataset.  More generally, the Inception Score cannot be used outside of image generation tasks.  The GAN framework has proven useful in a variety of domains (e.g., imitating RL policies), which is why we've proposed GMAM as a general metric that can be applied generally any domain.", "title": "Re: More results on CIFAR (Xun Huang)"}, "HJ04Yh1bl": {"type": "rebuttal", "replyto": "Byk-VI9eg", "comment": "This is a great paper and I really enjoy reading it. One thing I would like to see is more quantitative results on CIFAR 10 dataset. For example, is there a table of pairwise GMAM metrics on CIFAR, similar to the one on MNIST? Is it possible to show the Inception Scores on CIFAR? In the paper it's said that: \"Salimans et al. (2016) recommend an Inception score, however, it assumes labels exist for the dataset.\". To my knowledge it's not true, in Salimans et al. (2016) they also compute Inception Scores for models without using label information (See Table 3).", "title": "More results on CIFAR"}}}