{"paper": {"title": "Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness", "authors": ["Tianyu Pang", "Kun Xu", "Yinpeng Dong", "Chao Du", "Ning Chen", "Jun Zhu"], "authorids": ["pty17@mails.tsinghua.edu.cn", "kunxu.thu@gmail.com", "dyp17@mails.tsinghua.edu.cn", "duchao0726@gmail.com", "ningchen@mail.tsinghua.edu.cn", "dcszj@mail.tsinghua.edu.cn"], "summary": "Applying the softmax function in training leads to indirect and unexpected supervision on features. We propose a new training objective to explicitly induce dense feature regions for locally sufficient samples to benefit adversarial robustness.", "abstract": "Previous work shows that adversarially robust generalization requires larger sample complexity, and the same dataset, e.g., CIFAR-10, which enables good standard accuracy may not suffice to train robust models. Since collecting new training data could be costly, we focus on better utilizing the given data by inducing the regions with high sample density in the feature space, which could lead to locally sufficient samples for robust learning. We first formally show that the softmax cross-entropy (SCE) loss and its variants convey inappropriate supervisory signals, which encourage the learned feature points to spread over the space sparsely in training. This inspires us to propose the Max-Mahalanobis center (MMC) loss to explicitly induce dense feature regions in order to benefit robustness. Namely, the MMC loss encourages the model to concentrate on learning ordered and compact representations, which gather around the preset optimal centers for different classes. We empirically demonstrate that applying the MMC loss can significantly improve robustness even under strong adaptive attacks, while keeping state-of-the-art accuracy on clean inputs with little extra computation compared to the SCE loss.", "keywords": ["Trustworthy Machine Learning", "Adversarial Robustness", "Training Objective", "Sample Density"]}, "meta": {"decision": "Accept (Poster)", "comment": "This paper proposes an alternative loss function, the max-mahalanobis center loss, that is claimed to improve adversarial robustness. \n\nIn terms of quality, the reviewers commented on the convincing experiments and theoretical results, and were happy to see the sample density analysis. \n\nIn terms of clarity, the reviewers commented that the paper is well-written. \n\nThe problem of adversarial robustness is relevant to the ICLR community, and the proposed approach is a novel and significant contribution in this area. \n\nThe authors have also convincingly answered the questions of the authors and even provided new theoretical and experimental results in their final upload. "}, "review": {"SJxKz6B2ir": {"type": "rebuttal", "replyto": "rJgxo3S2sr", "comment": "Thank you for the suggestion, we have uploaded a new revision to clarify this clearer at the beginning of the experiment section.", "title": "Thank you!"}, "HJg7WGbhYB": {"type": "review", "replyto": "Byg9A24tvB", "review": "[Post rebuttal: The rebuttal addresses most of my concerns. I have updated my score.]\n\nThis paper points out some limitation of the traditional softmax cross-entropy (SCE) loss, e.g., causing indirect and unexpected supervisory signals on the learned features so that the points with low loss values tend to spread over the space sparsely. To remedy this, the authors then proposes the max-mahalanobis center (MMC) loss. By analyzing the sample density, it is proved that the MMC loss has a sample density proportional to the number of data samples in each class. This means MMC loss induces higher feature densities than the SCE loss, thus is expected to be more robust under adverssarial attacks.\n\nI find the paper fairly well written in general, and the arguments are well supported by the development of the theoretical results. There are, however, several questions raised by the reviewer.\n\nOne question is that by looking at the definition (8), it seems the MMC loss essentially tries to move data from different classes apart. This seems to be quite similar to the max margin loss. I would expect the authors differentiate the differences between these two. Consequently, I would also like to see empirical comparisons between these two losses.\n\nAnother question is even if you have Theorem 2, the transfer from Theorem 2 to robustness does not seem direct, e.g., how do you guarantee when the density form in eq.9 is better than that in eq.7 for robustness?\n\nThen when looking back at the sample density definition in eq. (2). I wonder how the Vol is defined to guarantee eq.2 is a valid density function? e.g., to guarantee the integration equals to 1.\n\nIn terms of experiments, since it is claimed that the proposed loss adds little computation cost compared to the SCE loss, I think it is better to include running time comparison in the results.\n\nThe last two lines in page 8, what are unseen attacks? From the experiments, it seems that it means the PGD with different steps. I think the authors  should be careful to use the term, because some literature use the term *different attacks* to refer to attacks with different *norms*.\n\nSecond line below Table 5: it is said the MMC loss keeps state-of-the-art performance on clean data. However, by looking at Table 4, the state-of-the-art is obvious SCE. Why did you say that?\n\nOthers:\n1. S_k,\\tilde{k}^2 is undefined.\n2. How do you solve the minmax problem below eq.8? I guess you use the algorithm in Appendix B.1? Please clarify.\n", "title": "Official Blind Review #1", "rating": "6: Weak Accept", "confidence": 3}, "BygFbsH3oS": {"type": "rebuttal", "replyto": "SklLIKB3sH", "comment": "The method 'Center loss' is exactly the method of Wen et al. (2016). You can find it in, e.g., Table 1, Table 2, Table 4 and Figure 3. \n\nMMLDA is the method of Pang et al. (2018), as detailed in Remark 4.\n\nPang et al.  Max-mahalanobis linear discriminant analysis networks. ICML 2018\n\n\nSince it is almost the deadline of rebuttal, we will keep online for your further feedback, thank you!", "title": "Thank you for your feedback!"}, "HklhmVi9sS": {"type": "rebuttal", "replyto": "Sye48n16FB", "comment": "We really appreciate it!", "title": "Thank you for updating the score"}, "Sye48n16FB": {"type": "review", "replyto": "Byg9A24tvB", "review": "The paper compares between SCE loss,  large-margin Gaussian Mixture (L-GM) loss and proposes the Max-Mahalanobis center (MMC) loss as an alternative to explicitly learn more structured representations and induce high-density regions in the feature space. Overall the paper is well written, with sufficient theoretical reasoning and experiments. However, the reviewer has the following concerns and questions,\nThe theoretical analysis depends largely on the Gaussian assumption and argues that when the loss is distributed as Gaussian, it seems to be not even a fair comparison since assuming L_{MMC} is gaussian is totally different from assuming L_{g-SCE} is Gaussian. Also in practice it is hard to justify whether certain loss function really behaves like a Gaussian distribution, which makes the application of the theorem more limited. In fact, if the samples are concentrated (which can be common in practice), is the proposed method still able to induce high density sample region?\nThe experiments give very competitive results for MMC loss. It would also be interesting to see if implementing other defenses or do an adversarial training would still make MMC loss much better than other loss (at least from the AT example, it seems that MMC does not perform uniformly better than SCE as before).\nAre the experiment results sensitive to the choice of parameters C_MM and L?\n\nI have read the author responses and I think they are quite solid. I have updated my score. \n", "title": "Official Blind Review #3", "rating": "6: Weak Accept", "confidence": 2}, "BJlhtpUciS": {"type": "rebuttal", "replyto": "r1xg2e3YsS", "comment": "Thank you! We really appreciate the support and approval.", "title": "Thank you!"}, "ByeZZ-gc5B": {"type": "review", "replyto": "Byg9A24tvB", "review": "This paper proposes an alternative loss function for classification models that they claim leads to improved adversarial robustness even under strong adaptive attacks. It also attempts to analyze how the softmax cross-entropy loss discourages robustness by considering the problem in terms of local density in the pre-logit feature space.\n\nAlthough as an emergency reviewer I haven't had time for a thorough verification, the overall idea seems sound, as do their theoretical and experimental results. I appreciate the careful analysis of the sample densities induced by each method; the N/L^2 vs. N/L result is especially nice. They also seem to follow best practices for evaluating adversarial defenses. Overall I do feel like the research topic of developing alternate loss functions and identifying pathologies with current popular loss functions is important and maybe insufficiently studied / publicized, so I think publishing this paper would be helpful for the field.\n\nA few questions:\n(1) If the MMC loss makes your final models so much more robust to small perturbations, why is there still such a large clean accuracy drop when combining your method with adversarial training in Figure 3a? I would have hoped that the tradeoff would have been less extreme. If you started adversarial training midway through the training process, or used a smaller perturbation size, would the tradeoff still be as large as with SCE models?\n(2) It makes sense that the optimal method of choosing MM centers would be to place them at the vertices of simplexes when #dims = #classes, but if there was some other way of avoiding the degradation problem from Wen et al. 2016, would it ever make sense (especially when #dims < #classes) to allow some automatic slackening of the MM centers (i.e. allow them to move from their original positions, but at a heavy cost), in order to permit classes that are similar (e.g. different breeds of imagenet dogs) to cluster more closely together, or perhaps to allow for classes with different levels of dispersion? Something feels suboptimal about forcing class centers to be equidistant and identical. This isn't intended as a major criticism but it might be an interesting direction for future work.", "title": "Official Blind Review #4", "rating": "8: Accept", "confidence": 3}, "Bkla0uKUjB": {"type": "rebuttal", "replyto": "Byg9A24tvB", "comment": "Dear Reviewers,\n\nThank you again for your valuable comments and suggestions, which are really helpful for us. We have uploaded new revisions and posted responses to the proposed concerns and questions.\n\nWe totally understand that this is a quite busy period of time, since the reviewers may be preparing the rebuttal for their own submissions or rushing for the deadline of the recent conferences.\n\nSo we deeply appreciate it if the reviewers can take some time to return further feedbacks on whether our responses and extra experiment results solve their concerns. If there is any other question, we will try our best to provide satisfactory answers. \n\nBest,\nThe authors\n", "title": "Looking forward to further feedbacks"}, "SJgdKWYIjB": {"type": "rebuttal", "replyto": "HJxtbjQUcS", "comment": "We have uploaded a newer revision, which includes the ablation study in Table 1 and described in Section 4.3.\n\nTo investigate the effect on robustness induced by high sample density in MMC, we substitute uniformly sampled center set $\\mu^{r}=\\{\\mu_{l}^{r}\\}_{l\\in[L]}$ for the MM center set $\\mu^{*}$, and name the resulted method as \"MMC-10 (rand)\". There is also $\\|\\mu_{l}^{r}\\|_{2}=C_{\\text{MM}}$, but $\\mu^{r}$ is no longer the solution of the min-max problem in Section 3.3.\n\nFrom the results in Table 1, we can see that higher sample density alone in \"MMC-10 (rand)\" can already lead to much better robustness than other baseline methods even under the adaptive attacks, while using the optimal center set $\\mu^*$ as in \"MMC-10\" can further improve performance.", "title": "Update on ablation study experiments"}, "HJeCDtiksr": {"type": "rebuttal", "replyto": "Sye48n16FB", "comment": "Thank you for your valuable review.\n\nQuestion 1. Gaussian assumption:\nWe upload a revision, where we remove the Gaussian assumption in Theorem 1 and  Theorem 2 to get a more general form. In experiments, we find that $p_{k}(c)$ in MMC has much higher probability nearby the loss $c=0$, comparted to $p_{k,\\tilde{k}}(c)$ in SCE, which further leads to higher sample density beyond the theoretical analyses.\n\nBesides, when we analyze the conclusions of Theorem 1 and Theorem 2 in the original version, we also do not depend on any of the Gaussian parameters like $C_{k}$ / $C_{k,\\tilde{k}}$, $S_{k}$ / $S_{k,\\tilde{k}}$ or even the Gaussian density function $\\varphi(x)$. We demonstrate the superiority of MMC over SCE based on the comparison between $N_{k}$ and $N_{k,\\tilde{k}}$, and the denominator terms in Eq. (7) and Eq. (9) that are independent of the Gaussian assumption.\n \nActually, the only use of the Gaussian assumption is to make the representation of sample density more specific in Theorem 1 and Theorem 2. This assumption can be removed to obtain a more generalized formula of sample density without changing our analyses and conclusions, just as shown in the revision.\n \n\nQuestion 2: Results on AT:\nThe improvement of combining MMC with AT is mainly in the cases when models are evaded by the attacks different from those used in training. For example, in Table 1, MMC + AT (tar) can have 45.1% accuracy under PGD-50 (un, $\\epsilon=16/255$) attack, while SCE + AT (tar) can only have 16.0% accuracy.\n \n\nQuestion 3: Sensitivity to the choice of $C_{\\text{MM}}$ and $L$:\nWe have done the experiments of $C_{\\text{MM}}=100$ and compare it with the results of MMC-10 in Table 1, as shown below:\n \n   Method ||Clean || P-10(tar) | P-10(un) | P-50(tar) | P-50(un) || P-10(tar) | P-10(un) | P-50(tar) | P-50(un) ||\nMMC-10  || 92.7 || 48.7 | 36.0 | 26.6 | 24.8 || 36.1 | 25.2 | 13.4 | 17.5 ||\nMMC-100 || 92.8 || 48.4 | 35.6 | 26.4 | 24.3 || 35.8 | 25.0 | 13.1 | 17.3 ||\n \nWe can see that MMC-100 has similar performance as MMC-10. In Table 4 and Table 5, we show the effectiveness of our method on CIFAR-100, where $L=100$. So the performance of MMC loss is relatively not sensitive to the choice of $C_{\\text{MM}}$ and $L$.\n", "title": "Thank you for your valuable review"}, "rkxNi5sysB": {"type": "rebuttal", "replyto": "HJg7WGbhYB", "comment": "Thank you for your valuable review.\n\nQuestion 1: Difference between max-margin loss and MMC:\nGenerally, MMC loss can encourage intra-class compact (higher sample density) in training, while keeping inter-class dispersion by the MM centers. In comparison, max-margin loss like SVM can only induce inter-class dispersion. Besides, as shown in our experiments and other empirical results (https://github.com/adversarial-robustness-benchmark/adversarial-robustness-benchmark ), only inducing inter-class large margin like MMLDA, L-GM or DeepDefense [1] cannot provide reliable robustness under adaptive attacks.\n \n[1] Yan et al. Deep defense: Training dnns with improved adversarial robustness. NeurIPS 2018.\n \n \nQuestion 2: About the conclusion in Theorem 2:\nWe do not intend to claim that higher sample density is a sufficient condition for robustness. Instead, as indicated by Schmidt et al. (2018), having enough samples is generally a necessary condition to train robust models, both globally (sample complexity) and locally (sample density). So the density form in Eq. (9) is better than Eq. (7) indicates that MMC loss can better achieve the necessary condition for robust learning, given a fixed amount of training data. Then in our experiments, we further empirically verify that the higher density induced by MMC can indeed lead to better robustness.\n \n\nQuestion 3: Definition of sample density:\nThe sample density in Eq. (2) denotes 'number of training samples per unit volume', so the integration over whole space is the number of training samples in the dataset $D$, i.e., $N=|D|$. This can be formally denoted as $\\int \\text{SD}\\cdot d V=\\int d N=N$.\n\n \nQuestion 4: Computational cost of MMC:\nWe perform our experiments on a single NVIDIA Tesla P100 GPU. Both SCE and MMC are trained by 200 epochs, as shown in Figure 3(a). The training time per epoch is\n                                 SCE         MMC\nResnet-32   ||  48~51s   ||  49~51s   ||\nResnet-110  || 189~211s || 192~214s  ||\n \nBesides, we indeed use the algorithm in Appendix B.1 to solve the min-max problem Eq.(8), we will make this clearer in the revision. We implement the algorithm in Matlab code, and it takes less than one second to craft the MM centers used in this paper.\n \n\nQuestion 5: About the terms:\nThank you for pointing out. We use PGD-10 with $\\epsilon=8/255$ in AT, so the 'unseen attacks' refer to those with different steps (e.g., PGD-50) or different norms (e.g., $\\epsilon=16/255$) as shown in Table 1. \n\nWe upload a revision, the modifications include:\n1. We change the claim of 'state of the art' to 'comparable' to avoid an overclaim as you suggested;\n\n2. We remove the term 'unseen attacks' and directly refer to the attacks different from those used in AT;\n\n3. We clarify the algorithm used to solve the minmax problem below Eq.(8);\n\n4. We remove the Gaussian assumption in Theorem 1 and  Theorem 2 to get a more general form.\n", "title": "Thank you for your valuable review"}, "BJgACOjJiS": {"type": "rebuttal", "replyto": "HJxtbjQUcS", "comment": "Thank you for the supportive review.\n\nWe upload a revision which includes discussion on related angular margin-based softmax (AMS) losses in Appendix B.5 (due to limited space in the main text). We highlight the two main differences between MMC and AMS  losses below:\n\nDifference one: The inter-class margin\n\nThe AMS losses induce the inter-class margins mainly by encouraging the intra-class compactness, while the weights are not explicitly forced to have large margins.\n\nThe MMC loss simultaneously fixes the class centers to be optimally dispersed and encourages the intra-class distribution to be compact. Note that both of the two mechanisms can induce inter-class margins, which can finally lead to larger inter-class margins compared to the AMS losses.\n\n\nDifference two: The normalization\n\nThe AMS losses use both weight normalization (WN) and feature normalization (FN) to exploit the angular metric, which makes the normalized features distribute on hyperspheres. The good properties of the AMS losses are at the cost of abandoning the radial degree of freedom, which may reduce the capability of models.\n\nIn the MMC loss, there is only WN on the class centers, i.e., $\\|\\mu_{y}^*\\|=C_{\\text{MM}}$, and we leave the degree of freedom in the radial direction for the features to keep model capacity. However, note that the MMC loss $\\|z-\\mu_{y}^*\\|_{2}^2\\geq (\\|z\\|_{2}-C_{\\text{MM}})^2$ is a natural penalty term on the feature norm, which encourage $\\|z\\|_{2}$ to not be far from $C_{\\text{MM}}$. This prevents models from increasing feature norms for easy examples and ignoring hard examples, just similar to the effect caused by FN but more flexible.\n\n\nAs to the class centers, an ablation study on uniformly centers is a good suggestion. We will check the mentioned work and conduct some necessary experiments.", "title": "Thank you for the supportive review"}, "SklH2OoksS": {"type": "rebuttal", "replyto": "ByeZZ-gc5B", "comment": "Thank you for the supportive review.\n\nQuestion 1. The tradeoff between clean and adversarial accuracy:\nThank you for the insightful suggestions, which are enlightening for us. We will try these techniques to improve the tradeoff.\n \n\nQuestion 2. More flexible variants:\nActually, we have proposed two flexible variants of MMC loss in Appendix B.3. One is called elastic Max-Mahalanobis center (EMC) loss, which regards MMC centers as a prior and adds a penalty term to slacken the real position of centers, just as you suggested. Another one is called hierarchical Max-Mahalanobis (HM) loss, which uses a hierarchical center set to deal with the more complicated datasets.", "title": "Thank you for the supportive review"}, "HJxtbjQUcS": {"type": "review", "replyto": "Byg9A24tvB", "review": "This paper first shows some potential issues of softmax loss (i.e., cross-entropy loss with softmax function) and then propose the Max-Mahalanobis center (MMC) loss to encourge the intra-class compactness for better adversarial robustness.\n\nThe MMC loss is essentially minimizing the distance between the feature and the pre-fixed class center. Different from center loss, these centers are determined by minimizing the maximum inner product between any two class centers. Since the norm of these class centers are normalized to a constant. It is equivalent to angles. This acutally reminds me of a number of works in angular margin-based softmax loss. Just to name a few:\n\n[1] Large-Margin Softmax Loss for Convolutional Neural Networks, ICML 2016\n[2] SphereFace: Deep Hypersphere Embedding for Face Recognition, CVPR 2017\n[3] Soft-margin softmax for deep classification, ICNIP 2017\n[4] CosFace: Large Margin Cosine Loss for Deep Face Recognition, CVPR 2018\n[5] ArcFace: Additive Angular Margin Loss for Deep Face Recognition, CVPR 2019\n\nI think these works are closely related to what the authors aim to do, and therefore they should be discussed methodologically and compared empirically.\n\nBesides that, I think it is also worth conducting an ablation study for how to determine these class centers. This paper considers to minimize the maximum inner product. There are a few papers listed below that explicitly discusses how to make the class centers uniformly spaced. The authors may consider to compare these methods for determining the class centers. \n\n[1] Learning towards Minimum Hyperspherical Energy, NeurIPS 2018 \n[2] UniformFace: Learning Deep Equidistributed Representation for Face Recognition, CVPR 2019\n\nFor the experiments, the MMC loss indeed shows some advantages over the softmax loss. I am basically convinced by the experiments, although it can further strengthen the paper if the authors can conduct some evaluations on large-scale datasets like ImageNet.\n\nI appreciate the authors provide many theoretical justifications, which is inspiring. Intuitively speaking, I can understand that shrinking the feature space (i.e., make feature distribution more compact) can improve the adversarial robustness. As a result, I think this paper is naturally motivated and is also theoretically sound. The experiments can be further improved.", "title": "Official Blind Review #2", "rating": "6: Weak Accept", "confidence": 2}}}