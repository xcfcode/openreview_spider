{"paper": {"title": "Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by Enabling Input-Adaptive Inference", "authors": ["Ting-Kuei Hu", "Tianlong Chen", "Haotao Wang", "Zhangyang Wang"], "authorids": ["tkhu@tamu.edu", "wiwjp619@tamu.edu", "htwang@tamu.edu", "atlaswang@tamu.edu"], "summary": "Is it possible to co-design model accuracy, robustness and efficiency to achieve their triple wins? Yes!", "abstract": "Deep networks were recently suggested to face the odds between accuracy (on clean natural images) and robustness (on adversarially perturbed images) (Tsipras et al., 2019). Such a dilemma is shown to be rooted in the inherently higher sample complexity (Schmidt et al., 2018) and/or model capacity (Nakkiran, 2019), for learning a high-accuracy and robust classifier. In view of that, give a classification task, growing the model capacity appears to help draw a win-win between accuracy and robustness, yet at the expense of model size and latency, therefore posing challenges for resource-constrained applications. Is it possible to co-design model accuracy, robustness and efficiency to achieve their triple wins? This paper studies multi-exit networks associated with input-adaptive efficient inference, showing their strong promise in achieving a \u201csweet point\" in co-optimizing model accuracy, robustness, and efficiency. Our proposed solution, dubbed Robust Dynamic Inference Networks (RDI-Nets), allows for each input (either clean or adversarial) to adaptively choose one of the multiple output layers (early branches or the final one) to output its prediction. That multi-loss adaptivity adds new variations and flexibility to adversarial attacks and defenses, on which we present a systematical investigation. We show experimentally that by equipping existing backbones with such robust adaptive inference, the resulting RDI-Nets can achieve better accuracy and robustness, yet with over 30% computational savings, compared to the defended original models.\n", "keywords": ["adversarial robustness", "efficient inference"]}, "meta": {"decision": "Accept (Poster)", "comment": "The authors develop a novel technique to train networks to be robust and accurate while still being efficient to train and evaluate. The authors propose \"Robust Dynamic Inference Networks\" that allows inputs to be adaptively routed to one of several output channels and thereby adjust the inference time used for any given input. They show \n\nThe line of investigation initiated by authors is very interesting and should open up a new set of research questions in the adversarial training literature.\n\nThe reviewers were in consensus on the quality of the paper and voted in favor of acceptance. One of the reviewers had concerns about the evaluation in the paper, in particular about whether carefully crafted attacks could break the networks studied by the authors. However, the authors performed additional experiments and revised the paper to address this concern to the satisfaction of the reviewer.\n\nOverall, the paper contains interesting contributions and should be accepted."}, "review": {"Skgy0H6woH": {"type": "rebuttal", "replyto": "ryeFuGK1qH", "comment": "\nWe sincerely appreciate your positive opinion and insightful suggestions about our work. \n\nRegarding the role of \"increasing capacity\", we draw the conclusions from the theoretical analysis in (Tsipras et al. (2019), Nakkiran (2019), which are aligned with our current observations in experiments. That said, those works present more a high-level motivation than any actual algorithmic foundation, for our work.\n", "title": "Response to Reviewer#2"}, "Bke0kZ6vjB": {"type": "rebuttal", "replyto": "HJgVmFG6qH", "comment": "\nQ1:  Paper organization and writing style.\nThank you very much for your suggestion. We have revised the paper in an effort to improve its clarity and reader friendliness:\n\n-\tWe have collected the two discussion paragraphs: \"Intuition: Multi-Output Networks as Special Ensembles\" and \"Do Triple Wins Go Against the Model Capacity Needs?\", into one dedicated section \"Discussion and Analysis\" after Section 4. We hope that resolves the current impression \"the entire paper reads constantly like a literature review\".\n-\tWe also re-organized Section 3, to first provide an overview of RDI-Nets, followed by discussing concrete attack and defense forms. \n\nWe are more than happy to take any further suggestions to revise this manuscript. \n\nQ2:  Directly attack the decision function.\nWe appreciate this insightful and important comment. We conduct the requested evaluation and see our strongest defense (Max-Average) still perform effectively under the new attack. \nThe decision function of the multi-exit network for an input example is the single exit loss function through which that specific example is actually routed. In view of that, we implemented this \"direct decision attack\", by every time computing the adversarial perturbations w.r.t. the actual single exit. The resulting new attack thus can be viewed as an input-adaptive selection version of single attacks. On RDI-ResNet38 with Max-Average defense, the result is:\n------------------------------------\nATA        TA                MFlops\n43.70%   83.31%        64.82\n------------------------------------\nClearly, this new form of attack is indeed considered more challenging by RDI-Nets, as more examples are now routed to higher-level exits for more scrutiny. It leads to the improved averaged inference cost (~10 MFlops higher than the max-average attack in Table 3), a model behavior aligned with our expectation. \nDespite so, for this new attack, the ATA of our RDI-Net is 1.41% higher than the original ResNet-38 (Table 1) and the TA is comparable (0.30% lower), with 18.3% computational savings on average. Thus it still achieves our aimed \"triple wins\", though understandably with fewer margins, under this new stronger attack. \nWe would like to thank you again for bringing up this new attack possibility. We would be more than happy to include the above discussions, and possibly more results into our paper if you are in favor of so. We also tried another suggested randomized attack and report the results in the response to Reviewer #1.\n\nQ3:  About minor comments.\nWe appreciate your careful proofreading and have revised the paper accordingly.\n", "title": "Response to Reviewer#3"}, "H1lCVUpwir": {"type": "rebuttal", "replyto": "HyxN_BoaFr", "comment": "\nQ1. About highlighting our contribution\n\nYou are precisely correct.  We reduce the average computation loads by input-adaptive routing to achieve \"triple wins\", rather than proposing a specific design of robust light-weight models. We have highlighted the difference in the revised paper (Section 3 beginning).\n\nQ2: More diverse attack forms.\nWe appreciate your insightful suggestion. As you suggested, we create the new \"randomized attack\": that attack will randomly combine the multi-exit losses, where the weight coefficients are i.i.d. sampled from Gaussians and then normalized to have their sum equal one. On our strongest defended model of RDI-Resnet38 (using Max-Average), it achieves TA = 83.79%, ATA = 44.86%, with 28.88% MFlops saving.\n\nWe also tried a direct attack on the decision function and report the results in the response to Reviewer #3. \n\nQ3: Closer comparison with ATMC\t\nWe communicated with the ATMC authors and obtained their original implementation, to train a new model whose number of flops is much closer (to the extent possible) to our RDI-ResNet38. The results below demonstrate that ours outperforms ATMC in this setting. We have confirmed the results with ATMC authors.\n------------------------------------\nModel    ATA        TA                  MFlops\nATMC     42.66%  83.51%        58.03\nOurs      43.32%   83.79%         57.81  \n------------------------------------\n\nQ4: Missing citation.\nWe appreciate your suggestion and have cited it. \n", "title": "Response to Reviewer#1"}, "HyxN_BoaFr": {"type": "review", "replyto": "rJgzzJHtDB", "review": "The paper exploited input-adaptive multiple early-exits, an idea drawn from the efficient CNN inference, to the field of adversarial attack and defense. It is well-motivated by the dilemma between the large model capacity required by accurate and robust classification, and the resulting model complexity as well as inference latency. \n\nOverall, this paper presents an interesting perspective, with strong results. The usage of input-adaptive inference reduces the average inference complexity, without conflicting the \"larger capacity\" assumption for co-winning robustness and accuracy. \n\nSince no literature has discussed the attacks for a multi-exit network, the authors constructed three attack forms, and then utilized adversarial training to defend correspondingly. The design of Max-Average Attack is particularly smart - to balance between \"benefiting all\" and \"maximally boosting one\" (its result is also convincingly good).\n\nThe authors presented three groups of experiments, from relatively heavy networks (ResNet38), to very compact ones (MobileNet-V2). It is especially meaningful to see their strategy work on MobileNet too (though the computational saving is a bit less, no surprise). The authors also did due diligence in ablation study and comparing with recent alternatives.\n\nSeveral points that could be addressed to potentially improve the paper:\n\n- The authors want to make it clearer that: their \"triple win\" is not about constructing a light-weight model that is both accurate and robust. It's instead about given an accurate + robust, yet heavy-weight model, how to reduce its AVERAGE computational load per sample inference, by routing \"easier\" examples to earlier exits. \n\n- Can the authors think of and construct more diverse and stronger attacks for RDI-Nets? For example, it would be interesting to attacking RDI-Nets (e.g., defended by Max-Average) with randomized weighted combinations of single attacks? \n\nNote that, at inference time, the same \"randomized combination\" cannot be also adopted as defense, because an input always wants to exit the earliest possible for efficiency gains.\n\n- The advantage over ATMC is not obvious: slightly lower TA, slightly higher ATA, and slightly more parameters. Could the authors try to align their parameters more closely (to the extent possible)?\n\n- A missing related work: \"Shallow-Deep Networks: Understanding and Mitigating Network Overthinking\", ICML 2019. It also discussed how to append early exits to pre-trained backbones.\n\n\n", "title": "Official Blind Review #1", "rating": "8: Accept", "confidence": 3}, "ryeFuGK1qH": {"type": "review", "replyto": "rJgzzJHtDB", "review": "This paper considers the following problem: in a classification setting, it appears that by increasing the model capacity, the model accuracy and robustness seem to be improved, at the expense of model size and latency. Thus, the authors want to design an approach where at the same time accuracy, robustness and efficiency are improved at the same time.\n\nTheir idea is \"multi-exit networks\" with inference that adapts based on the input. Particularly, their proposed \"Robust Dynamic Inference Networks\" allows each input  -- clean or adversarial -- to choose adaptively one of the multiple output layers to output its prediction. This way, they can do an investigation to new variations of adversarial attacks and adversarial defenses. Their experiments show that indeed via this approach, they can achieve the triple wins of accuracy, robustness, and efficiency.\n\n+ novel idea, promising results,  \n- Although I like the discussion of accuracy-robustness tradeoff in par 2 of Introduction, I am not sure about the statement that increasing model capacity both robustness and accuracy are improved, as used in the abstract, is always true.\n+ First time adversarial attacks and defenses are studied in a multi-output model. \n+ Interesting connection of multi-output networks with ensemble models.\n\nOverall, I believe that this is an interesting, novel paper, which could be of high interest in the ICLR community, and I would vote for its acceptance. ", "title": "Official Blind Review #2", "rating": "8: Accept", "confidence": 3}, "HJgVmFG6qH": {"type": "review", "replyto": "rJgzzJHtDB", "review": "This paper proposes a framework coined as \u2018Robust Dynamic Inference Networks (RDI-Nets)\u2019. The goal is concurrently achieving accuracy, robustness and efficiency via \u2018input-adaptive inference\u2019 and \u2018multi-loss flexibility\u2019  on a multi-output architecture. The observation is that \nin a deep architecture, the representations in earlier layers can also be used for solving a specific downstream classification task. So by attaching several final classification stages at the intermediate layers and by using the uncertainty of the softmax output as a decision criteria as when to use the current output as the final decision, the authors aim to achieve a triple win.\nThe paper then proposes some attack criteria for a multi-output network.\n\nThe paper is not very well written. The paper has a designated related work section but the entire paper reads from its abstract to conclusions constantly like a literature review. This makes it hard to focus and identify the original contribution. The proposed architecture is only introduced later in detail in 3.3 after the attacks. I found the organization and writing style not very reader friendly.\n\nThe authors provide a large experimental section, however the key problem with the paper is that it blurs the evaluation issue. While the observation of using uncertainty of estimates at intermediate levels has some intuitive appeal, the decision criteria that the authors propose requires careful selection of thresholds and a good calibration. But given the thresholds the final decision is just a function of the entire network - as it should be. So a natural attack here is just attacking this decision function (or an approximate differentiable proxy) to see if this model provides extra robustness. Is such an evaluation available? Otherwise the proposed approach provides a false sense of robustness as the proposed attacks are not geared towards the actual underlying model.\n\nMinor: \nThe definition of entropy in (6) is missing a minus sign. \n\nThe notation f(\\theta| x) for theta as parameters and x as input for a function is in conflict with probability notation of conditional probabilities.\n", "title": "Official Blind Review #3", "rating": "3: Weak Reject", "confidence": 2}}}