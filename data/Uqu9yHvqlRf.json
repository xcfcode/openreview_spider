{"paper": {"title": "What Preserves the Emergence of Language?", "authors": ["Ziluo Ding", "Tiejun Huang", "Zongqing Lu"], "authorids": ["~Ziluo_Ding1", "~Tiejun_Huang1", "~Zongqing_Lu2"], "summary": "", "abstract": "The emergence of language is a mystery. One dominant theory is that cooperation boosts language to emerge. However, as a means of giving out information, language seems not to be an evolutionarily stable strategy. To ensure the survival advantage of many competitors, animals are selfish in nature. From the perspective of Darwinian, if an individual can obtain a higher benefit by deceiving the other party, why not deceive? For those who are cheated, once bitten and twice shy, cooperation will no longer be a good option. As a result, motivation for communication, as well as the emergence of language would perish. Then, what preserves the emergence of language? We aim to answer this question in a brand new framework of agent community, reinforcement learning, and natural selection. Empirically, we reveal that lying indeed dispels cooperation. Even with individual resistance to lying behaviors, liars can easily defeat truth tellers and survive during natural selection. However, social resistance eventually constrains lying and makes the emergence of language possible.", "keywords": ["emergence of language", "reinforcement learning"]}, "meta": {"decision": "Reject", "comment": "The authors present a study on what maintains the stability of emerged communication protocols. To study this question the authors design experiments in bargaining communities of agents in 3 setups,  a) no punishment of restriction of liar agents b) allowing individual agents to refuse bargaining with  liar agents and c) introducing a global punishment system for liar agents.\n\nOverall the reviewers agree that the design of the study is interesting, but also point that motivation and take-home messages of this study are unclear. Having read the paper, I share the same opinion. The authors discuss on a very abstract level about the implications of this study for the field of AI, but this study is quite specific and clearly does not capture all the complexities or real societies. From the scale of results and study, I think it would be more valuable to draw some concrete proposals/implications about perhaps multi-agent modelling or environment design in general. \n\nAll in all, this is an interesting study but some more work needs to be done around research framing.\n"}, "review": {"BL7EiOyDE0x": {"type": "review", "replyto": "Uqu9yHvqlRf", "review": "**Summary:** This paper studies multi-agent communication with an aim to mimic conditions for the emergence of language in society. They argue that the emergence of language requires co-operation. However, people can cheat and make a profit by lying, and eventually, people have no incentive to co-operate. \n\nA proxy multi-agent setting is created to study this which proceeds in a series of interaction between two (randomly sampled) agents. In each interaction, there is a market demand for N items, and both agents have a fixed quantity of these items and their own hidden utility. An agent makes a proposal to another agent for a set of goods which consists of quantities of each item that they are willing to give. The other agent has to fulfil the remaining quantity to match the market demand. The other agent can accept the proposal at which point both agents get reward based on the remaining items and their respective utilities. Otherwise, the bargaining will continue and the other agent will make a proposal. There is a timeout after which both get a reward of 0.  There are certain agents who are chosen as \"liars\" who can make a proposal but refused to follow through leading to the remaining market gap being split equally.  Lying can, therefore, result in profit. A credit mechanism is also introduced to measure the performance of agents. Liars can use credit scores to decide whether to lie or not. A neural network is used to generate proposals and REINFORCE style training is performed to optimize reward. Authors also study \"natural selection\" where low-ranking agents get eliminated after a certain time, and \"genetic evolution\" where high-ranking agents produce clones.\n\nThree different settings are studied: (i) where there are no measures taken to stop liars, (ii) where each truth-teller can refuse to play with an agent with negative credit score, (iii) where global measures are taken including reward penalty for lying or liar agents being banned for a fixed time. It is found that in both (i) and (ii); liars take over society. Individual counter-measures slow down the proliferation of liars but don't stop them. However, global measures in (iii) are able to stop liars. Authors argue that global measures in human society (reciprocal altruism) is the reason why conditions were right for language to evolve.\n\n**Strength:**\n- The setting is interesting. In general, understanding the dynamics of language evolution is a very interesting topic. This can shed light on human history, and maybe potentially be helpful for developing language understanding agents. \n\n**Weakness:**\n- The language part of the story is confusing since there is no language used in the experiments. In fact, what is really being asked here is if we can have a society without cooperation? Since, if everyone ends up being a liar then we don't have a society. Therefore, the language part feels like a red-herring. \n\n- Implications of the results are unclear as it is not obvious that the setup captures all the important nuances present in human society. E.g., in a real-world, people who are speaking the truth can help each other by sharing technology that can give them a survivor edge over liars. This happens even if liars are not directly punished for their deeds. Then there is the question if the way natural selection and genetic evolution are modelled, reflect the real-world. I am not an expert on evolution but the paper doesn't say enough to justify the choice.\n\n**Questions:**\n\n- In the case where agent \"i\" lies, the other agent will still end up paying its share of the accepted proposal plus 50% of what agent \"i\" promised. Is this right? \n\n- Can one pay more items than they possess? If not, do we always have $d_n \\ge q^i_n + q^j_n$ for every $i$ and $j$, as otherwise there are not enough items to satisfy the market?\n\n- In the setting of individual resistance, once an agent ends up with a negative credit score then the truth-tellers will refuse to play with them resulting in an addition of $1 - \\sqrt{e} < 0$ to their credit score. So can an agent never increase their total reward once their credit score becomes negative? Or, perhaps liars will still play with them and so there is a chance for their total reward to increase.\n\n- How would the behaviour be if the agent also had access to (i) total reward earned by the other agent, (ii) percentage of cases the other agent lied. E.g., if an agent saw that the other agent lie then they are likely to either not play with them or demand a more lucrative offer before committing. This can allow for more interesting policies to evolve.", "title": "Interesting Setting but Implications of Results are Unclear or Speculative", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "avjqUzBqhgV": {"type": "rebuttal", "replyto": "RaJvGPYZX55", "comment": "We thank all the reviewers for their thoughtful comments and suggestions. \n\nWe have uploaded a revised version of the manuscript which addresses the concerns shared by the reviewers. In particular, we supplemented some motivations behind fundamental assumptions made in this work. In more detail, we explained what motivated us to investigate, the reasons why we disregarded linguistic change and the relationship between our work and the emergence of language. Secondly, we cleaned-up some sloppy terminology, corrected the typos, and revised Figure 3.", "title": "Summary of Response to Reviews"}, "RaJvGPYZX55": {"type": "rebuttal", "replyto": "LFgPObCwvU9", "comment": "Please let us know whether our responses have addressed your comments and concerns. Also let us know if you have further comments. We think this would greatly help us to improve the paper. ", "title": "We would like to encourage reviewer 1 and 3 to respond to our responses. "}, "NOgzNQvY2ah": {"type": "rebuttal", "replyto": "GVYCImi4TI", "comment": "For the argument that language evolves from na\u00efve communication, some works make an agreement that prior to the emergence of language some PRE-ADAPTATIONS occurred in the hominid lineage (Morten H, 2003. Language evolution: consensus and controversies). In more detail, many works argue that one candidate is the ability to use symbols. For example, (Bickerton, D, 2003. Symbol and structure: a comprehensive framework for language evolution.) in the evolution of our species, the symbolism may have preceded syntax by as much as two million ago, besides, three features (modality, symbolism, and structure) of language evolved separately. (Iain Davidson, 2003. The Archaeological Evidence of Language Origins: States of Art; Deacon, 2003. Universal grammar and semiotic constraints.) also stress the work of understanding the relations between the earliest communication using symbols and the final stage of the evolutionary emergence of language.  \n\nAs (Deacon, 1997. The Symbolic Species-The Co-Evolution of Language and the Brain) points out, if we are interested in the origin of language, we need to understand the emergence of symbolic signals (na\u00efve communication). Based on all these arguments, our investigating na\u00efve communication protocol uses symbols to transmit meaning based on a social convention or implicit agreement.    \n\nAccording to (Li and Hombert, 2002. On the evolutionary origin of language; Giv\u00f3n, 2002. The evolution of language out of pre-language.), there is a criterion separating pre-language communication from post-language communication in hominid evolution is the difference between linguistic change and the evolutionary change of communication in the animal kingdom. The pre-language communicative behavior of hominids, like animal communicative behavior, was subject to the constraints of Darwinian evolution. Those hominids who made the change achieved a higher level of fitness than those hominids who failed to make the change. While linguistic change, which began in the post-language communicative era of hominid evolution, however, is by and large tied to society and culture. Thus, we disregard the factors related to linguistic change since we are investigating pre-language communication in hominid evolution. \n\nAs for lying, vervets\u2019 lying is just one example to illustrate language is not the prerequisite of lying since no animal signaling system is like natural language. Nobody can ever find evidence about whether hominid would lie or not. However, there is no doubt human is more intelligent than other animals. Since so many animals show lying behaviors (Whiten, A. & Byrne, R. W., 1988. Tactical deception in primates; W Abberley, 2015. Animal Cunning: Deceptive Nature and Truthful Science in Charles Kingsley's Natural Theology), we believe it is a reasonable assumption that lying is possible at the early stage of hominid evolution.\n\nAll in all, we argue that lying is possible in pre-language communication from which language evolved, and we are investigating what resists lying from undermining the motivation of communication using symbols.\n\n\\>>>Is there a reason to use a discrete dynamic over a continuous one?\n\nIf you are referring to why choosing K tournaments instead of one tournament before natural selection:\nCredit is meaningless when there is only one tournament since it varies based on the profits obtained from previous tournaments. In addition, global lying behavior only makes sense when the number tournament is large since the agent tells lies not only about details but also relevant to the global situation. \n\nIf you are referring to why choosing K tournaments, not some continuous setting: \nSince we use playing games representing the competitions, corresponding one game with one discrete step is reasonable. The discrete step also allows us to apply reinforcement learning (dealing with problems in Markov decision processes) investigating how global lying deals with the credit mechanism in the second setting.\n", "title": "Reply to AnonReviewer 4 "}, "LFgPObCwvU9": {"type": "rebuttal", "replyto": "Uqu9yHvqlRf", "comment": "We look forward to fully discussing the comments and concerns of the reviewers. Hope they could fully understand the merits of the paper.  ", "title": "We have posted the responses to each reviewer and we will continuously address any further comments. "}, "uybzeSW9vp": {"type": "rebuttal", "replyto": "RstOOu5fQ4n", "comment": "\\>>> Much of the motivation of this paper relies on the argument that there are strategies that functionally dominate cooperation.\n\nTransmittability, compositionality, learnability, grammatical and semantic categories, and many other properties make the human language unique among natural communication systems. However, human languages, like species, evolve over time. As a complex communication system, language should evolve from an immature communication system at an early stage. This is the period we want to investigate when na\u00efve communication protocol, not necessarily possessing the properties owned by language (e.g. cryptophasia created by twins is not culturally transmitted), was just created and used by agents in a community. The main reason is that lying behavior should emerge once communication is feasible since some species (e.g., vervet monkey) have proved to express lying behavior in their daily life. Thus, we disregard other factors, such as transmissibility, since these properties do not contradict the conclusion we obtained. As for neutral models, it is defined to indicate how languages can change at the level of linguistic variants (Reali & Griffiths, 2011. Words as alleles: connecting language evolution with Bayesian learners to models of genetic drift). However, we are investigating the motivation of communication, which is the prerequisite of further evolution. As for motivation, we need to figure out whether communication can bring enough benefits since communication itself incurs additional resources. We are not investigating the distribution of word frequencies or the relationship between word frequencies and other factors. \n\n\\>>> The claim that \"[...] in order to ensure the survival advantage of many competitors, animals are selfish in nature\" flies in the face of the whole line of research on animal alarm calls.\n\nFirst of all, as illustrated in (Zuberbuehler 2009, \"Survivor Signals: The Biology and Psychology of Animal Alarm Calling\"), alarm call is beneficial to a signaler if it increases the reproductive success since receivers prefer individuals as mating partners that are more willing to produce risky alarm calls in the presence of predators. Also, alarm signal is possible to trigger a subsequent group effort to get rid of the predator, then this behavior is profitable since it decreases the vulnerability of the signaler. All in all, parts of hypotheses about the presence of alarm calls are based on the assumption it is beneficial to the signaler, not to others. Therefore, our argument indeed does not fly in the face of the whole line of research on animal alarm calls since animal may do it for its own survival. Moreover, the existence of social animals does not mean animals are selfless facing the conflict of interests. \n\n\\>>> Is there a reason to use a discrete dynamic over a continuous one?\n\nWe use discrete symbols over continuous ones to communicate since it can be easily interpreted and analyzed. And most animals communicate with discrete signals. \n\n\\>>> Why use a multi-round bargaining game to model language evolution by contrast to, say, an established signaling game-style setup with conflict of interests?\n\nIf we modify an established signaling game-style setup with conflict of interests, such as one\u2019s goal is to signal others to a wrong direction and gain the reward, we do not see any motivation for the receiver to communicate in the first place. On the contrary, we have shown that agents can cooperate with a conflict of interest in the bargaining game.\n\n\\>>> How is the \"credit mechanism\" and the \"market\" motivated/grounded in light of this being an investigation about language emergence?\n\nIn short, the credit mechanism means the agent begins to realize that others would also tell lies, which is one step in the evolution process. Because no consensus is reached in the community and there is no external authority, the individual has no choice but resists this behavior on its own. \n\nAs for market, it is just used in the bargaining game for a better understanding of how the game works. The core idea is to design a non-cooperative game with conflict of interests. We believe the non-cooperative game is extremely common in real-world and can be a representative setting. \n\n", "title": "Reply to AnonReviewer 4"}, "oSyqxEYRW8": {"type": "rebuttal", "replyto": "BL7EiOyDE0x", "comment": "\\>>>The language part of the story is confusing since there is no language used in the experiments. In fact, what is really being asked here is if we can have a society without cooperation? Since, if everyone ends up being a liar then we don't have a society. Therefore, the language part feels like a red-herring.\n\nWe argue that the emergence of language is a process of continuous improvement, in other words, we have simpler communication protocol, such as transmitting a few symbols representing proposals, at the very early stage. And it cannot be considered as language. Then communication protocol has continuously improved more and more sophisticatedly and language is finally possible. Besides, lying behavior is possible immediately when agents are capable of communicating with each other. Therefore, what we want to express is: agents somehow master a na\u00efve communication protocol at a first stage, then once lying behavior appears in the community, it is unlikely to further develop a more sophisticated communication protocol among agents since lying undermines the motivation of cooperation as well as communication. \n\n\\>>> Implications of the results are unclear as it is not obvious that the setup captures all the important nuances present in human society\u2026\n \nIn the second experiment settings, it is worth noting we are investigating a community that is at the early stage and extremely unstable. The agents do not have enough cognition to understand obligatory reciprocal altruism, on the contrary, they are rather short-sighted driven by selfish nature. Sharing information is an altruistic act and should not occur according to standard darwinian theory (Ib Ulbaek, 1998. The origin of language and cognition). Evolution demands that we enhance our fitness, not others. And the question arises, why should agents help others without any profits? \n\nIn the third setting where obligatory reciprocal altruism has been evolved, social pressure dominates since it influences agents more severely and regulates agents more effectively than other factors (including sharing information) due to its mandatory. \n\nSurvival of the fittest is a way of describing the mechanism of natural selection originated from darwinian evolutionary theory. Our evolution mechanism obeys this core thought. Therefore, the weakest agent does not have offspring while the strongest agent has more offspring than other agents. \n\n\\>>> In the case where agent \"i\" lies\u2026\n\nYes, the market will evenly and compulsorily collect the missing from both parties. Such a setting could mimic the scenario where lying can benefit oneself and damage the other party.\n\n\\>>> Can one pay for more items than they possess? \n\nIt is not allowed to pay for more items than they possess. Therefore, we always have $d_n \\leq q_n^i + q_n^j$. \n\n\\>>> In the setting of individual resistance\u2026\n\nThe liar with all negative credit scores to all the truth tellers would have no chance to play games with them. However, its reward could still increase since it can play with other liars. \n\n\\>>> How would the behavior be if the agent also had access to\u2026 \n\nThe main difference between individual pressure and social pressure is that social organizations have the right to access more information than the individual therefore it can influence liars more precisely. It is unrealistic for agents to have a God-like view to know others\u2019 information. Besides, as we mentioned before, agents may not have the intention or motivation to share information with others. How to gradually evolve from individual pressure to social pressure is not the focus of this paper, but will be investigated in future work. \n\n\n", "title": "Reply to AnonReviewer 3"}, "SgfiVbK1SH": {"type": "rebuttal", "replyto": "a0iw7YBEPt1", "comment": "\\>>> My main worry about the paper is that the conceptual motivation is a bit unclear\u2026\n\nLanguage is a structured system of communication. However, just as Rome was not built in a day, language evolved from na\u00efve communication. But lying behaviors emerge as long as communication is possible. As normally assumed, once a na\u00efve communication protocol has been created, it is more convenient and efficient for agents to cooperate and gain more profits, thus they have more intention and motivation to develop a more complex communication protocol. However, what if, at this stage, some agents happen to learn how to lie? We have shown that, once lying behavior appears, liars would be dominant in the community, leading to less need and motivation for cooperation. In addition, the motivation for communication would also perish. Therefore, in our setting it is unnecessary to investigate the change of protocol itself, not to mention, existing na\u00efve communication protocol may also die out according to Lamarckism. In our settings, the na\u00efve communication protocol mentioned above is transmitting a few symbols representing proposals. \n\n\\>>> choice to not do simultaneous proposals\u2026 \n\nSince first-mover has been mitigated by the strategy in (Cao, ICLR 2018. EMERGENT COMMUNICATION THROUGH NEGOTIATION), there should be no difference between these two kinds of non-cooperative games. Moreover, empirically agents cannot make use of communication to obtain extra profits in the simultaneous setting. In more detail, one party does not know what the other would offer, which incurs additional mistrust. Therefore, their proposal would be more conservative by giving an evenly dividing proposal. Then communication is useless since nothing valuable can be inferred.  \n\n\\>>> Natural selection mechanism\n\nIn our setting, the number of offspring is not proportional to fitness, but it still follows the core principle. We deterministically remove the offspring of the weakest agent and add one more offspring for the strongest agent. The main purpose is to accelerate evolution.   \n  \n\n\\>>> The y-axis in the main results are \"average scaled reward\"\u2026 \n\nThe scaled reward is the rewards normalized by the maximum reward achievable for each agent, and scaled reward shows the relationship with the optimal strategy of each agent. We did experiments about random policy and the result shows it is around 0.5, which is similar to the evenly dividing strategy. \n.  \n\\>>> \"As the natural selection approaches, there is less and less need to pretend for liars ...\"\n\nAfter 10 tournaments, natural selection happens. As natural selection approaches, it means they are retiring from the stage of history. Therefore, if the liar still has credits, it is desired to use them to get more profits before natural selection, otherwise, it would be wasteful. \n", "title": "Reply to AnonReviewer 1"}, "RstOOu5fQ4n": {"type": "review", "replyto": "Uqu9yHvqlRf", "review": "##### Summary ##### \nThis paper investigates conditions under which communities of cooperative agents are stable. Communities in multi-round bargaining games with evolutionary dynamics are evaluated in three main setups. The first imposes no restrictions on the agents' behavior and is shown to be easily invaded by deceitful agents. The second enables agents to refuse to bargain with deceitful agents. Nevertheless, such communities are shown to be invadable. Finally, in the third setup, a global punishment system is shown to be able to drive out deceitful invaders. The main take-home message is that, when lying is an option, agents(' communities) need to be prepared for it.  \n\n##### Reasons for score #####\nI vote for rejecting this submission. The main reason, further detailed in \"Cons\" below, is that I am not convinced that the problem this manuscript addresses is not an artifact of the rather strong assumption of selfish individuals and communities driven solely by functional pressure. I agree with the authors that we need to start looking at more naturalistic setups (e.g., communities instead of two-player games). However, this also relates to the evolutionary dynamics we take into consideration, and to a careful motivation of the setups we analyze.     \n\n##### Pros #####\n\n+ Language emergence is a topic that has drawn renewed interest from multiple disciplines. Studying the conditions under which agents' acquired behaviors are (not) stable in a dynamic setting is important to understand their underpinning.\n+ The setups are well explained and easy to follow   \n\n##### Cons ######\n- Much of the motivation of this paper relies on the argument that there are strategies that functionally dominate cooperation. However, the view that functional pressure is all there is to evolution is rather outdated. If the authors wish to stick to this line of argumentation, I encourage them to give strong arguments for why we should disregard other factors, such as transmittability/acquisition (e.g., Kirby et al. 2015, \"Compression and Communication in the Cultural Evolution of Linguistic Structure\", or Brochhagen et al. 2018, \"Coevolution of Lexical Meaning and Pragmatic Use\") or neutral models (e.g., Reali & Griffiths 2011, \"Words as alleles: connecting language evolution with Bayesian learners to models of genetic drift.\", or Perfors & Navarro 2014, \"Language Evolution Can Be Shaped by the Structure of the World\"). Along the same lines, the view that functional pressure needs to apply to only individuals, and that these are fully selfish, also requires evidence or needs to be clearly marked as a rather strong assumption. The claim that \"[...] in order to ensure the survival advantage of many competitors, animals are selfish in nature\" flies in the face of the whole line of research on animal alarm calls (e.g., Zuberbuehler 2009, \"Survivor Signals: The Biology and Psychology of Animal Alarm Calling\"); and, for that matter, the existence of any social animal. In sum, as it stands, I am not convinced that the problem this manuscript addresses is not an artifact of the assumption of selfish individuals and communities driven solely by functional pressure.\n- Terminology is very sloppy at times. What is \"successful evolution\" (p. 1) or \"naive natural selection\" (p.8)?\n- Writing could be greatly improved. There are a lot of typos and borderline grammatical sentences\n- References are wrong (e.g., Lewis' work on convention is not from 2008 but from 1969. The same goes for all the references on seminal work in game theory)\n- Many assumptions in the setup are not motivated. For instance, is there a reason to use a discrete dynamic over a continous one? (p. 3) Why use a multi-round bargaining game to model language evolution by contrast to, say, an established signaling game-style setup with conflict of interests? How is the \"credit mechanism\" and the \"market\" motivated/grounded in light of this being an investigation about language emergence? (p. 3)\n- The lines in Figure 3a and Figure 3b are very hard/impossible to read. Particularly Figure 3b.\n- The y-axis in the plots in Figure 3 are not aligned, rendering a comparison across conditions hard (and visually misleading)\n", "title": "This work investigates conditions under which communities of cooperative agents are stable. While the experiments are interesting, there's a lack of motivation behind fundamental assumptions made in this work", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "a0iw7YBEPt1": {"type": "review", "replyto": "Uqu9yHvqlRf", "review": "# Overall review\n\nThis paper attempts to address a question in the emergent communication literature: what preserves / maintains the stability of emerged communication protocols.  The authors manipulate the prevalence of lying behavior in a community of agents playing a variant of a Nash bargaining game.  The main take-away is that explicit punishment, from the environment and from truth-tellers not wanting to communicate with liars, can prevent the spread of exploitative lying behavior in the community.\n\nMy main worry about the paper is that the conceptual motivation is a bit unclear.  The authors present the paper as addressing when emergent communication can be stable.  And, after identifying a condition under which a penalty for lying removes liars from the population, they conclude that \"Only under such a environment, language is finally possible.\"  But in all experiments, the communication protocol is fixed: mappings from market needs to proposals.  In other words, what changes is less the communication protocol itself, and more the prevalence of lying / truth-telling.  It thus is not clear how these results are to be interpreted as being about the emergence of communication itself, and not alternative uses of a pre-existing protocol.\n\nPros:\n* Addresses a foundational question in emergent communication.\n* Explicitly models a community of agents, instead of just dyads.\n* Identifies explicit factors influencing their outcome of interest.\n\nCons:\n* Conceptual motivation a bit unclear (see above).\n* Communication protocol is fixed, not emergent.\n* Many interesting results / sub-experiments are presented as parentheticals / foot-notes, without full details in appendices.\n\n\n# Small comments\n\n* p 3, choice to not do simultaneous proposals.  More details about these experiments should probably be provided in an appendix.\n\n* Natural selection mechanism: the authors remove the lowest-performing single agent.  This is relatively different from the standard interpretation, which is that the number of offspring in the next generation is proportional to an agent's fitness.  Did the authors experiment with that approach, or can they say more to motivate theirs?\n\n* The y-axis in the main results are \"average scaled reward\".  How exactly is the scaling done?  This would help in interpreting the results, as would comparison with a random baseline and/or an optimal strategy.\n\n* \"As the natural selection approaches, there is less and less need to pretend for liars ...\"  I had some difficulty following the reasoning here.  Are the 10 tournaments _before_ a single episode of natural selection?  Or did natural selection occur in the middle?  If the former, it would help to know if these are averaged across \"generations\" in order to support the authors' interpretation.\n\n\n# Minor typographic comments\n\n* abstract: \"From the perspective of Darwinian, ...\" needs to be finished after \"Darwinian\".  Same at the end of page 1.\n\n* p 1, \"some intrigue properties\" should be \"some intriguing properties\"\n\n* p 2, \"lairs\" should be \"liars\"; this one recurs a few times in the text.\n\n* p 8, \"artificial intelligent\" should be \"artificial intelligence\"", "title": "Interesting, but needs clearer motivation and detail", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}}