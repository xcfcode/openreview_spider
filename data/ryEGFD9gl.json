{"paper": {"title": "Submodular Sum-product Networks for Scene Understanding", "authors": ["Abram L. Friesen", "Pedro Domingos"], "authorids": ["afriesen@cs.washington.edu", "pedrod@cs.washington.edu"], "summary": "A novel extension of sum-product networks that incorporates submodular Markov random fields into the sum nodes, resulting in a highly expressive class of models in which efficient inference is still possible.", "abstract": "Sum-product networks (SPNs) are an expressive class of deep probabilistic models in which inference takes time linear in their size, enabling them to be learned effectively. However, for certain challenging problems, such as scene understanding, the corresponding SPN has exponential size and is thus intractable. In this work, we introduce submodular sum-product networks (SSPNs), an extension of SPNs in which sum-node weights are defined by a submodular energy function. SSPNs combine the expressivity and depth of SPNs with the ability to efficiently compute the MAP state of a combinatorial number of labelings afforded by submodular energies. SSPNs for scene understanding can be understood as representing all possible parses of an image over arbitrary region shapes with respect to an image grammar. Despite this complexity, we develop an efficient and convergent algorithm based on graph cuts for computing the (approximate) MAP state of an SSPN, greatly increasing the expressivity of the SPN model class. Empirically, we show exponential improvements in parsing time compared to traditional inference algorithms such as alpha-expansion and belief propagation, while returning comparable minima.\n", "keywords": ["Computer vision", "Structured prediction"]}, "meta": {"decision": "Reject", "comment": "This paper was reviewed by three experts. While they all find merits in the paper (interesting new model class SSPN, new MAP inference algorithm), they all consistently point to deficiencies in the current manuscript (lack of parameter learning, emphasis on evaluation on energies, lack of improvements in accuracy). \n \n One problem that (I believe) is that manuscript as it stands makes neither a compelling impact on the chosen application (semantic segmentation) nor does it convincing establish the broad applicability of the proposed model (how do I run SSPNs on activity recognition or social network modeling). \n \n To be clear, we all agree that there is promising content here. However, I agree with the reviewers that the significance has not been established."}, "review": {"rJEgfZw8e": {"type": "rebuttal", "replyto": "ryEGFD9gl", "comment": "The main concern raised in each review is the lack of a direct comparison of SSPNs to existing semantic segmentation benchmarks. We address this point here and then respond to each reviewer's other points directly. We\u2019ve also made significant revisions to the structure and writing of the paper, particularly in the inference section, which we hope more clearly explains the intuitions behind InferSSPN.\n\nDespite not having comparisons on semantic segmentation benchmarks, SSPNs are a significant step forward in the state-of-the-art on scene understanding. SSPNs are (provably) more expressive than (and contain as a special case) MRFs and SPNs as commonly used for scene understanding and semantic segmentation, meaning that SSPNs are a richer model class than those already in use. Despite this increase in expressivity and complexity, InferSSPN is a very efficient (approximate) inference algorithm for the problem of parsing an image with respect to a grammar, which has been addressed by many previous works, but their approaches have all been very restrictive or inefficient. InferSSPN provably achieves low-order-polynomial time complexity for a problem with a state space that has size exponential in both the number of pixels and the height of the grammar. While the first version of the paper did not include accuracy results, as we thought the energy results were sufficient, we\u2019ve since updated the paper to include all accuracy, energy, and time complexity results for all test cases. These show empirically that InferSSPN provides exponential improvements in time-complexity with no loss in accuracy relative to alpha-expansion, which provably returns local optima that are within a constant factor of the global optimum.\n\nFurther, while we have characterized SSPNs in terms of scene understanding, they are as broadly applicable as SPNs and MRFs, and scene understanding is just the initial application we chose to focus on. Future applications may include activity recognition or social network modeling. Nonetheless, this paper presents a powerful new representation for efficiently modeling and reasoning about scenes at multiple levels of abstraction and is well within the scope of ICLR, which includes \u201chierarchical models\u201d and \u201capplications to vision\u201d in its list of relevant topics.\n\nLearning SSPNs is important \u2013 both for evaluating SSPNs on existing semantic segmentation benchmarks and for their adoption in general \u2013 and is something that we are already working on. Unfortunately, there do not yet exist any image grammars or relevant datasets with which to train SSPNs, so learning requires either creating such datasets or learning with a large number of hidden variables. This is ongoing and future work. However, we believe that one benefit of our contributions will be to spur the creation of such datasets and open up new research problems where reasoning about multiple levels of abstraction in scenes and higher-level relationships between objects is crucial. Finally, it\u2019s common in AI and ML for new representations to be introduced well before learning algorithms are properly developed for them. Notable cases include graphical models and previous work on image grammars, and this paper does the same for SSPNs.\n", "title": "General response to concern about our empirical results"}, "BJOu-WP8e": {"type": "rebuttal", "replyto": "Bksi_o-Eg", "comment": "Thank you for your detailed comments and feedback. We disagree that SSPNs are antithetical to ICLR. While our results do not currently include learning, SSPNs are absolutely learnable, just as SPNs, MRFs, and CRFs, and convolutional neural networks are learnable. While structure learning is possible for most of these models, the vast majority of learning (in ICLR and in other conferences) is parameter learning, meaning that the aforementioned models all have equivalent amounts of human-specified structure. The only difference between SSPNs and these other models (ignoring SPNs) is that SSPNs can be (but do not need to be) defined with respect to a grammar, as a convenient method for specifying the architecture of the network and to provide them with additional semantic information such as constituency and sub-categorization relationships.\n \nWith respect to inference time, many convolutional neural network architectures for semantic segmentation end up down-sampling images quite extensively (e.g., Deeplab, FCN) due to the use of max-pooling or strided convolution. In our preliminary work on end-to-end training of SSPNs with deep networks, the input image to the SSPN ends up being much smaller than the full image and thus inference only takes a small fraction of a second. As such, inference time during training is similar to that of a forward pass through resnet101, making end-to-end training quite realistic.\n\nSee our general response to this point above.\n", "title": "Review response"}, "rk1PbbPLl": {"type": "rebuttal", "replyto": "SJQ0axzNg", "comment": "Thank you for your review.\n1. We do not do any learning in this paper, which is why it is not discussed. The grammar structures used in the experiments are algorithmically defined and the corresponding weights are generated heuristically by counting symbol appearances in the evaluated images. The same structures and parameters are used when evaluating each inference algorithm.\n\nThe generative process does not select symbols, instead it always begins at the start symbol over the entire image, chooses a production of the start symbol (from a categorical distribution over said productions \u2013 the paper has been updated to make this more explicit), chooses a partition of the current region into a labeling based on the constituent symbols of the chosen production (by sampling from the MRF defined by this production over the pixels in the current region), and then recurses on each (constituent, subregion) pair. The production-selection process is equivalent to that found in PCFGs. \n\n2. See our general response to this point above. It\u2019s not clear to us how evaluating on the Berkeley segmentation dataset (BSD) would be meaningful, as our model and inference algorithm are about identifying semantic classes and relationships such as part-subpart and class-subclass, not about identifying image contours or segmenting based on intensity values. \n", "title": "Review response"}, "HybXZWD8l": {"type": "rebuttal", "replyto": "Hy80uyQVg", "comment": "Thanks for your comments and feedback.\n\n1. We\u2019ve edited and re-written parts of the paper to fix inaccuracies. For example, with respect to alpha-expansion and BP as scene-understanding algorithms, we simply meant that they are used for this task, not that they are explicitly designed for it. This has been clarified, as has the language regarding the approximate MAP state (where the intention was that the MAP state is the optimal parse, but this was poorly worded). We note, however, that inference in time sub-linear in network size is not uncommon, depending on the definition of the network. Techniques such as A* and branch-and-bound are able to explore graphs and networks in time sub-linear in their size.\n\n2. See our general response to this point above.\n\n3. In editing the paper, we\u2019ve re-structured and re-written parts of the inference section to try to make the intuitions more clear and have included a figure to help visualize the key parts of InferSSPN.", "title": "Review response"}, "BkmacPXml": {"type": "rebuttal", "replyto": "H1Y6hVk7g", "comment": "Thanks for your questions, I've responded to them below.\n\n1) Why evaluate on training data?\nThis paper is about representation and inference; learning is future work. As such, we are only evaluating inference performance and not generalization performance. Evaluating inference performance on test data would confuse inference performance with generalization performance, so we evaluated on the training data to ensure the two measures are kept separate.\n\n2) How do the energy values achieved by the various algorithms correlate with segmentation quality?\nMean pixel accuracies are in the high 80s to mid 90s on the training data, but we did not report them because they\u2019re not comparable to previous results reported in the literature (due to evaluation on a subset of the training data). Here we\u2019re just evaluating our model and inference algorithm. However, we could include a figure or brief discussion demonstrating that the resulting segmentations are good and that lower energy correlates with improved accuracy.\n\n3) If the pairwise terms were dropped from SSPNs, would this simplify to some existing model? How much modelling benefit comes from the pairwise terms?\nDropping the pairwise terms would result in a model that independently parsed each pixel by simply choosing the lowest energy path in the grammar for that pixel (where E(path) = the sum of production costs along the path plus the unary term at the terminal), which would simply correspond to a structured form for the unaries that does not provide any smoothing or label-space structure between pixels. The reason for the pairwise terms is that a regular SPN (defined from the productions of a grammar) would need to explicitly consider an exponential number of splits for each production, which is computationally infeasible and thus untestable. Incorporating (submodular) MRFs into the SPN allows us to perform inference in an otherwise highly-intractable model.\n\n4) Similarly, if the grammar were dropped from the model to get a standard MRF, how would the segmentation quality compare? I.e., how much benefit comes from using the grammar?\nIn general, the reason to use an SSPN (or a grammar in natural language processing) is that it simultaneously segments different regions and objects at multiple levels of abstraction and, in particular, considers multiple ways in which a region can be realized via its productions in the grammar. In addition, this top-down information can actually improve the bottom-level segmentation, e.g., segmenting a roof from a wall may be more accurate knowing that they\u2019re both part of a house, in contrast with an MRF, which only considers a single production and a single level of abstraction. \n\nWe also note that because the flat model is a special case of an SSPN, we can always include a production in the grammar corresponding to the flat MRF, which will be chosen if it has the lowest energy, so the SSPN will never produce worse segmentations. For the experiments in the paper, the accuracies of the bottom-level segmentations are essentially identical to those resulting from segmenting the image with a flat MRF, as one would expect.\n\n5) Can you give a ballpark number for how expensive running inference would be relative to ConvNet operations if one were trying to jointly learn SSPN and ConvNet parameters?\nYes, although we first note that our code is not highly-optimized and has not been extended to run on the GPU, so these numbers can definitely be improved. Further, there are many techniques (such as warm-starting) that can be used to speed up inference during learning. Nonetheless, in the experiments in the paper, total SSPN inference time ranged from less than 1 second to a maximum 287 seconds; however, for the depth experiments (which were the most time consuming), only 5/60 of the runs took over 200 seconds. Thus, inference is in general fairly fast, albeit slower than with just a flat MRF, but only by a constant factor (|G|) per iteration.\n\nPlease let us know if you have any further questions.", "title": "AnonReviewer2's questions"}, "H1Y6hVk7g": {"type": "review", "replyto": "ryEGFD9gl", "review": "InferSSPN looks to be a good algorithm for solving MAP inference problems in Submodular Sum-Product Networks (SSPN). However, I'm missing the experimental justification for why SSPN is a good model. This leads to some questions:\n\n- Why evaluate on training data?\n\n- How do the energy values achieved by the various algorithms correlate with segmentation quality?\n\n- If the pairwise terms were dropped from SSPNs, would this simplify to some existing model? How much modelling benefit comes from the pairwise terms?\n\n- Similarly, if the grammar were dropped from the model to get a standard MRF, how would the segmentation quality compare? I.e., how much benefit comes from using the grammar?\n\nAlso,\n\n- Can you give a ballpark number for how expensive running inference would be relative to ConvNet operations if one were trying to jointly learn SSPN and ConvNet parameters?This paper develops Submodular Sum Product Networks (SSPNs) and\nan efficient inference algorithm for approximately computing the\nmost probable labeling of variables in the model. The main\napplication in the paper is on scene parsing. In this context,\nSSPNs define an energy function with a grammar component for\nrepresenting a hierarchy of labels and an MRF for encoding\nsmoothness of labels over space. To perform inference, the\nauthors develop a move-making algorithm, somewhat in the spirit\nof fusion moves (Lempitsky et al., 2010) that repeatedly improves\na solution by considering a large neighborhood of alternative segmentations\nand solving an optimization problem to choose the best neighbor.\nEmpirical results show that the proposed algorithm achieves better\nenergy that belief propagation of alpha expansion and is much faster.\n\nThis is generally a well-executed paper. The model is interesting\nand clearly defined, the algorithm is well presented with proper\nanalysis of the relevant runtimes and guarantees on the\nbehavior. Overall, the algorithm seems effective at minimizing\nthe energy of SSPN models.\n\nHaving said that, I don't think this paper is a great fit for\nICLR. The model is even somewhat to the antithesis of the idea of\nlearning representations, in that a highly structured form of\nenergy function is asserted by the human modeller, and then\ninference is performed. I don't see the connection to learning\nrepresentations. One additional issue is that while the proposed\nalgorithm is faster than alternatives, the times are still on the\norder of 1-287 seconds per image, which means that the\napplicability of this method (as is) to something like training\nConvNets is limited.\n\nFinally, there is no attempt to argue that the model produces\nbetter segmentations than alternative models. The only\nevaluations in the paper are on energy values achieved and on\ntraining data.\n\nSo overall I think this is a good paper that should be published\nat a good machine learning conference, but I don't think ICLR is\nthe right fit.", "title": "Questions", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "Bksi_o-Eg": {"type": "review", "replyto": "ryEGFD9gl", "review": "InferSSPN looks to be a good algorithm for solving MAP inference problems in Submodular Sum-Product Networks (SSPN). However, I'm missing the experimental justification for why SSPN is a good model. This leads to some questions:\n\n- Why evaluate on training data?\n\n- How do the energy values achieved by the various algorithms correlate with segmentation quality?\n\n- If the pairwise terms were dropped from SSPNs, would this simplify to some existing model? How much modelling benefit comes from the pairwise terms?\n\n- Similarly, if the grammar were dropped from the model to get a standard MRF, how would the segmentation quality compare? I.e., how much benefit comes from using the grammar?\n\nAlso,\n\n- Can you give a ballpark number for how expensive running inference would be relative to ConvNet operations if one were trying to jointly learn SSPN and ConvNet parameters?This paper develops Submodular Sum Product Networks (SSPNs) and\nan efficient inference algorithm for approximately computing the\nmost probable labeling of variables in the model. The main\napplication in the paper is on scene parsing. In this context,\nSSPNs define an energy function with a grammar component for\nrepresenting a hierarchy of labels and an MRF for encoding\nsmoothness of labels over space. To perform inference, the\nauthors develop a move-making algorithm, somewhat in the spirit\nof fusion moves (Lempitsky et al., 2010) that repeatedly improves\na solution by considering a large neighborhood of alternative segmentations\nand solving an optimization problem to choose the best neighbor.\nEmpirical results show that the proposed algorithm achieves better\nenergy that belief propagation of alpha expansion and is much faster.\n\nThis is generally a well-executed paper. The model is interesting\nand clearly defined, the algorithm is well presented with proper\nanalysis of the relevant runtimes and guarantees on the\nbehavior. Overall, the algorithm seems effective at minimizing\nthe energy of SSPN models.\n\nHaving said that, I don't think this paper is a great fit for\nICLR. The model is even somewhat to the antithesis of the idea of\nlearning representations, in that a highly structured form of\nenergy function is asserted by the human modeller, and then\ninference is performed. I don't see the connection to learning\nrepresentations. One additional issue is that while the proposed\nalgorithm is faster than alternatives, the times are still on the\norder of 1-287 seconds per image, which means that the\napplicability of this method (as is) to something like training\nConvNets is limited.\n\nFinally, there is no attempt to argue that the model produces\nbetter segmentations than alternative models. The only\nevaluations in the paper are on energy values achieved and on\ntraining data.\n\nSo overall I think this is a good paper that should be published\nat a good machine learning conference, but I don't think ICLR is\nthe right fit.", "title": "Questions", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}}