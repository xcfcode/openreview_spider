{"paper": {"title": "A Solution to China Competitive Poker Using Deep Learning", "authors": ["Zhenxing Liu", "Maoyu Hu", "Zhangfei Zhang"], "authorids": ["liuzx@smzy.cc", "humaoyu@smzy.cc", "zzf@smzy.cc"], "summary": "This paper introduces a method to play China competitive poker using deep neural network, gets the state of the art performance.", "abstract": "Recently, deep neural networks have achieved superhuman performance in various games such as Go, chess and Shogi. Compared to Go, China Competitive Poker, also known as Dou dizhu, is a type of imperfect information game, including hidden information, randomness, multi-agent cooperation and competition. It has become widespread and is now a national game in China. We introduce an approach to play China Competitive Poker using Convolutional Neural Network (CNN) to predict actions. This network is trained by supervised learning from human game records. Without any search, the network already beats the best AI program by a large margin, and also beats the best human amateur players in duplicate mode.", "keywords": ["artificial intelligence", "China competitive poker", "Dou dizhu", "CNN", "imperfect information game"]}, "meta": {"decision": "Reject", "comment": "The paper presents a CNN that is trained from human games to predict which actions to take for China Competitive Poker (Dou dizhu).\n\nThe paper is poorly written, not because of the English, but because it is hard to understand the details of the proposed solution: it is not straight-forward to reimplement a solution from the presentation in the paper. It lacks explanations for several design decisions. This is unfortunate, as the authors point out in the rebuttal that they actually did way more experiments that are presented in the paper. Moreover, the experimental results lack comparisons to baselines, ablations, so that the proposed solution could be evaluated fairly.\n\nIn its current state, this paper can not be accepted for presentation at ICLR 2019."}, "review": {"SJlglkRYxN": {"type": "rebuttal", "replyto": "HJehAIhjyE", "comment": "If you are interested in, please send an email to liuzx@smzy.cc and zzf@smzy.cc", "title": "Thank you for your reply"}, "r1eKD--3aQ": {"type": "rebuttal", "replyto": "BJeKTW7zpQ", "comment": " It's not clear that separating the policy and kicker networks would be more advantageous than combining them. Thousands of actions is not a too large number - language modeling work routinely deals with outputting many more classes than that.\n\nThousands of actions is not a too large number, but extreme examples are hardly found in records. We separated the network in order to make the both are simple. We will try to combine the policy and kicker network in our plan.\n\n- There were no comparisons with baseline models or different model architectures. I would like to see some results on the same structure, but with an Linear model, MLP or LSTM across the time dimension, or search through different types of convolutional networks.\n\nWe tried different models in CCP, like DNN, RNN, LSTM, but the results were not very well (CNN was the best model), and we did not collect enough data. We will add these in the next version.\n\nThanks for useful questions, we will add these in the next version.\n\n\n", "title": "Thanks for your questions. We will optimize paper"}, "S1empmJnTm": {"type": "rebuttal", "replyto": "HygUgVsfam", "comment": "(3) While what the authors claim are weak reasons/conjectures of using CNN, those reasons are not strong. Or at least the paper fails to answer this question: \"Does CNN perform well *because* it matches the translation variance needed for this task?\"\n\nThe answer is yes. We tried DNN, RNN, LSTM in CCP, did not achieve good performance. But we didn't record too much data.\n\n(4) What the authors claimed only shows that the network can *predict* how human moves well, but it does not explain why the network can *act* better than human. The fact that the data set contains possibly more low-level players than high-level ones makes it really mysterious on why the network can *act* better than all those players. The mystery is not well-answered by the authors' hand-waving statements---more scientific evidence is needed.\n\nI think human is a board word, and \u201c*act* better than all those players\u201d is not accurate. There are high level players records in data, although it's really hard to analysis.\n", "title": "Thanks for your questions. We will optimize paper."}, "B1lI3xdG6Q": {"type": "rebuttal", "replyto": "BygupeAAhX", "comment": "Thanks for your review.\n\n(1)in other words, the paper is currently not reproducible at all. So the following comments are based on the trust-worthiness of the paper.\n\nWe will offer a online interface to public, it will return a action when you sent cards and game process. You can test the model as you wish. It will take a few days to prepare I think. And, I can offer the video of test match (all 10 games) and public email addresses of four top amateur players, you can check with them.\n\n(2)immature writing: The writing lacks formality and looks like a final project report. For instance, the super-short Section 2 is rather unprofessional---it is hard to believe that the related works can be described within two paragraphs anyway. Even as someone who understands the game of China Competitive Poker, I find it very hard to follow Section 3. There is a big room for improving the English writing.\n\nI am really sorry about it. I will continue to optimize the paper and improve English.\n\n(3)ill-illustrated specialty of the model: In particular, it is not clear why the model should be superior than other modeling choices. For instance, what role does the neighboring connections of CNNs play? What are the cons and pros of choosing CNNs? Are there strong motivations to design the model this way?\n\nThe following is the reason written in the paper:\n\nWe choose CNN to solve the problem in CCP due to the following reasons: First, CNN has achieved superhuman performance in perfect information games. Second, there is semi-translational invariance in CCP, e.g. there are two sets of cards in the same category but with different ranks (like \u201c34567\u201d and \u201c45678\u201d, see more information in section 3), if we add each card\u2019s rank, \u201c34567\u201d become \u201c45678\u201d, this is translational invariance. The player can play out \u201c45678\u201d after another one played out \u201c34567\u201d, but it is illegal if we swap the order, this is the reason for \u201csemi\u201d.\n\nBesides X-axis, I think there is translation invariance in Z-axis also. CNN can get good performance dealing with translation invariance.\n\n(4)many unanswered mysteries: why does the model trained with human records readily super-human? Note that this is controversial to common imitation learning where the typical performance is bound by the human-level performance. Even though authors claimed in the response that there are \"many professional records\"---but how many is many? Did the authors analyze the records and separate the professional versus amateur ones?\n\nFirst, many authors proved that the neural network can get the top amateur level in games just by supervised learning, like Chris J. Maddison\u2019s paper \u201cMOVE EVALUATION IN GO USING DEEP CONVOLUTIONAL NEURAL NETWORKS\u201d showed: \u201cWe train a large 12-layer convolutional neural network by supervised learning from a database of human professional games. The network correctly predicts the expert move in 55% of positions, equalling the accuracy of a 6 dan human player.\u201d 6 dan is top level in amateur players. Deepmind got similar conclusion in their paper.\n\nSecond, compared to Go, there are seldom professional players in the strict sense in CCP. It is not a full time job for \"CCP professional players\", because players can not get enough money in CCP match. Maybe \"semi-professional player\" is more suitable, but they are really top players than others. As I said in previous reply, game records came from online platform. Players only need to offer a cellphone number or a tencent account to online platform. I think it is really very hard to distinguish just by them. many online platforms support for visitors to log in.", "title": "Thanks for your review."}, "BJeKTW7zpQ": {"type": "review", "replyto": "rJzoujRct7", "review": "This paper provides a system to play CCP using some deep learning. The system consists of  three modules - the bid module, which is rule based, and the policy and kicker networks, which are simple convolutional neural networks. The authors use a dataset of 8 million game records consisting of 80 million state action pairs, and train the network in a supervised fashion. The resulting model is able beat MicroWe, the current state of the art in playing CCP, and even are able to beat a few \"top amateur players\"\n\n- Why is the bid module also not learned? It seems like the feature set for the bid module is fairly simple, and a linear or MLP can do fairly well compared to a rule based module.\n- It's not clear that separating the policy and kicker networks would be more advantageous than combining them. Thousands of actions is not a too large number - language modeling work routinely deals with outputting many more classes than that.\n- Were the convolutions chosen 1D, 2D, or 3D? The figure seems to imply that the convolutions were over the XZ dimensions, with Y as the channel dimension. If so, this doesn't make too much sense to be, since the Z dimension is not uniform - the last index is all unseen cards, which is significantly more than the middle indices of \"what was played in this round\". There shouldn't be a lot of translational invariance in the Z dimension. I'm also not convinced that translational invariance is helpful in the X dimension.\n- There were no comparisons with baseline models or different model architectures. I would like to see some results on the same structure, but with an Linear model, MLP or LSTM across the time dimension, or search through different types of convolutional networks.\n- What hyperparameters were searched through in the learning process?\n- Missing citations for MicroWe being the best CCP AI, and citations for the accomplishments of the top amateur players.\n- How far away are the top amateur players from professional players? Please provide some context on how far this system is from solving CCP.\n- Fig 3, 4 should just say #of games instead of \"iteration\"\n\nThis paper shows that one choice for a supervised learning system on a CCP game database can achieve amateur level human play. It does not give insight to why the system was designed this way, why the model choices were made, and how good simpler baselines might be able to achieve. The paper is not clearly written enough, and does not provide enough scientific value to be accepted to the conference.", "title": "Good performance results, but not much scientific contribution", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "BygupeAAhX": {"type": "review", "replyto": "rJzoujRct7", "review": "The authors propose a model that learns to play the China Competitive Poker game. The model uses CNN to predict the actions, and is trained from actual human game records. The model is shown to beat the current best AI and human amateur players.\n\nThe performance is certainly strong (if it were true). But given the double-blinded policy, there is literally no way to verify the correctness of the performance---in other words, the paper is currently not reproducible at all. So the following comments are based on the trust-worthiness of the paper.\n\n(1) immature writing: The writing lacks formality and looks like a final project report. For instance, the super-short Section 2 is rather unprofessional---it is hard to believe that the related works can be described within two paragraphs anyway. Even as someone who understands the game of China Competitive Poker, I find it very hard to follow Section 3. There is a big room for improving the English writing.\n\n(2) ill-illustrated specialty of the model: In particular, it is not clear why the model should be superior than other modeling choices. For instance, what role does the neighboring connections of CNNs play? What are the cons and pros of choosing CNNs? Are there strong motivations to design the model this way? \n\n(3) many unanswered mysteries: why does the model trained with human records readily super-human? Note that this is controversial to common imitation learning where the typical performance is bound by the human-level performance. Even though authors claimed in the response that there are \"many professional records\"---but how many is many? Did the authors analyze the records and separate the professional versus amateur ones?", "title": "promising performance, left more mysteries than observations", "rating": "2: Strong rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "HJgfur5Inm": {"type": "rebuttal", "replyto": "rJgEq1qrn7", "comment": "This is not our design, but I think it also can work very well.\nWe made it simpler compared to your idea", "title": "Yes, more parameters if full connection is 15*19*512"}, "BylSiKSBnm": {"type": "rebuttal", "replyto": "SyeZVvHV3m", "comment": "1. As paper shows, we used 1 full connection layer.\n2. We did not use pooling.\n3. The size is 3*3 or smaller. Because input is asymmetrical shape, we used 1*3 also.", "title": "I think it is more like VGG"}, "SkgYrSeV2X": {"type": "rebuttal", "replyto": "BkeBfg-mnX", "comment": "1) How did you get 8 million matches' records?\nwe cooperate with online platforms, and get records.\n\n2) Why such ordinary samples could achieve so high-level?\nI guess the reason is it includes many records generated by professional players. Although there are so many competitions in China, they still play online game, and have accounts on many platforms.  Overall quality of records is also high quality I think.\n\nThe test match is held for test the distance between amateur players and DeepRocket, the result surprised us. We pay attention to Monte Carlo method for defeating professional players after test match.", "title": "Good question."}, "SJeVf_S2iQ": {"type": "rebuttal", "replyto": "S1xe6Ub2jQ", "comment": "Because MW is a commercial software, the company offers online interface for test. I could ask for interface, and then maybe you can test. Otherwise, really hard to find English information.\n\nAbout dismantling, you are right, we did it by ourselves. Mapping them to all corresponding features in Y axis. We code different functions using python. they match each feature and add to Y axis.", "title": "Thank you."}, "rkg_dernjX": {"type": "rebuttal", "replyto": "Bker4Zzni7", "comment": "I am a amateur player of Go. Tencent held competition for AI many times. Besides AlphaGo, there are many famous AI in Go, like \"JueYi\" and \"JinMao\" (sorry, Chinese pronunciation) which are developed by Tencent, \"XingZhen\" developed by Tsinghua University.\nBut I seldom heard Doudizhu competition for AI.", "title": "BTW, I know many competitions for AI in the game of Go."}, "SyxKWCEhiQ": {"type": "rebuttal", "replyto": "Bker4Zzni7", "comment": "There are really many many Doudizhu competitions in China, like 360, TuYou, Tencent, JJ and many more\uff0c but only open to human players. If you know many competitions for AI, please tell us.\n\nAnother question about how to prove MW represents the best CCP AI.\nBesides MW won the champion in NCGT, MW have been used in many online Doudizhu game, and get the rank No1 of market share. If you still doubt about it, I can give more details. That is why we think MW is the best and chose it to be opponent.  ", "title": "Is there many Doudizhu competitions for AI in China?"}, "Syg6kcNhi7": {"type": "rebuttal", "replyto": "SyxUgd09j7", "comment": "It is 13 kinds, not 15 kinds. you can treat Rocket as a kind of Bomb. It is also not necessary adding \"PASS\" to in Y-axis.\nThe left 2 is some other information, like round, role, the number of left cards.\nIt is too complex to show a example here. Please reply me if it is still hard to understand.", "title": "Only a little difference with your description."}, "SkekEpSjj7": {"type": "rebuttal", "replyto": "Hkeup6hcjQ", "comment": "(1)I want to know does this network have any special features?\nI am not sure about the meaning of special features. The major features are in Y axis, like Trio or Solo. Other than these, we add the round info, role info and the number of left cards of each player as features. Could you show a example please?\n\n (2)if there is a network graph inserted in paper will be more well.\nThanks for your suggestion. I think I will add it in next version. Actually, we found something interesting about strides, layers, filters and accuracy, but the paper is limited in 8 pages, I have to give up introducing it in this paper.\n\nDo you consider to use resnet instead?  as in Alphago Zero\nAbout resnet, we already tried it in CCP. Generally speaking, we did not find obvious difference of performance between CNN and resnet, it seems CNN is a litter better than resnet according on the experiment result, but it is not enough. We will pay more attention in resnet when we defeat the human professional player.\n\nBTW, it better to provide a reference link for MicroWe.   there isn't any introduction about MicroWe in google.\nThe issue about MicroWe, first, unfortunately, the author of MicroWe have not published any paper, it is a commercial software, and most of customers are domestic, second, although the game is very popular in China, it is still hard to find more infos in english, also a english reference. \nthe website of National Computer Games Tournament (NCGT): http://computergames.caai.cn/\nbut it is still chinese website. \nI am sorry about it. I will ask the committee of NCGT for more english infos.", "title": "Good suggestion."}, "SJg60boYc7": {"type": "rebuttal", "replyto": "HJlezNB_9Q", "comment": "The main part of data came from the online game platform, and we choose high quality records, like from senior rooms. It is hard to distinguish which is top or amateur. \nWe also add some records from top players, but not too much, less than 3%.", "title": "Mixed Data."}, "Bkgw7g70Fm": {"type": "rebuttal", "replyto": "Syg6ApQTK7", "comment": "We found it is OK for training time, so we did not pay more attention to parallelization.", "title": "Only NVIDIA 1080TI * 1"}, "HkeXniWAKQ": {"type": "rebuttal", "replyto": "Hyld_dj3Km", "comment": "About bot exploitability.\nGenerally speaking, I think DeepRocket works well. It does stange actions in certain specific situations. E.g. landlord got \"345555679TTQKA22B\", output \"3\" rather than \"34567\" (I think most human players choose it) in a certain version.\n\nAbout the confidence interval.\nWe tested standard deviation of landlord's scores, each iteration is 1000 games.\n7.08798955981\n7.11032987983\n6.75631193774\n6.92882089536\n6.85500080233\n6.6713368975\n\nI agree with you, there are great fluctuations in poker game result, so we use the duplicate mode. We can offer the DeepRocket server interface in order to test, if necessary.\n(I would add more data if you think it is not enough.)\nThank you for your comment, waiting for more communication!", "title": "Good question!"}, "SJxc-I-TtQ": {"type": "rebuttal", "replyto": "rygg2Ghht7", "comment": "I changed the sequence in order to better answer your question.\n\n1.Why it has three table, player change the position in turn? \nThere are two tables in test match, also shown in Figure5, not three. Players do not change the positions in turn, but it is allowed that the players want to swap their position (role) after the end of the game, just between human players, although the situation did not occur in test match.\n\nsupplementary: there is another important imformation in plane, it is the number of left cards of the player.\n\n2. why both peasants are AI in Figure5? \nFirst of all, the three players are a team. The peasants must cooperate with each other, so it is better if peasants come from the same team. The peasants are DeepRocket in table2, while human players in table 1.\n\n3.BTW, does human know what the position is AI during playing poker.\nYes, all human players in test match know identity of each position in both tables clearly.\n\nIn fact, there are more complex duplicate mode, each team has four players, which include bid process. Please contact us when the authors are public, if you have interested in.\nThank you for your comment, waiting for more communication!", "title": "Hi, here it the answer for your questions!"}, "rJxbr1xRF7": {"type": "rebuttal", "replyto": "rklMU_-aFX", "comment": "(1)  The same model for both Peasant and Landlord? I think the policies of these two rules are distinct.\nYes, the same model. And you are right, the policies are distinct. An important thing I forgot to mention in paper is role information is in each plane in policy network, in order to distinguish whose action. I am sorry about it.\n\n(2) Does this model really show cooperation between the two Peasant? How to explain if it does?\nTo a certain degree. you can see example in paper, and we can find more examples. But it is not strong enough. The model does not work well when a peasant is in active mode, and have to help the partner to be in active mode next round. I think the model learned coorperation from human record, because the up peasant is a important position (does action before landlord), many obviously samples were found in record which were different from normal actions. And the role information in input of the policy network made an important impact also.\n\nThe question about insufficiency, I only showed the first test match result in paper, by the way, the test match is offline. We did enough test then focused on reinforcement and Monte Carlo method. We can offer the DeepRocket server interface in order to test, if necessary.\n\nThank you for your comment, , waiting for more communication!", "title": "Thank you for your question!"}, "rJgPaVs2Km": {"type": "rebuttal", "replyto": "BJe2x9vnKQ", "comment": "I searched the data and found \"56789\" was played out by Guofeng Xie, who won the champion in offline match. I contacted him and the following is his reply: \nFirst of all, \"3456789\" is a obvious normal and good choice. but the reason for \"56789\" is based on (1) He was not sure who had the last \"2\", he can only play out solo after played out \"3456789\", Landlord had two jokers, and maybe another \"2\", the game would be under the control of Landlord, so Guofeng Xie did not choose the longer solo with chain. (2) \"J\" had not been seen yet, he worried about Landlord had trio with pair, it is defense-based consideration. It is also hard even \"4KAAA22\" left, because Landlord may seperate the jokers. (3) \"4KAAA22\" and \"344KAAA22\" have advantages and disadvantages respectively. The former has less sets, while the latter is more flexible.\n\nThe following is author's reply:\nWe recorded the process with video. I found Guofeng Xie considered for a long time at that moment. It was really hard to choose.\nThank you for your comments, waiting for more communication!", "title": "Although the action looks like strange, the player has his thinking."}}}