{"paper": {"title": "Online and stochastic optimization beyond Lipschitz continuity: A Riemannian approach", "authors": ["Kimon Antonakopoulos", "E. Veronica Belmega", "Panayotis Mertikopoulos"], "authorids": ["kimon.antonakopoulos@inria.fr", "veronica.belmega@ensea.fr", "panayotis.mertikopoulos@imag.fr"], "summary": "We introduce a novel version of Lipschitz objective continuity that allows stochastic mirror descent methodologies to achieve optimal convergence rates in problems with singularities.", "abstract": "Motivated by applications to machine learning and imaging science, we study a class of online and stochastic optimization problems with loss functions that are not Lipschitz continuous; in particular, the loss functions encountered by the optimizer could exhibit gradient singularities or be singular themselves. Drawing on tools and techniques from Riemannian geometry, we examine a Riemann\u2013Lipschitz (RL) continuity condition which is tailored to the singularity landscape of the problem\u2019s loss functions. In this way, we are able to tackle cases beyond the Lipschitz framework provided by a global norm, and we derive optimal regret bounds and last iterate convergence results through the use of regularized learning methods (such as online mirror descent). These results are subsequently validated in a class of stochastic Poisson inverse problems that arise in imaging science.", "keywords": ["Online optimization", "stochastic optimization", "Poisson inverse problems"]}, "meta": {"decision": "Accept (Spotlight)", "comment": "This is a mostly theoretical paper concerning online and stochastic optimization for convex loss functions that are not Lipschitz continuous. The authors propose a method for replacing the Lipschitz continuity condition with a more general Riemann-Lipschitz continuity condition, under which they are able to provide regret bounds for the online mirror descent algorithm, as well as extending to the stochastic setting. They follow up by evaluating their algorithm on Poisson inverse problems. \n\nThe reviewers all agree that this is a well-written paper that makes a clear contribution. To the best of our knowledge, the theory and derivations are correct, and the authors were highly responsive to reviewers\u2019 (minor) comments. I\u2019m therefore happy to recommend acceptance."}, "review": {"SkeKfUUoqS": {"type": "review", "replyto": "rkxZyaNtwB", "review": "The paper establishes optimal regret bounds of the order O(\\sqrt{T}) for Follow The Regularised Leader (FTRL) and Online Mirror Descent (OMD) for convex loss functions and potentials (a.k.a. Riemannian regularizers) that are, respectively, Lipschitz continuous and strongly convex with respect to a given Riemannian metric. These conditions naturally generalize the classical conditions typically considered in the literature, which are defined with respect to a global norm and, as such, are not well-suited to problems where the loss functions and its gradient present singularities at the boundary of the feasibility region. The authors suggest a principled way to choose both the Riemannian metric and the potential function based on the singularity landscape of the gradient of the loss function. Via standard online-to-batch conversion, the authors also address the offline setting and give O(1/\\sqrt{T}) error bounds for ergodic averages in convex problems and for last iterates in non-convex problems satisfying a weak secant inequality. The authors include numerical experiments involving a Poisson inverse problem.\n\nThe paper is well-written, with a very clean narrative highlighting the main ideas and results. To the best of my knowledge, the literature review is complete and rightly highlights the fact that most results in the literature on Riemannian mirror descent methods have so far primarily addressed offline deterministic problems with exact oracle gradients. The contribution of this work lies not only in the focus on online and noisy setting but also on establishing natural results upon natural generalizations of well-known conditions in standard (non-Riemannian) settings. The techniques used are extensions of the classical theory and follow quite naturally, with the exception of the non-trivial primal-dual inequality (20).\n\nQUESTIONS/SUGGESTIONS:\n1) Can the authors be more explicit about how the (OMD) equations are derived from (16). While this is standard, I feel currently there is a bit of a jump in the narrative\u2014which otherwise is very good.\n2) The workhorse behind the established results is the primal-dual inequality (20) which relies on the introduction of the Fenchel coupling. Can the authors be more explicit about the use of this inequality, and what makes the Riemann generalization difficult in general? In particular, can the authors comment on the applicability of this inequality (or similar) to the smooth setting?\n3) Typo: sometimes the notation $\\mathcal{U}$ seems to be used instead of the notation $\\mathcal{X}$. See, for instance, equation (7) in Definition 1 and the definition of the set $\\mathcal{Z}$ in Remark 2.\n\nAFTER REBUTTAL: I thank the authors for addressing my questions.", "title": "Official Blind Review #4", "rating": "8: Accept", "confidence": 2}, "Hyg2Myvror": {"type": "rebuttal", "replyto": "HylZuqdiFB", "comment": "Thank you for your constructive feedback and positive evaluation! Regarding your comments:\n\n1.  We fully agree that the connection between non-Euclidean smoothness/continuity conditions is not always clear. For instance, depending on the choice of regularizer, a convex function which is differentiable on an open domain of $\\mathbb{R}^n$ could be RL continuous, relatively continuous / smooth, or any combination of the above (or, of course, none).  In our view, this shows that a judicious choice of regularizer can lead to significant algorithmic performance gains (as different settings have different advantages/disadvantages). Our primary motivation for introducing the RLC condition (and hence extending the standard bounded gradient regularity assumption) was to focus on online and/or stochastic convex optimization problems where smoothness does not contribute to better regret rates. Going forward, we believe that a precise characterization of the interplay between the various smoothness/continuity conditions above would be of clear and certain value to the community - but, at the same time, this cannot be attempted within the scope of the current paper. We've introduced a \"concluding remarks\" section to discuss precisely this issue.\n\n\n2.  Concerning the papers mentioned: we were not aware of the relSGD paper of Hanzely and Richtarik (2018), many thanks for bringing it to our attention! We have now included this paper in our review of the state of theart in the introduction - thanks again.\n\n\n\n3.  Regarding the experimental part: since acceleration cannot be achieved in a generic stochastic setting without some variance reduction scheme (such as SVRG or the like), it is not clear how to put the APBG framework of Hanzely et al. on an equal footing with the methods studied in the current paper, so we did not attempt it. On the other hand, there are indeed several interesting connections with the recent paper of Hanzely and Richtarik (2018), which we detail below:\n\n3a) First, we noticed a typo in p. 18 (now p.19 in Sec. F.2) of the supplement of our paper: when we referred to the Burg regularizer, we actually gave the definition of the standard (Gibbs-Shannon) entropic regularizer. That was a mistake, apologies for any confusion caused: the definition should read $h(x) = - \\sum_{i} \\log x_{i}$.\n\n3b) To connect this with the work of Hanzely and Richtarik (2018), note that relSGD is  the mirror descent method generated by the Burg regularizer above with step-size $\\gamma_t \\propto 1/\\sqrt{t}$.\n\n3c) On that account, relSGD is most closely connected with the CMP method of He et al. (2016): CMP is also generated by the Burg entropy, but includes an extra-gradient step. [In Bregman language, relSGD is stochastic *mirror descent* with Burg regularization while CMP is stochastic *mirror-prox* with Burg regularization]\n\n3d) CMP was one of the algorithms that we tested, and it was the second-best to RMD (which is generated by the O(1/x) regularizer of Example 4).\n\n3e) Even though we did not report these results, Burg mirror descent with and without an extra-gradient step (i.e., CMP and relSGD respectively) behave similarly, with the extra-gradient version (CMP) performing slightly better.\n\nSince we are already comparing RMD to CMP (and CMP and relSGD behave similarly), we feel that adding an extra set of experiments would only occlude the discussion. Because of this, we opted not to present more experiments in the revised version of our manuscript; however, we are including a detailed version of the above discussion in the experimental section (p. 19 in the appendix), and we also discuss relSGD as an example of OMD in Section 4.\n\nFor your convenience, we've outlined all relevant changes in our revision in blue.", "title": "Thanks for the constructive feedback and positive evaluation!"}, "rJgdta8HsB": {"type": "rebuttal", "replyto": "SklTXJI75B", "comment": "Many thanks for the constructive feedback and positive recommendation! Concerning your questions and remarks:\n\n1. Indeed, a suitable nonlinear transformation of the feasible region could allow us to recover Lipschitz continuity in the standard (global) sense. In general however, a non-linear transformation would also destroy convexity, so we see no systematic way of transforming the problem in a way that would allow us to maintain both convexity and Lipschitz continuity.\n\n2. Point taken about the definition of lower semicontinuity. In the revised version of our paper, we provide a clear definition at the point where the notion is introduced (bottom of p. 5).\n\n3. Typos: fixed, many thanks!\n\nFor your convenience, we've outlined all changes in our manuscript in blue.", "title": "Thanks for the constructive feedback and positive evaluation!"}, "rJe1H2UBoS": {"type": "rebuttal", "replyto": "SkeKfUUoqS", "comment": "Many thanks for the constructive feedback and positive recommendation! Regarding your  questions and suggestions:\n\n1. We will be happy to provide more details about the derivation of (OMD) from the \u201clinearized\u201d version of (FTRL). In the updated version of the manuscript, we have included a relevant paragraph right after (16).\n\n2. The reviewer is correct that the primary workhorse of our analysis is the primal-dual inequality (20) for the Fenchel coupling. The main idea behind it serves a dual purpose: first, it seeks to leverage the generalized strong convexity condition in a way that allows the associated regularizer h to be properly adjusted to the singularity landscape of the problem. Our first idea here (which seemed easier to be checked), would be to assume that the Riemannian position-dependent norm would be applied at the base point (instead of x). However, the analysis breaks down completely under this modification. We have not been able to find another distance-like measure that is well-suited to the analysis of mirror descent in this context. The second point is that we need to compare primal vectors (solution points) to dual vectors (the iterates $Y_t$ that generate the algorithm): primal-primal divergence measures cannot do that, but the Fenchel coupling is perfectly suited for that purpose.\n\nThe above also partially answers the reviewer\u2019s comment regarding smoothness. In particular, a natural way to define smoothness via the use of a local Riemannian norm would be to extend the standard (Euclidean) descent lemma, namely by asking that $f(y) \\leq f(x) + \\langle\\nabla f(x),y-x\\rangle + L\\|x-y\\|_{y}^2$ for all $x,y$. However, if one applies a Riemannian gradient descent algorithm of the form $X_{t+1} = X_{t} - \\gamma_{t} \\mathrm{grad} f(X_{t})$ (with $\\mathrm{grad} f$ denoting the standard Riemannian gradient),  the above definition would not offer a way to control the error quantity $-\\gamma_{t}\\|\\mathrm{grad} f(X_t)\\|_{X_t}^2 + L\\gamma^{2}_{t}\\|\\mathrm{grad} f(X_{t})\\|_{t+1}^2$, which is the main ingredient for obtaining the $O(1/T)$ convergence rate in the standard Euclidean case. This is circumvented by the use of the Lipschitz-like / relative smoothness discussed in the papers mentioned in the introduction (and also mentioned by Reviewer 1); however, as can be seen in these works, smoothness does not seem to provide any benefit in the online/stochastic case (where the best achievable rates are $O(1/\\sqrt{T})$).\n\n3. Typos: fixed, many thanks!\n\nFor your convenience, we have highlighted all the relevant changes in our paper in blue.", "title": "Thanks for the thoughtful remarks and positive evaluation!"}, "HylZuqdiFB": {"type": "review", "replyto": "rkxZyaNtwB", "review": "This paper investigates online and stochastic convex optimization problems in which the objective function is not Lipschitz continuous. The originality of this study lies in the use of Riemannian geometry. Specifically, the standard condition of Lipschitz continuity is replaced with a more general condition involving Riemannian distances and called Riemann-Lipschitz Continuity (RLC). Based on an appropriate definition of Riemannian regularizer and a generalization of Fenchel coupling to Riemannian geometry, the authors provide $O(\\sqrt T)$ regret (resp. risk) bounds for the online (resp. stochastic) mirror descent algorithm, under the Riemann-Lipchitz condition. The performance of the algorithm is validated on Poisson inverse problems.\n\nOverall, this is a dense, yet interesting, paper. I am not an expert in Riemannian geometry but, as far as I could check, the proofs look correct. Notably, the analysis of OMD is relatively standard, once we get a bound (Prop B.1) on the Fenchel coupling, using the Riemannian dual norm. \n\nI have essentially one main comment. Clearly, the concept of \u201cRiemann-Lipschitz continuity\u201d is different from the notions of \u201crelative continuity\u201d and \u201crelative smoothness\u201d that have been recently proposed in the literature. But it is not clear that the Riemann-Lipschitz condition can tackle convex optimization tasks in which relative continuity and relative smoothness do not hold. In particular, Poisson (linear) inverse problems have already been handled under the relative smoothness condition, using Mirror Descent or Bregman proximal methods (Hanzely and Richtarik, 2018; Hanzely et. al. 2018). Thus,\n* from a conceptual viewpoint, it would be interesting to provide some applications in which the RLC condition hold, but the relative smoothness condition does not; \n* from an experimental viewpoint, in Sec. 6, it would be legitimate to compare the present \u201cRiemannian Mirror Descent\u201d algorithm with respect to the APBG method (Hanzely et. al. 2018) and the relSGD method (Hanzely and Richtarik, 2018). \n", "title": "Official Blind Review #1", "rating": "6: Weak Accept", "confidence": 2}, "SklTXJI75B": {"type": "review", "replyto": "rkxZyaNtwB", "review": "Summary:\n\nThe paper generalizes regret analysis results from convex online learning to\nfunctions that are not Lipschitz but Riemann Lipschitz continuous.\n\nExample:\n$f(x) = -\\log(x) + x$ is convex on the convex domain $X = [0, 2]$ but $f$ is\nnot Lipschitz on $D$ since $f(x) \\to \\infty$ as $x \\to 0$.\n\nA possible Riemannian metric that can be used on the domain of such a function\nis the Poincare metric $g(x) = 1 / x^2$.\nThe norm defined by that Riemannian metric is $\\| z \\|^2_x = z^T g(x) z$.\nThis norm can be used to measure infinitesimal distances in $X$.\nThe Riemannian distance $dist(x, x')$ on $X$ that follows from this is defined\nas integrating over the infinitesimal distances on a curve connecting\n$x$ and $x'$ as measured by the norm defined above.\n\nIntuitively, an infinitesimal distance Lipschitz bound can be seen to be\nconstructed by\n$| f(x + \\delta x) - f(x) | \\approx \\| f'(x) \\| \\| \\delta x \\|$ as $\\delta x \\to 0$\nwhich in the case of our example does not exist since $f'(x) \\to \\infty$.\nBut when using a Riemannian metric based norm\n$\\| f'(x) \\| = \\sqrt{ f'(x)^T g^{-1}(x) f'(x) }$\non the right-hand side we have\n$f'(x) = -\\frac{1}{x} + 1$\n$f'(x)^2 = \\frac{1}{x^2} - \\frac{2}{x} + 1$\n$f'(x)^2 g^{-1}(x) = O(1)$\nwith $g(x) = 1 / x^2$.\n\nIn this way it is possible to bound changes of $f(x)$ relative to changes in\n$x$ for functions that are not Lipschitz continuous.\n\nThe authors show how a suitable Riemannian metric can be transformed into\na regularizer usuable in online optimization.\nThey present various rates that appear to be otherwise known for similar\nregularizers.\nMy knowledge of the online learning literature is very limited so I cannot\nmake a qualified statement about these formal analyses in a reasonable amount\nof time.\n\nThe authors also transfer the results from the convex online setting to the\nconvex stochastic setting and the nonconvex setting.\n\nBased on my limited understanding I would recommed to accept the paper.\nThe analysis to me seems both rigorous and useful in practice\n(at least with regard to the formal definitions of Riemannian metrics and\nRiemannian Lipschitz condition for singular functions).\n\nRemarks / Suggestions:\n- With a similar knowledge of the underlying function it would perhaps be\n\tpossible to perform a nonlinear transformation of the input space that\n\tleads to Lipschitz continuous function.\n\tCan something be said about this?\n\n- Definition 2: Write out l.s.c. (lower semi-continuous?) as it does not seem\n\tto be defined everywhere and not every reader is necessarily familiar\n\tenough with convex analysis\n\n- Page 8: Typo: \"Eucldiean stochastic gradient method\n", "title": "Official Blind Review #2", "rating": "8: Accept", "confidence": 1}}}