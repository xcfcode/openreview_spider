{"paper": {"title": "Group Equivariant Stand-Alone Self-Attention For Vision", "authors": ["David W. Romero", "Jean-Baptiste Cordonnier"], "authorids": ["~David_W._Romero1", "~Jean-Baptiste_Cordonnier2"], "summary": "We provide a general self-attention formulation to impose group equivariance to arbitrary symmetry groups.", "abstract": "We provide a general self-attention formulation to impose group equivariance to arbitrary symmetry groups. This is achieved by defining positional encodings that are invariant to the action of the group considered. Since the group acts on the positional encoding directly, group equivariant self-attention networks (GSA-Nets) are steerable by nature. Our experiments on vision benchmarks demonstrate consistent improvements of GSA-Nets over non-equivariant self-attention networks.", "keywords": ["group equivariant transformers", "group equivariant self-attention", "group equivariance", "self-attention", "transformers"]}, "meta": {"decision": "Accept (Poster)", "comment": "The paper introduces group equivariant self attention networks constructed by defining positional encoding that are invariant to the group action considered. This is related to equivariance in set networks . The work is sound and the idea of infusing the inductive bias via the positional encoding is  interesting and leads to improvement  results when comparing transformers with equivariance and without it, nevertheless more work needs to be done to bridge the gap in terms of performance with CNNs as pointed by the reviewers.  Authors made an admirable efforts in the rebuttal and in the revision of the paper clarifying most of the reviewers questions and concerns.   Accept \n\n"}, "review": {"xEOs98b6CI_": {"type": "review", "replyto": "JkfYjnOEo6M", "review": "This paper develops self-attention mechanisms for group equivariant networks. This is a natural and potentially useful piece of architecture, that, drawing inspiration from its success for text and image analysis, is likely to introduce an effective inductive bias to the group convolution networks. \nThe paper is based on the following series of observations. First, represent an image as a set of $N$ feature vectors (e.g.,  pixels). Second, consider group actions $\\mathcal{G}$ that can be represented as sub-groups of the permutation group $\u05bf\\mathbb{S}_N$ acting on the $N$ image pixels. Third, the standard self-attention layer is permutation equivariant. A way to further restrict this equivariance to smaller sub-group of the permutations  $\\mathcal{G}<\\mathbb{S}_N$ is by adding (or concatenating?) to the set of feature vectors, used as keys in the attention layer, functions which are invariant to this subgroup but not to any larger group. This will lead to operators that are equivariant to the desired sub-group $\\mathcal{G}$. Lastly, since doing that directly on the representation of an image leads to larger invariances than desired, the authors work with signals defined over the group and consider regular group action (i.e., change of variables of functions). For example, for the roto-translation group that adds $90$ degrees rotations around the center of the image to the standard translations, this means representing four copies of the image and defining the self-attention layer from the original image and such signals as well as self-attention maps between pairs of such signals. \n\nOverall, I feel this work offers some interesting observations relating symmetry and equivariance/invariance and self-attention. However, I find this work not fully ready in terms of exposition, ideas delivery and elaboration. The paper is not well balanced between developing and explaining its main contribution (starting page 6), and self-attention background. I understand there is much to cover, but explaining the main constructions in half a page is too short. I think the paper keeps reintroducing positional encoding and self-attention in several formulations and there is much space to save there. Furthermore, the explanations and notations are somewhat not coherent and clear, for example (eqs. 13, 14) are not sufficiently explained and demonstrated. Although i dont think it is a necessary condition for publication of such paper, the results don't show an improvement over \"standard\" group convolution methods, although the authors claim expressiveness of their self-attention networks is at-least of that of generalized convolutions. Lastly, the last paragraph before section 6, describing the expressive power of these network is not sufficiently developed and justified. \n\nSome more comments are:\n- There are different notations for concat (word and union) and softmax (word and sigma).\n- Equation 7 has some repeating unclear part.\n- $X_i$ is not defined in equation 5.\n- What happens when the group action cannot be represented as subgroup of permutations? (Page 4, lower part). That is, when there is no such injective map as $x$...\n- What is $m$ in equation in Proposition 4.1?\n- Can $\\mathcal{X}$ be continuous space or should is be discrete as well? If continuous how does $y\\in\\mathcal{X}$ in example 4.2.1 work?\n- Sentence after proposition 4.2 is not clear. \n- After definition 4.3 - \"we shown\" - where?\n- What is $m^r$?\n- \"This allows us to go beyond group discretizations that live in the grid without introducing interpolation artifacts.\" --> How?\n- Before section 5.1 - what is $\\mathcal{H}$?\n- In Proposition 5.2: shouldn't $\\mathcal{L}_g$ also be applied to $\\rho$?\n- Page 6: \"an space\".\n- Page 7: what are linear mappings on $\\mathcal{G}$?\n- Last paragraph before section 6: why is this layer maximally expressive for *sub-groups* of $\\mathbb{S}_N$.\n\nUPDATE:\nI thank the authors for their detailed response and edits. Overall, the authors have addressed my comments, but I have failed to understand some parts. I am still (slightly) positive about this work. >> Please check again for typos.", "title": "good progress, exposition and paper balance not sufficiently good....", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "vQMVbMs-7eh": {"type": "review", "replyto": "JkfYjnOEo6M", "review": "### Summary\nThe paper proposes an approach for building group-equivariant self-attention networks. The authors use group-invariant positional encodings, and thus the output of a self-attention layer is equivariant under the actions from the considered group. They empirically demonstrate that group-equivariant self-attention networks have an improvement over their non-equivariant counterparts.\n\n### Pros\n1. I enjoyed reading the paper. It has a clear title. The abstract, the intro, and the related work are well-written and give a clear understanding of the content of the paper. The technical sections are coherent and well-structured.\n2. The authors propose a general formulation of group-equivariant self-attention networks and rigorously prove their statements.\n3. The experiments demonstrate the improvements achieved by the added group-equivariance in image classification on several datasets.\n\n### Cons\nI did not find any major weaknesses in the presented paper. I did find some minor issues which, however, do not change the general impression and my decision.\n1. While the authors claim that the proposed formulation is general, they only consider 2 compact groups. A group of reflections and a discrete group of rotations. The authors also claim that current computational constraints restrict the possibility of training models with big vicinities until they converge. This issue can be especially important if a group of dilations (scaling group) is considered. The current scale-equivariant models of Bekkers 2020, Sosnovik et al. 2020, Worrall and Welling 2019, Romero et al. 2020 require one to process images with big filters. Is an implementation of a scale-equivariant self-attention network feasible given the current constraints? A discussion of these limitations would make the contribution of the current paper more clear.\n2. The authors use long equations with a very nested structure. Reading these equations is complicated given the current notation. The main source of confusion comes from repetitive sequences of brackets. A minor rethinking of the notation may improve the readability. For example, using square brackets when a function is an argument i.e. $\\alpha(f)(i, j) \\rightarrow \\alpha[f](i, j)$\n\nIt is a well-written paper. The theory is coherent. The text is easy-to-follow. The experimental section demonstrates a thorough evaluation of the proposed method. \n\n### After-rebuttal comments\nThe authors andwered my questions. My decision stays the same\n", "title": "An interesting paper with good evaluation", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "w-_srXVwjr": {"type": "review", "replyto": "JkfYjnOEo6M", "review": "***Summary***\n\nI would firstly like to thank the authors for an interesting read. I enjoyed going through the submission very much.\n\nThe submission outlines a general framework to make self-attention equivariant under the action of \u2018arbitrary\u2019 groups. The authors go about laying out the mathematical foundations of self-attention from a functional standpoint and then find the conditions that must be satisfied by the individual components of the attention mechanism to make it adhere to the imposed equivariance constraints. Namely, they note that absolute positional encodings must be done away with and that activations must be lifted to a homogenous space of the group in question in order for non-trivial (non-constant) relative positional encodings to be used. They experiment on the MNIST-rot, CIFAR10 and PatchCameylon datasets, but unfortunately the results fall significantly behind standard baselines.\n\n\n\n***Pros***\n\nThe paper is written very clearly and from what I could see the mathematics appears to be technically sound. \n\nThe authors also provide an in-depth appendix, which contains a lot of details as to group theory and their experiments.\n\nI think the primary objective of making self-attention equivariant is nice. I also think that the conclusion the authors come to makes sense and in someways (with hindsight, having read the paper) is to be expected. \n\nIn the experiments, the choices of which datasets to use make sense from the point of view of the equivariance literature.\n\nI like it how the authors explain that the networks are steerable by design because the group can act on the positional encodings.\n\n\n\n***Cons and constructive feedback***\n\nI would like to see a discussion comparing the proposed method with the works of \u201cAffine Self-Convolution\u201d by (Diaconu and Worrall, 2019), and \u201cAttentive group equivariant convolutional networks\u201d (Romero et al., 2019), which are both very close works in this area. What are the differences?\n\nThe results are quite disappointing. After the main theory I would have been happy with results en par with existing works, but CIFAR performance of, for instance, 83.7% compared to a baseline of 91.1% really isn\u2019t great. For me this is the main drawback of this work. Furthermore, how are the models comparable with the baselines? Are they matched in terms of numbers of parameters, or size of the activations, or something else? Perhaps this could be a source of the discrepancy between the results.\n\nI would also like to see comparisons with the work of Romero and Diaconu, who have results in their papers.\n\nIn the abstract you state that you can impost equivariance to arbitrary groups? Is this really so? Surely just compact, discrete groups?\n\nEquation 1: you introduce the notation \u2018sigma\u2019 for the softmax nonlinearity but then immediately use \\text{softmax} in eqn 1.\n\nEquation 7: what is the difference between the right hand part of the first line and the second line?\n\nDefinition 4.1: is this definition not overly restrictive by focussing on left-regular representations for L and L\u2019? It also precludes the use of irreducible representations as commonly used in the works on group equivariant networks.\n\nExample 4.2.1 I think this could have been stated more simply by specifying the group and action.\n\nDefinition 4.3 shown -> show\n\nProposition 4..2 Nor permutation nor translation -> Neither permutation nor translation\n\nSection 5.2: Good references here would be Theorem 3.1 of \u201cA General Theory of Equivariant CNNs on Homogeneous Spaces\u201d, (Cohen et al., 2018) and Theorem 1 of \u201cB-Spline CNNs on Lie Groups\u201d (Bekkers, 2020). Also, is this statement proven? I couldn\u2019t find it in the submission.\n\nSection 6. Efficient implementation\u2026: I would like to see more detail here since it is not clear in which way the implementation is efficient.\n\nJust a small note: you use American spelling throughout the paper, but missed out behaviour and neighbourhood, which should read behavior and neighborhood.\n\n***Post-rebuttal review***\n\nI have increasing my recommendation to a 6. This is on account of the improvements to the submission by the authors, a detailed rebuttal, and somewhat to align with the recommendations of the other reviewers. I still do find that the experimental results could be improved somewhat, but as another reviewer pointed out, this is not a huge concern within the majority of the equivariance literature. I thank the authors for an interesting read and thank you for a good rebuttal.\n", "title": "Initial review", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "HZ0JQ-wvtV5": {"type": "rebuttal", "replyto": "7CjZLvnkpj", "comment": "With this discussion period coming to an end, we would like to thank the reviewers for the time they invested in reviewing our paper and the insightful suggestions they made to improve our work.\n\nBest regards, \n\nThe authors.", "title": "Thank you for the reviews"}, "YPnW7KtVngL": {"type": "rebuttal", "replyto": "gTnzLKTbBS1", "comment": "**Furthermore, the explanations and notations are somewhat not coherent and clear, for example (eqs. 13, 14) are not sufficiently explained and demonstrated.**\nWe filtered out the incoherences mentioned by the reviewers in the new version of our work. In addition, We added a line intuitively explaining the definition of lifting and group self-attention right before the corresponding mathematical definitions. Additionally, we added a line in both definitions defining lifting and group self-attention in terms of vanilla self-attention (Eqs. 13, 15). We hope this makes them more accessible and gives more clarity on their modus operandi.\n\n**Although i dont think it is a necessary condition for publication of such paper, the results don't show an improvement over \"standard\" group convolution methods, although the authors claim expressiveness of their self-attention networks is at-least of that of generalized convolutions.**\nThis is true. However, we note that this is not the focus of the experimental part. Our focus is rather to evaluate GSA-Nets w.r.t. equivalent non-equivariant counterparts (the G-CNNs are included only for fair comparison) . Please see \"Summary of changes in the new version of our work.\" for a broader discussion on our experimental results.\n\n**Lastly, the last paragraph before section 6, describing the expressive power of these network is not sufficiently developed and justified.**\nWe will add a detailed discussion on this behavior in a new section of the appendix, which will be linked to the corresponding paragraph. \n\n**There are different notations for concat (word and union) and softmax (word and sigma).**\nThis has been resolved in the new version of the manuscript. \n\n**Equation 7 has some repeating unclear part.**\nThis has been resolved in the new version of the manuscript. \n\n**$X_i$ is not defined in equation 5.** This has been resolved in the new version of the manuscript. We now define $i, j$ before Eq. 5. \n\n**What is $m$ in equation in Proposition 4.1?**\n$m$ stands for multi-head self-attention. Please see Eqs. 9, 10.\n\n**Sentence after proposition 4.2 is not clear.**\nWe have rewritten this sentence. \n\n**After definition 4.3 - \"we shown\" - where?**\nWe built a semi-formal construction of why this is the case in Sec. 4.3. and Sec. 5. The formal proofs of our statements are given in Appx. G.\n\n**What is $m^{r}$ ?**\n$m^{r}$ stands for multi-head self-attention with relative positional encodings. Please see Eq. 11.\n\n**\"This allows us to go beyond group discretizations that live in the grid without introducing interpolation artifacts.\" --> How?**\nThis is due to the nature of the positional encoding, which is defined in a continuous space. Please see Sec. 5.1. in the new version of our paper. \n\n**Before section 5.1 - what is \\mathcal{H}?**\n$\\mathcal{H}$ comes from the definition of an affine group $\\mathcal{G} = \\mathbb{R}^{d} \\rtimes \\mathcal{H}$, where $\\mathcal{H}$ is a group acting on $\\mathbb{R}^{d}$. Please see Def. C.3. for further details.  \n\n**In Proposition 5.2: shouldn't  $\\mathcal{L}_{g}$ also be applied to $\\rho$ ?**\nNo. The reason is that the positional encoding is a construction of the operation and does not change as a function of the input. From page 4 in the absolute position paragraph:  \"Note that this encoding is not dependent on functions defined on the set but only on the set itself. footnote - Illustratively, one can think of this as a function returning a vector representation of pixel positions in a grid. Regardless of any transformation performed to the image, the labeling of the grid itself remains exactly equal. -\"\n\n**Page 6: \"an space\".** \nThis has been resolved in the new version of the manuscript. \n\n**Page 7: what are linear mappings on $\\mathcal{G}$?**\nA linear mapping on $\\mathcal{G}$ is a linear map whose domain is not $\\mathbb{R}^{d}$ anymore but the group itself $\\mathcal{G}$.\n\n**Last paragraph before section 6: why is this layer maximally expressive for sub-groups of $\\mathbb{S}_N$.**\nThis statement holds not only for sub-groups of $\\mathbb{S}_N$. Ravanbaksh (2020) recently proved that networks that build upon layers using regular representations are equivariant universal approximators provided global receptive fields. Since global group self-attention has a global receptive field and uses regular representations, it fulfills the requirements given by  Ravanbaksh (2020)'s theory. **[EDIT]:** We have now extended and developed the last paragraph of this section. \n\nOnce again, thank you very much for your time, attention and very useful commentaries. We sincerely appreciate the time you put in evaluating our approach. If you have any further questions or comments please let us know. We are more than happy to answer them :) \n\nBest regards,\nThe Authors.\n\n", "title": "Initial Response R5 -- Continuation --"}, "7CjZLvnkpj": {"type": "rebuttal", "replyto": "JkfYjnOEo6M", "comment": "Dear reviewers,\n\nFirst of all we would like to thank you very much for your thorough and valuable reviews and for the time you invested in writing them.  We have submitted a new revision of our work based on your observations. The quality of our manuscript has much improved based on your suggestions and we sincerely thank you for that. \n\nIn this comment we briefly summarize general changes to the document.  We will promptly address each of your individual concerns and questions as responses to each of your reviews.  \n\n#### Changes\n**General**: \n- We have improved the notation throughout the document (**R4**) and filtered out spelling inconsistencies and typos (**R1, R5**)\n\n**Sec. 2. Related Work**:\n- We largely modified the related work section. We included additional references suggested by the reviewers and better positioned our work w.r.t. related works (**R1, R3**).\n\n**Sec. 5. Group Equivariant Stand-Alone Self-Attention**\n\n* We have included an additional subsection **Sec. 5.1. Group self-attention is an steerable operation**. In this section we illustrate that (1) self-attention is a steerable operation (**R3**), and that (2) group self-attention is able to handle groups not contained in $\\mathbb{S}_{N}$ (**R5**).\n\n* We have added a line intuitively explaining the definition of lifting and group self-attention before the corresponding mathematical definitions. In addition, we added a line in both definitions that define lifting and group self-attention in terms of vanilla self-attention (**R3, R4, R5**). \n\n* We have now further extended and developed the discussion of the last paragraph of Sec. 5.3 on the expressivity of group self-attention (**R5**).\n\n**Sec. 6. Experiments**\n* We modified the first paragraph to emphasize the relevance of our experimental results (**R1, R3, R5**).\nSpecifically, we emphasize that the focus of our experiments is the evaluation of GSA-Nets with respect to *equivalent* non-equivariant self-attention networks. Convolutional architectures are included in our results *only* to provide a fair view to the yet present gap between self-attention and convolutional architectures in vision tasks, which is also present  for their group equivariant counterparts. In other words, our networks do not build upon these architectures.\nWe note that this performance gap is not unique to our work but universal to self-attention. Self-attention still has problems in outperforming convolutional nets for visual data. In fact this is a very active research direction, for which alternatives are also submitted to this ICLR 2021 (with good assessment scores) https://openreview.net/forum?id=YicbFdNTTy.  However, shall self-attention networks outperform convolutional networks, we expect that by making them group equivariant additional improvements can be obtained. \n* We included results from attentive G-CNNs (Romero et. al. 2020a) in our tables (**R1**).\n* We fixed a typo in the results of the **Z2_CNN** reported in the CIFAR-10 Table. The results are 90.56%, 1.37M instead of 91.08%, 1.44M.\n\n**Appendix**\n* We included a new section in Appx. E, **Current empirical aspects of scale equivariant self-attention**, where we briefly discuss current practical aspects on the implementability of GSA-Nets for the scaling group. (**R4**)\n\n**Important**: If we missed something you find important in our update please let us know. We will do our best to include it in our work.\n\nWe will now address each of your individual concerns and questions as responses to your reviews.  \n\nBest regards,\nThe authors. \n\n\n\n\n\n\n\n\n", "title": "Summary of changes in the new version of our work."}, "gTnzLKTbBS1": {"type": "rebuttal", "replyto": "xEOs98b6CI_", "comment": "Dear reviewer 5,\n\nFirst of all we would like to thank you very much for thorough, insightful review and for supporting our work.\n\nFirstly, we would like to clarify an important point of our work: \nWe note that our group self-attention is not only restricted to sub-groups of the permutation group. For example, in our experiments we consider multiple groups of rotations finer than 90 degrees, which cannot be described in terms of permutations and thus, are not a subgroup of  $\\mathbb{S}_{N}$. This comes from the fact that the positional encoding is defined in a continuous space, which is not restricted by any discrete grid (See Sec.5.1 for further details). **[EDIT]** We also modified the sentence after Def. 4.3 to accentuate that our approach is not limited to sub-groups of the permutation group.\n\nBased on this paragraph we now respond to the following comments:\n\n**What happens when the group action cannot be represented as a subgroup of permutations? (Page 4, lower part). That is, when there is no such injective map as $x$...** \nThe map $x$ is still injective for groups not contained in the permutation group (See example below and Sec.5.1). \n\n**Can $\\mathcal{X}$  be continuous space or should is be discrete as well? If continuous how does $y \\in \\mathcal{X}$ in example 4.2.1 work?**\nYes, $\\mathcal{X}$ is in fact continuous. Let us illustrate this with an example. Imagine that we take a picture of a flying bird with a clear sky as background. Then we represent the picture by a set $S=${$ i $}$_{i \\in S}$ . In this case, the position function $x(i)$ is given by the corresponding spatial coordinates $x(i) \\forall i \\in S$. Now, imagine that the bird flies $y$ centimeters further. We take our camera and get another picture.  Once more, we represent the picture by a set $S=${$ i' $}$ _{i' \\in S}$ with corresponding spatial coordinates $x(i') \\forall i' \\in S$. Note that the sets are equal as the resolution of the camera does not change. Also the positional encoding is equivalent as the space where the coordinates are defined ($\\mathcal{X}$) does not change. We can see that the pictures are exactly equal except for the values of the position function, which are now given by  $x(i') = x(i) + y$. As a result, we see that this operation is equivariant to translations. In particular the \"pixel\" $i'$ is equivalent to the \"pixel\" $i$ up to a transformation. Specifically we have that $x'(i') = x(i) + y$ or equally $i' = x'^{-1}(x(i) + y)$. The same logic holds for other transformations such as fine-grained rotations.\n\nNow we proceed with answering the rest of your questions, suggestions, comments and concerns:\n\n**A way to further restrict this equivariance to smaller sub-group of the permutations $\\mathcal{G}<\\mathbb{S}_N$ is by adding (or concatenating?) to the set of feature vectors, used as keys in the attention layer, functions which are invariant to this subgroup but not to any larger group.**\nThis is indeed the case. In order to demonstrate this, it is sufficient to follow the same steps as in the proof of the summation case considered in this work. The proofs boil down to a change of variables, which can also be done in the case of concatenations.\n\n **Overall, I feel this work offers some interesting observations relating symmetry and equivariance/invariance and self-attention. However, I find this work not fully ready in terms of exposition, ideas delivery and elaboration. The paper is not well balanced between developing and explaining its main contribution (starting page 6), and self-attention background. I understand there is much to cover, but explaining the main constructions in half a page is too short**\nWe understand that half a page to explain the main contribution is indeed too short. We have extended it in the new version of our manuscript and elaborated on some important properties of our approach (e.g., steerability). However, we respectfully disagree with your statement regarding the balance between the development and explanation of the paper's main contribution. An alternative to the current paper structure would be to instantiate right away Sec. 5 after introducing self-attention in Sec 3 and proceed with a \"top-down\" disentanglement of ideas. We considered this structure while constructing the paper but concluded that that structure made the paper much more difficult to read. As stated by some of the other reviewers, the paper is \"easy-to-follow\" and \"makes sense with hindsight having read the paper\". We argue that this is due to the progressive construction of ideas in Sec. 4, which is why we consider placing Sec 4 vital in order to progressively understand the contributions of the paper. In addition, we note that the contributions of the paper already start in Sec 4. In fact, to the best of our knowledge, several of the conclusions drawn in these part have not been proven before: Prop. 4.2, 4.3 and Sec. 4.3. We hope this sheds light into the importance of our structure selection.\n\n\n\n\n\n", "title": "Initial Response R5"}, "ixtrDT857B": {"type": "rebuttal", "replyto": "mQTDlCkObEN", "comment": "**Definition 4.1: is this definition not overly restrictive by focussing on left-regular representations for L and L\u2019? It also precludes the use of irreducible representations as commonly used in the works on group equivariant networks.**\nThis can indeed be extended to other type of representations. However, we restrict ourselves to regular representations as we exclusively develop theory and experiments for that kind of representations. Adding more general representations could elevate the difficulty of the paper and occlude its contributions. In addition, this helps us to position our work better w.r.t. existing literature (e.g., SE(3)-Transformers, Fuchs et. al., 2020).  \nWe note that the selection of regular representations is not arbitrary but based on theoretical and experimental indicating that they are more expressive than the irreducible ones (Weiler & Cesa, 2019; Ravanbakhsh, 2020).  \n\n**Example 4.2.1 I think this could have been stated more simply by specifying the group and action.**\nWe note that we construct this example using the action (or representation of the group) for set elements. Note that set elements the set $i \\in \\mathcal{S} $ cannot be translated as translation is not well-defined in the space of set indexes. In order to do so, the set element must be taken to an space where this action is well-defined ($\\mathcal{X}$ in the example). This is performed via the position mapping $x: i \\mapsto x(i) \\in \\mathcal{X}$. Once in this space, we can now apply a translation to the position of the index. For a translation given by $y$, its action is given by $x'(i) = x(i) + y$. However, as the function $f$ in Ex. 4.2.1 is defined on the set indexes space, we need to go back to this space. Consequently, we have that  $i' = x^{-1}(x(i) + y)$. \n\nAs a result, we see that the equivalent of the action of the group for the set space is given by $y * i = x^{-1}(x(i) + y)$ and the group representation for functions defined in this set is given by $\\mathcal{L}_{y}[f] (i) = f(y^{-1}*i) = f(x^{-1}(x(i) - y))$. This gives us the description shown in Example 4.2.1.  For more details on this operation please see Appx. D.\n\n**Definition 4.3 shown -> show** \nThis has been resolved in the new version of the manuscript.\n\n**Proposition 4..2 Nor permutation nor translation -> Neither permutation nor translation**\nThis has been resolved in the new version of the manuscript.\n\n**Section 5.2: Good references here would be Theorem 3.1 of \u201cA General Theory of Equivariant CNNs on Homogeneous Spaces\u201d, (Cohen et al., 2018) and Theorem 1 of \u201cB-Spline CNNs on Lie Groups\u201d (Bekkers, 2020).**\nWe have included these references in the new version of the manuscript.\n\n**Also, is this statement proven? I couldn\u2019t find it in the submission.**\nIt is not explicitly proven in the document. However, it is straightforwardly derived from the proof of equivariance for group self-attention (Appx. G).  In order to see this, it is sufficient to put away the non-linearities in the operation for a moment. I.e., define a \"linear self-attention\". From here one can conclude that the operation is equivariant as well (while being defined on set elements).  From here we can conclude the validity of the statement. We considered this to be sufficient for the submission. However, if you would like to see this explicitly in the document, we are happy to include this specifically in Appx. G.\n\n**Section 6. Efficient implementation\u2026: I would like to see more detail here since it is not clear in which way the implementation is efficient.** It is efficient in the sense that a naive implementation would require recomputing content attention values for each $\\mathcal{L}_{h}[\\rho], h \\in \\mathcal{H}$.\n\n**Just a small note: you use American spelling throughout the paper, but missed out behaviour and neighbourhood, which should read behavior and neighborhood.**\nThis has been resolved in the new version of the manuscript. Thank you for pointing this out.\n\nOnce again, thank you very much for your time, attention and very useful commentaries. We sincerely appreciate the time you put in evaluating our approach. If you have any further questions or comments please let us know. We are more than happy to answer them :) \n\nBest regards,\nThe Authors.\n\n\n\n", "title": "Initial Response R1 -- Continuation --"}, "mQTDlCkObEN": {"type": "rebuttal", "replyto": "w-_srXVwjr", "comment": "Dear reviewer 1,\n\nFirst of all we would like to thank you very much for thorough, insightful review. We are very happy to hear that you enjoyed reading the paper.\n\nNow we will answer to all of your questions, suggestions, comments and concerns:\n\n**I would like to see a discussion comparing the proposed method with the works of \u201cAffine Self-Convolution\u201d by (Diaconu and Worrall, 2019), and \u201cAttentive group equivariant convolutional networks\u201d (Romero et al., 2019), which are both very close works in this area. What are the differences?**\nWe largely modified the related work section. We included additional references and better positioned our work w.r.t. related works, e.g., Romero et al., 2019, Romero et al., 2020a, Fuchs et al., 2020. \n\n\n**The results are quite disappointing. After the main theory I would have been happy with results en par with existing works, but CIFAR performance of, for instance, 83.7% compared to a baseline of 91.1% really isn\u2019t great. For me this is the main drawback of this work. Furthermore, how are the models comparable with the baselines? Are they matched in terms of numbers of parameters, or size of the activations, or something else? Perhaps this could be a source of the discrepancy between the results.**\nWe modified the first paragraph of the Experiments section to emphasize the relevance of our experimental results. Specifically, we emphasize that the focus of our experiments is the evaluation of GSA-Nets with respect to equivalent non-equivariant self-attention networks. Convolutional architectures are included in our results only to provide a fair view to the yet present gap between self-attention and convolutional architectures in vision tasks, which is also present for their group equivariant counterparts. In other words, our networks do not build upon these architectures. We note that this performance gap is not unique to our work but universal to self-attention. Self-attention still has problems in outperforming convolutional nets for visual data. In fact this is a very active research direction, for which alternatives are also submitted to this ICLR 2021 (with good assessment scores) https://openreview.net/forum?id=YicbFdNTTy. However, shall self-attention networks outperform convolutional networks, we expect that by making them group equivariant additional improvements can be obtained.\n\n**I would also like to see comparisons with the work of Romero and Diaconu, who have results in their papers.**\nWe included results from attentive G-CNNs (Romero et. al. 2020a) in our tables. We do not add results from Diaconu & Worrall as they use different datasets or groups in their experiments.\n\n\n**In the abstract you state that you can impost equivariance to arbitrary groups? Is this really so? Surely just compact, discrete groups?**\nWe note that our self-attention *formulation*  is valid for continuous groups as well (for theoretical purposes). Though it is true that networks using this formulation cannot directly handle continuous groups in practice, we see that this is not detrimental in practice.  We have explicitly stated this behavior in a new paragraph above Section 5.1. \nSpecifically, using fine enough discrete groups seems to be sufficient.  This statement is based upon empirical evidence from our work as well as from extensive experiments in Weiler & Cesa, 2019, Tab 3, which indicate that performance saturates for fine discrete approximations of the underlying continuous group. In addition, networks handling fine enough discrete approximations consistently outperform networks handling continuous groups via irreducible representations. We further conjecture that this is a result of the networks receiving discrete signals as input. As the action of several group elements fall within the same pixel, no further improvement can be obtained.\n\n**Equation 1: you introduce the notation \u2018sigma\u2019 for the softmax nonlinearity but then immediately use \\text{softmax} in eqn 1.**\nThis has been resolved in the new version of the manuscript.\n\n**Equation 7: what is the difference between the right hand part of the first line and the second line?** This was a typo. This has been resolved in the new version of the manuscript.\n\n\n\n\n\n", "title": "Initial Response R1"}, "F8yWulU5d9C": {"type": "rebuttal", "replyto": "vQMVbMs-7eh", "comment": "Dear reviewer 4,\n\nFirst of all we would like to thank you very much for thorough, insightful review. We are very happy to hear that you enjoyed reading the paper and happy to see that you strongly support our work. Thank you! \n\nIn the following we elaborate upon the minor issues you raised:\n\n**The authors also claim that current computational constraints restrict the possibility of training models with big vicinities until they converge. This issue can be especially important if a group of dilations (scaling group) is considered. The current scale-equivariant models of Bekkers 2020, Sosnovik et al. 2020, Worrall and Welling 2019, Romero et al. 2020 require one to process images with big filters. Is an implementation of a scale-equivariant self-attention network feasible given the current constraints? A discussion of these limitations would make the contribution of the current paper more clear.**\nThis is a very important point indeed. In fact is difficult to come up with a working scale-equivariant self-attention network given the current constraints. Luckily, there is an option. It is possible to replicate the technique used in Worrall & Welling, 2019, for self-attention. Worrall & Welling, 2019 implement their method in terms of dilated convolutions by using a dyadic set of scales (see Fig. 3 of their paper). We believe that an equivalent self-attentional counterpart can be constructed. To this end, one can consider a \"sparse\" dilation of the neighborhood in self-attention in a way similar to dilated convolutions. This is an interesting application. However, the question remaining is how good would such a network be. Worrall & Welling, 2019 reported that this did not work very well in practice. We will briefly discuss this in more detail in Appx. E. \n\n**The authors use long equations with a very nested structure. Reading these equations is complicated given the current notation. The main source of confusion comes from repetitive sequences of brackets. A minor rethinking of the notation may improve the readability. For example, using square brackets when a function is an argument**\nWe implemented your bracket's suggestion across the paper. Indeed the readability remarkably improved. We also improve Eqs. 13 and 14 by (1) describing lifting and group self-attention in terms of vanilla self-attention, and (2) providing an intuitive description of their modus operandi. \n\nOnce again, thank you very much for your time, attention and very useful commentaries. We sincerely appreciate the time you put in evaluating our approach. If you have any further questions or comments please let us know. We are more than happy to answer them :) \n\nBest regards,\nThe Authors\n", "title": "Initial Response R4"}, "f4eHgP0c5bw": {"type": "rebuttal", "replyto": "JR95b8TqOAf", "comment": "**The paper concludes with the claim that linear mappings whose positional encoding is G-invariant are G-equivariant. This is easy to see in the definition of convolution and one can imagine this for linear mappings but it is difficult to see that self-attention is a linear mapping if one looks at eq. 5 and possible definitions of the encoding function (12). I see it through the equivalence proof in Cordonnier but not through the self-attention definition.**\nIn order to see this, it is sufficient to put away the non-linearities in the operation  for a moment. I.e., define a \"linear self-attention\". After one concludes that the operation is equivariant, one can proceed to analyze if the non-linearities disturb the equivariance property. This is inline with conventional procedures when analyzing the equivariance properties of convolutional architectures. Initially one considers a convolution without non-linearity and subsequently demonstrates that the non-linearity does not disrupt equivariance, which happens to be the case for the softmax operation.\n\n**Experiments do not show any advantage of equivariant self-attention in z2 or r4 CNNS.**\nThis is true. However, we note that this is not the focus of the experimental part. Our focus is rather to evaluate GSA-Nets w.r.t. equivalent non-equivariant counterparts. Please see \"Summary of changes in the new version of our work.\" for a broader discussion on our experimental results. \n\n**Last: Steerability is claimed in the abstract and the introduction but never mentioned again in the paper. One can somehow see how the positional encoding implies it but a section would be worth to be dedicated to it.**\nThis is an important point. We have included a section on this topic **Sec 5.1. Group self-attention is an steerable operation**. \n\nOnce again, thank you very much for your time, attention and very useful commentaries. We sincerely appreciate the time you put in evaluating our approach. If you have any further questions or comments please let us know. We are more than happy to answer them :) \n\nBest regards,\nThe Authors.\n\n\n\n", "title": "Initial Response R3 -- Continuation --"}, "JR95b8TqOAf": {"type": "rebuttal", "replyto": "jiKkjHqyeaf", "comment": "Dear reviewer 3,\n\nFirst of all we would like to thank you very much for thorough, insightful review and the time you invested in evaluating our work. We would also like to thank you for supporting our work.\n\nNow we will answer to all of your questions, suggestions, comments and concerns:\n\n**The authors have a very condensed related work section without going into any detail ....**\nWe have largely modified the related work section. We incorporated several of the references you specified and positioned our work better w.r.t. related works. \n\n\n**But probably most relevant is the missing discussion on equivariance on set networks (incl point cloud networks) and graph networks (Maron and Lipman).**\nDue to space constraints we unfortunately were not able to include a discussion in comparison to set networks. We note, however, it is not standard to find set-networks in group equivariant literature as set equivariant architectures manage equivariance in a different way. With that being said, we did include the work of Maron et al 2020 \"On Learning Sets of Symmetric Elements\". This work bridges these two families of models and we believe our insights nicely connect with their work and they might be useful for works in that direction. \n\n**There is no positional encoding in point clouds but the value at each element are the coordinates and some parallels can be drawn to positional encodings (for example first few layers of pointnet).**\nWe have briefly discussed the possibilities to use our work for graphs and other set-like structures as possible future direction by highlighting the connection between positional encodings and spatial coordinates (Sec. 7).\n\n**The functional formulation is elegant but difficult to follow. The authors might want to explain the benefits compared to tensor formulation.**\nWe agree that for permutations a formulation using matrices can be more appropriate. However, in the general spectrum of our work, matrix notation can be much more cumbersome than functional notation. For example, in order to represent translations by $t = (t_x, t_y)$, an important running example in our work, one must define a matrix [[0,0, $t_x$],[0,0,$t_y$]] and append a row of ones to the coordinates of the object being translated. Next, this procedure needs to be repeated to each of the coordinates of the object to be translated. \n\nThis procedure can quickly become cumbersome and difficult to understand, especially when these matrices change for different groups. This is for example the case for permutations w.r.t. the other groups considered in this work. Furthermore, matrix notation by itself can be difficult to understand for readers not acquainted with it. In order to avoid this, we decided to define the transformations in a way much more familiar to all of us which we have been using since high-school: a functional representation. For example, the translation of an object $f$ becomes $f(p_x-t_x, p_y-t_y)$ or simply $f(p - t)$. We note that the SE(3)-Transformer paper does not use tensor notation to define the convolution or prove translation equivariance. \n\n**Then they prove translational equivariance for relative positional encoding. It is easy to see that relative positional encoding is translation invariant. The step to equivariance has to be followed in the appendix and it would be easier for the reader to provide at least a sketch in the main text.**\nThis is indeed a valid point. Unfortunately, we did not have space to incorporate this in the main text. However, as you state, \"it is easy to see that relative positional encoding is translation invariant\". Considering the current constraints as well as the comments from the other reviewers, we decided to leave this part as it is. We hope you understand our decision. \n\n**The observation about translation paves the ground for generalizing to any group if the positional encoding is invariant to this group. Unfortunately, at this point the discussion becomes very confusing compared to the original \"lifting\" by Cohen and Welling (2016). While this paper makes the lifting appear as a trick, the main idea of Cohen and Welling...**\nWe apologize for the confusion in this paragraph. We have modified this paragraph to make it clearer. We now provide an analog to your sentence \"...one performs a group correlation where the output is a function of the group action...\" for the self-attention operation.\n\n\n\n\n", "title": "Initial Response R3"}, "jiKkjHqyeaf": {"type": "review", "replyto": "JkfYjnOEo6M", "review": "The authors describe their contributions in the introduction: the analysis of equivariance of self-attention, and how group invariance in the relative positional encoding enables group equivariance of the self-attention.\n\n\nThe authors have a very condensed related work section without going into any detail but with a lot of citations on (non attention) papers about equivariance. Works missed include Equivariant transformer networks by Tai et al., Equivariant multi-view networks (Esteves et al.), SO(3)-equivariant representations (Esteves et al. ), and early work on equivariant function spaces by Hel-Or and Teo (Canonical Decomposition of Steerable Functions).  \n\nBut probably most relevant is the missing discussion on equivariance on set networks (incl point cloud networks) and graph networks (Maron and Lipman). There is no positional encoding in point clouds but the value at each element are the coordinates and some parallels can be drawn to positional encodings (for example first few layers of pointnet). \n\nThe authors clearly define self-attention, first with matrices, and then with a functional formulation. The functional formulation is elegant but difficult to follow. The concatenation in the multi-head case is an example of where the vector space formulation allows replacing concatenation with a union. The authors might want to explain the benefits compared to tensor formulation.\n\nAuthors first prove permutation equivariance of global self-attention without positional encoding.\nThe proof in G.4.1 is kind of convoluted and might be clearer using only matrices (if $\\Pi$ is permutation than $\\sigma(\\Pi Q K^T \\Pi^T)\\Pi V = \\Pi \\sigma(Q K^T) V$.\n\nThen they prove translational equivariance for relative positional encoding. It is easy to see that relative positional encoding is translation invariant. The step to equivariance has to be followed in the appendix and it would be easier for the reader to provide at least a sketch in the main text. \n\nThe observation about translation paves the ground for generalizing to any group if the positional encoding is invariant to this group. Unfortunately, at this point the discussion becomes very confusing compared to the original \"lifting\" by Cohen and Welling (2016). While this paper makes the lifting appear as a trick, the main idea of Cohen and Welling is that when one applies group convolution on a quotient space, for example SE(2)-convolution on R^2, the result is automatically invariant in SO(2) since R^2=SE(2)/SO(2). Instead, one performs a group correlation where the output is a function of the group action (not of the quotient space) and after this step one applies a group convolution (also appearing in the spherical CNNs (Cohen)as well as in the icosahedral multi-view networks (Esteves)).\n\nThe paper concludes with the claim that linear mappings whose positional encoding is G-invariant are G-equivariant. This is easy to see in the definition of convolution and one can imagine this for linear mappings but it is difficult to see that self-attention is a linear mapping if one looks at eq. 5 and possible definitions of the encoding function (12). I see it through the equivalence proof in Cordonnier but not through the self-attention definition.\n\nExperiments do not show any advantage of equivariant self-attention in z2 or r4 CNNS.\n\nTo summarize the paper is interesting but quite difficult to follow. I wish the paper would follow the tensor notation like in the SE(3)-transformers. Authors should justify the superiority of their formalism vs tensors.\n\nRelated work should not be condensed with mere listing of citations like \\cite{*).\n\nLast: Steerability is claimed in the abstract and the introduction but never mentioned again in the paper. One can somehow see how the positional encoding implies it but a section would be worth to be dedicated to it. \n\n", "title": "This paper studies group equivariance properties of self-attention networks. Permutation equivariance follows from the self-attention definition while group equivariance depends on the definition of the positional encoding.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}