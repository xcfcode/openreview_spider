{"paper": {"title": "Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures", "authors": ["Pedro Hermosilla", "Marco Sch\u00e4fer", "Matej Lang", "Gloria Fackelmann", "Pere-Pau V\u00e1zquez", "Barbora Kozlikova", "Michael Krone", "Tobias Ritschel", "Timo Ropinski"], "authorids": ["~Pedro_Hermosilla1", "marco.schaefer@uni-tuebingen.de", "242528@mail.muni.cz", "gloria.fackelmann@uni-ulm.de", "pere.pau@cs.upc.edu", "kozlikova@fi.muni.cz", "michael.krone@uni-tuebingen.de", "~Tobias_Ritschel1", "~Timo_Ropinski2"], "summary": "We present a new neural network architecture to process 3D protein structures.", "abstract": "Proteins perform a large variety of functions in living organisms and thus play a key role in biology. However, commonly used algorithms in protein representation learning were not specifically designed for protein data, and are therefore not able to capture all relevant structural levels of a protein during learning. To fill this gap, we propose two new learning operators, specifically designed to process protein structures. First, we introduce a novel convolution operator that considers the primary, secondary, and tertiary structure of a protein by using $n$-D convolutions defined on both the Euclidean distance, as well as multiple geodesic distances between the atoms in a multi-graph. Second, we introduce a set of hierarchical pooling operators that enable multi-scale protein analysis. We further evaluate the accuracy of our algorithms on common downstream tasks, where we outperform state-of-the-art protein learning algorithms.", "keywords": ["classification", "bioinformatics"]}, "meta": {"decision": "Accept (Poster)", "comment": "Protein molecule structure analysis is an important problem in biology that has recently become of increasing interest in the ML field. The paper proposes a new architecture using a new type of convolution and pooling both on Euclidean as well as intrinsic representations of the proteins, and applies it to several standard tasks in the field. \n\nOverall the reviews were strong, with the reviewers commending the authors for an important result on the intersection of biology and ML. The reviewers raised the points of:\n- weak baselines (The authors responded with adding suggested comparison, which were not completely satisfactory)\n- focus mostly on recent protein literature\n- the reliance of the method on the 3D structure. The AC however does not find this as a weakness, as there are multiple problems that rely on 3D structure, which with recent methods can be predicted computationally rather than experimentally. \n\nWe believe this to be an important paper and thus our recommendation is Accept. As the AC happens to have expertise in both 3D geometric ML and structural biology, he/she would strongly encourage the authors to better do their homework as there have been multiple recent works on convolutional operators on point clouds, as well as intrinsic representation-based ML methods for proteins. "}, "review": {"lvFug2S-F5I": {"type": "review", "replyto": "l0mSUROpwY", "review": "This paper presents new convolutional and pooling operators for protein structures. These components are used to design an architecture that shows strong performance on several downstream tasks.\n\nThe main strength of the paper is the presentation of new ideas for modeling protein structures. The proposed operators leverage the intuition behind convolutional networks but extend them for the protein case, e.g. by introducing rotational invariance in addition to translational invariance. The ideas themselves are interesting to machine learning researchers and useful to those working proteins. Due to the complexity of the model, I recommend that the authors release their code so that other researchers could evaluate these ideas on additional problems. The writing and presentation is clear.\n\nWeaknesses:\n- More updated baselines should be used. For example, for the sequence-only baselines, the authors should compare to ProTrans [Elnaggar, et al. 2020] or [Rives, et al. 2019] which show better results than the baselines used here. On the structural side, the authors should compare to the architectures proposed by [Du, et al. 2019] or [Anand, et al. 2020]. \n- A key sequence baseline is missing: multiple sequence alignments.\n- The only tasks considered are classification tasks. The paper could be improved by evaluating on more practical tasks, such as protein design, e.g. the tasks in [Du, et al. 2019] or [Anand, et al. 2020]. The architecture described here could be very useful in those settings.\n- The authors compare to Bepler, et al. (2019) which is a great baseline since it uses both sequence and structural information. However, it appears from the text that the authors used the version of this model provided by Rao, et al. However, Rao et al. simply used the architecture from Bepler, et al. and re-trained it on sequence data only. Therefore, I recommend that the authors retrieve the weights from Bepler, et al. directly.\n- On the fold classification task, the hardest test set considered is \"Fold, in which proteins from the same superfamily are not present during training.\" It would be interesting to evaluate the model on a harder generalization setting in which proteins from the same fold are also not present during training. The delta between this model and DeepSF decreases when the sets go from family -> superfamily -> fold. To complete the picture, it would be important to go one step further.\n- Relatedly, the authors have not demonstrated that the models can generalize to novel folds. Without demonstrating this, the model cannot be used for important tasks, such as protein design. The paper would be much more compelling if the authors could show that their architecture generalizes better than prior work. To accomplish this, the authors would need to move beyond a classification framework toward a clustering framework because it's impossible for a classifier to predict novel folds.\n- The names of the test splits on the fold classification task is non-standard. Generally, \"fold split\" means that proteins from the same fold are not included in the same set; \"superfamily split\" means that proteins from the same superfamily are not included in the same set, etc. What the authors call the family split (\"in which proteins of the same family are present during training\") is usually not included as overfitting to / memorizing the training set could still result in good performance (perhaps this is why the proposed model scores 98.9% here).\n\nTo summarize the weaknesses: more work is needed on the baselines and metrics. Additional evidence is also needed to support that the model can generalize to unseen folds. \n\nOverall, this paper is a great start and the proposed model architecture could be interesting to ML researchers and practitioners in the biology space. In its current state, this is a borderline paper because it is missing a critical component of generalization of novel folds, which is necessary for this model to have significant impact in the field. If the authors can resolve my concerns during the rebuttal period, I am willing to raise my score.\n\nUpdate: The authors have included an additional experiment around fold generation in Sec 6.6. However, no baselines are included, so it is difficult to understand the result in context and understand how this method generalizes compared to existing methods. The authors have also included two additional baselines: Bepler, et al. and MSAs. More analysis is needed to compare this with SOTA in representation learning. The authors compare to \"Elnaggar et al. (2020)\" but it isn't clear which model was used. Elnaggar et al. (2020) have released a series of different models. The authors should clarify this in the camera-ready and ensure they used the best models released by Elnaggar et al. I have increased my score.", "title": "Interesting model architecture; but can the model generalize to unseen folds?", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "9TRw3pMaZdM": {"type": "review", "replyto": "l0mSUROpwY", "review": "This paper proposes a graph neural network architecture that operates on the atoms in a protein structure.\nIt proposes a specific multigraph and pooling model structure, constructed using Euclidian distance and 3 types of edges (Euclidian, covalent, and hydrogen+cov).\nThere are three consecutive levels of granularity, with nodes corresponding to: (1) atoms (2) amino acids and (3) grouped amino acids.\nThe model is used to make a global prediction for a protein, and results are presented on the taks of Fold Classification and Reaction classification.\n\nI recommend rejection for the paper in its current form, based on the concerns about the relevance of this method for fold classification (1/2 experiments), its framing as representation learning, and its framing as convolution vs graph neural networks.\n\n## Strenghts:\n* The two key model choices feel like a powerful choices for a graph neural network with an interesting domain-motivated set of architectural choices:\n  - construction of the hypergraph with shortest-distance edges of 3 types\n  - custom pooling of the graph from atom level nodes to groups of amino acids\n* The paper has helpful visualizations and well-written, however see below for concerns around framing.\n* Excellent ablation study in Table 2.\n\n## Weaknesses:\n* The key weakness is that the protein structure has to be provided as input to the network\n    - ~~therefore fold classification is a flawed experiment as the full atomic coordinates is all that's needed for perfect assignment to the folds. Specifically comparisons to sequence-only classification (TAPE, Unirep, etc) are misleading.~~\n    - as the authors point out, the amount of available data is tremendously less than sequence-only models. In fact the framing as \"representation learning\" is odd in this context, as there is no way to leverage unlabeled data, and no self-supervised objective is proposed.\n* I find the framing of the method somewhat misleading, on a few counts:\n    a) ~~representation learning~~ (see remarks abvove, no self-supervised + transfer of features)\n    b) naming the core layer of the model a \"convolution on 3D protein structures\" is off. A crucial element of standard convolution is the regularity of the domain, while this is intrinsically graph structured data. Furthermore I believe the method still fits in the \"neural message passing\" framework (see bullet below). Therefore the proposed architecture seems to be much better summarized as \"message passing graph neural network on a hierarchy of multi-graphs (hierarchy through protein pooling), with 3 types of graph edges defined by bonds and euclidian distances\".\n    c) after pooling, when vertices don't correspond to atoms but to clusters, the proposed convolution/GCN does not directly apply anymore. What are the edge connections at this stage?\n* I disagree with the phrase \"Although this operation could appear similar to message passing algorithms, they differ significantly\". I believe the method fits in the MPNN framework, roughly as follows (notation following Gilmer et al 2017, renaming x, xi to v, w):\n    - hidden state (per node) F_v with v the node (either atom, group of atoms, amino acid, cluster of amino acids depending on stage in the hierarchy)\n    - edge introduced if euclidian distance d(vw) < m_e\n    - edge features: 3 distances clamped [0,1]\n    - learned message function $M = \\kappa(e_{vw}) .  F_w$\n    - $h_v^{t+1} = m_v^{t+1}$ - or possibly including batchnorm and relu.\nThe above re-formulation is quite close to GCN from Kipf & Welling (2016) but with more complex learned message function function of the 3 distances.\n\n* Writing clarity: for eq (1) the notation needs to be introduced with dimensions (x, $\\kappa$, F). Specifically for kernel $\\kappa$ it needs to be made clear that $\\kappa_j$ is a function from $R^3 \\to R$ (?)\n* Comments on experimental results:\n    - ~~as mentioned above, I think fold classification is not an appropriate benchmark for this model~~\n    - for enzyme reaction classification, a sota method on this problem should be included as benchmark. Ryu et al 2019 (DeepEC) seems relevant here, or a method based on HMM profiles.\n\n-----\n### Edit: reply to author's response and updated paper \n(also see strikethroughs in the original review above)\n* Fold classification: let me withdraw my concern here, and will defer to other reviewers & AC judgement if this task makes sense with protein structure as input -- indeed it may not to be a trivial task. \n* Framing as (a) representation learning: improved in the updated paper, (b) convolution: still stands - the point cloud convs are not a very good comparison, since there is no graph structure there. (c) pooled coarsened graph stages: thanks for the pointer to end of Sec5.\n* Positioning wrt message passing: the paragraph is a big improvement, removing some claims about over-smoothing. However re: \"the message passing function is learned\": this is still very much within the default MPNN framework from Gilmer et al. Altogether, the whole method would still be much better framed as a graph-based network, rather than shoehorning this into a description of a single \"convolutional operator\".  This will allow a proper discussion of what is currently the end of Sec5, where the graph does not correspond to an atom-level graph anymore, rather they now correspond to amino acid or coarser level graphs - it is confusing that this coarser graph stages are so briefly glossed over.\n-- The citation to \"can also be understood in a message passing framework (Kipf & Welling, 2017)\" is off, should be \"Gilmer et al., 2017\" https://arxiv.org/abs/1704.01212 \n\nIn conclusion, I am raising my score from 4->5, leaning towards 6. There is a lot of good work in this paper, and I would consider the paper a clear accept with the same method and same results, if it were thoroughly rewritten based on graph neural networks. Requiring full atomic structure as input to the method is the major limitation to the application and impact of the method.", "title": "interesting architecture, but poorly framed, should be: multi-resolution graph MPNN", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "8c_y__Kbh3g": {"type": "rebuttal", "replyto": "yau7nsQ6n7P", "comment": ">What is the difference between the \u201cCovNeigh\u201d and the \u201cInConvC\u201d ablation.\n\nThe ablation independently studies the two steps of the unstructured convolution:\n1) to build a neighborhood $\\mathbf{x} \\in\\mathcal N(x_i)$ \n2) loop over all atoms and map multiple distances to $\\tau(\\mathbf x, \\mathbf x_i)$ to weights.\n\n\u201cCovNeigh\u201d would take (1) only those atoms that are linked by one type of chemical bound (covalent), and (2) perform as usual.\n\u201cInConvC\u201d would take (1) neighbours as usual, and (2) perform the kernel evaluation based on only one (the covalent) intrinsic distance.\nEssentially the first studies how the convolution input is built and the latter studies how it is weighted.\n---\n\n>On page 7, a **Table 4** is mentioned that doesn\u2019t appear to exist. I think they mean Table 3.\n\nYes, this is a mistake. It now points to **Table 3**.\n", "title": "Ablation studies clarification"}, "K47SH45Iqg3": {"type": "rebuttal", "replyto": "_z76ad0_t6Z", "comment": ">What would be the evidence for \u201cover-smoothing\u201d?\n\nAs we don\u2019t have evidence for this, we have removed this statement.\n\n---\n\n>Are there any \u201creplicates for standard error and ablation studies\u201d?\n\nUnfortunately we could not understand what the reviewer was referring to in this question. \n\n---\n\n>_JackHMMER_ or _HMMER_ are more appropriate comparisons than _BLAST_.\n\nThe revised paper now compares to _HHSuite_ in **Table 3**, which we understand to be the most recent and widely-accepted successor of _BLAST_.\nWe see the conclusion that ours (45.0% / 69.7% / 98.9% for fold/superfold/family) performs better than multiple sequence alignment (17.5% / 69.2 % / 98.6%) unaffected.\n\n---\n\n> Are hydrogens parameterized and how do you define hydrogen bonds? \n\nHydrogens are not considered since most of the protein structures come without hydrogens (crystallography-based acquisition used in PDB does not have enough spatial resolution to capture hydrogens) and if they have them, they are usually added by computational methods. We compute hydrogen bonds using DSSP _Kabsch and Sander, 1983_.\n\nThe revised paper now says \u201cAs several input proteins come without hydrogen bonds, they are computed in a pre-step using DSSP Kabsch and Sander (1983)\u201d.\n\n---\n\n>Does the modification of the architecture in **Table 2** change the number of parameters?\n\nYes, more layers, more parameters. Also, a higher number of hidden layers in the kernel increases the number of parameters.\n\n---\n\n>Can you define a \"ball query\"?\n\nThe paper now says \u201c.. ball query (a function returning all entities closer than $r$ to a point $x$)\u201d.\n\n---\n\n>How are post-translational modifications (PTMs) handled?\n\nPTM of amino acids and bound ligands or other molecules can provide cues of the function associated with the enzyme. Therefore, we only loaded atoms marked as \u201cATOM\u201d in the PDB files and we ignored atoms marked as \u201cHETATM\u201d.\n\n---\n\n>Are there any sequences with post-translational modifications (PTM) in the dataset? If so, how are those handled?\n\nYes, our data contains PTM in the sense of proteins that contain one or more amino acids from the 15 non-standard amino acids defined by _Nagata et al_ [2014]. To understand their importance, we split the test set of 5651 proteins total into a set with (598) and without PTM (2491). When repeating testing of our method, we find that the accuracy is 81.9% for PTM and 87.4% for non-PTM. This indicates both are handled well.\n", "title": "Multiple sequence alignment and post-translational modifications"}, "2ASyYz3k_GC": {"type": "rebuttal", "replyto": "9TRw3pMaZdM", "comment": ">Full atomic coordinates is all that's needed for perfect assignment to the folds. \n\nNot in practice.\n\n1) Using the sequence is an interesting theoretical problem indeed, but results are slow and of limited quality. HHSuite, for example, has an accuracy of 17.5%, while ours has 45.0%.\n\n2) Finding the right fold would require a database of all possible protein conformations and infinite time to search it exhaustively. In a finite world, this means that TM-align, a well-established package, requires 15 hours on six CPU cores to search 700 proteins against a reference set of 12k for an accuracy of 34%. We perform the same task in 16 seconds, trained on the same 12k proteins, at 45% accuracy, that is faster by three orders of magnitude.\n\nHow pressing this problem is, can be seen from the fact that the widely used Protein Data Bank has just recently adopted a new algorithm (https://tinyurl.com/yxgt67ff) for 3D structural similarity.\n\nFor similar reasons, one could also argue against using color in image classification: with it, things get easier. But using it right, if available, is an important problem to look into. In particular if it ultimately leads to better results.\n\n---\n\n>Comparisons to sequence-only classification (_TAPE_, _Unirep_, etc) are misleading.\n\nWe regret if this appears misleading to the reviewer, but we don\u2019t see a way to avoid this: To the one hand, leaving them out, one could question if 3D structure has any benefit at all. To the other hand, including them could be perceived as unfair as their task is harder. We now explain in the paper: \u201cThese methods are baseline that only have access to the sequence. Including them documents the benefits of using 3D structure.\u201d. \n\nPlease note how we do not only outperform sequence-based methods, but also all methods using 3D structure.\n\nPlease also note that there are several other 3D structure-based methods, that do not yet outperform sequence-based ones. To show this, the sequence-based baseline is required.\n\n---\n\n>Should this be called \u201crepresentation learning\u201d?\n\nWe have replaced \u201crepresentation learning\u201d with \u201cprotein learning\u201d.\n\n---\n\n> Is not calling this a \"convolution on 3D protein structures\" off, as it is not on a regular domain?\n\nThere is published work we cite that refers to learned operations on unstructured 3D point clouds as \u201cconvolutions\u201d\n\nhttps://arxiv.org/abs/1806.01759 (ACM Trans Graph 2018)\nhttps://arxiv.org/abs/1904.08889 (ICCV 2019)\n\nOur revised paper adds further citations along those lines\n\nhttps://arxiv.org/abs/1803.07289 (ACCV 2018)\nhttps://arxiv.org/abs/1811.07246 (CVPR 2019)\nhttps://arxiv.org/abs/1907.13079\n\n---\n\n> Where do edges come from after pooling when nodes are not atoms anymore?\n\nNew edges are created using Eq. 2 in the paper as it is stated in Sec. 5. The reviewer may also refer to Fig. 7 that visualizes old and new edges for all amino acids.\n\n---\n\n> When authors claim their operation \u201cappear similar to message passing algorithms\u201d, but \u201ddiffers significantly\", what is different?\n\nWe should be specific in how they differ, indeed.\n\nThe reviewer is correct to notice similarities: per-node state, edges to neighbors. We also believe the reviewer is right in noting the differences and novelty: learned message function, multiple metrics in one graph, using a hierarchy of graphs and pooling.\n\nSimilarity and differences can be phrased as unstructured convolution or as an extension of graph convolutions. We don\u2019t think it a weakness if a method can be explained in multiple frameworks.\n\nWe would not agree that our approach is in any sense a special case of _Kipf and Welling 2016_ (no edge features, one type of edges, no hierarchy, no learned message passing, nothing protein specific).\n\nA revised paper now replaces the original statement by the following: \u201cWhile we state our operation as an unstructured convolution (Hermosilla et al., 2018; Groh et al., 2018; Wu et al., 2019; Xiong et al., 2019; Thomas et al., 2019), it can also be understood in a message passing framework (Kipf & Welling, 2017) where hidden states are atoms, edges are formed based on spatial atom proximity and messages are passed between atoms. The key difference to existing work is, that we have edges for multiple kinds of bonds, use a hierarchy of graphs and that the message passing function is learned.\u201d\n\n---\n\n>Is the kernel in Eq. 1 a function from $\\mathbb R^3$ to $\\mathbb R$?\n\nYes, the revised paper now gives the signature of $\\kappa$.\n\n---\n\n> Could you compare to _Ryu et al. [2019]_ (DeepEC)?\n\nUnfortunately, we are not able to manage this within the rebuttal phase.\n", "title": "Fold task and framing of the method"}, "cpwMRq9YYZw": {"type": "rebuttal", "replyto": "IFYd1JRAH3", "comment": ">Will the code and trained models be made publicly available?\n\nThe code and training data is provided in the supplementary material already. Both will also be made public upon acceptance.\n\n---\n\n>Would authors acknowledge how homology information, drawn from, e.g., a sequence similarity search over a large protein database is a valuable source of additional information?\n\nWe did not use this information since we wanted to show that our method can learn end to end. However, this information could be easily incorporated by concatenating the features at the amino acid layer or at the atom level.\n\n---\n\n>The claim that \"As chain bindings affect the tertiary structure, the quaternary structure is captured implicitly.\" is a tautology and should be removed.\n\nWe agree and have removed this statement.\n", "title": "Additional input and code availability"}, "Ggx-od3JbAT": {"type": "rebuttal", "replyto": "lvFug2S-F5I", "comment": ">Will you release code?\n\nThe code can be found in the submitted supplementary material. The revised paper now includes the (anonymized) Github URL.\n\n---\n>Can it generalize to unseen folds?\n\nWe interpret this question to ask for one-shot learning: during testing, a network is presented with a protein from a fold unseen during training. Without having learned any classes, the method has to return the probability that the input protein is in the same fold as a reference protein, also not seen during training.\nFollowing _Koch et al.\u2019s_ popular \u201cSiamese Neural Networks for One-shot Image Recognition\u201d we have realized this challenging task with our architecture. During training, we withheld 50 out of the original 1195 folds. During testing, we compare all proteins contained in the test set to all proteins contained in a reference set that comprises out of all proteins, and thus represents all 1195 folds. From each test protein, we select the pair with higher probability to predict the fold. To analyze how accuracy is affected by folds unseen during training, we divided the Fold test set from Task 1 in two different test sets. Our _seen_ test set contains 400 proteins from 86 folds seen during training, while our _unseen_ test set contains 300 proteins from the 50 folds not seen during training. When analyzing how many proteins could be predicted correctly, we obtained an accuracy of 39.0% for _seen_ and an accuracy of 31.9% for _unseen_. This indicates that our method is able to generalize to folds that have not been seen during training. It also shows that our method is flexible enough to take concepts like the one from _Koch et al._, which uses hierarchical image convolutions, and generalize them to proteins. To view the obtained accuracies in the context of the other values reported in our paper, we also have trained the architecture for standard classification of Sec. 6.4 with the training set of this task, composed of  1145 folds. We obtained an accuracy of 46.5% when testing against the 86 folds compared to the 39% of the one-shot training.\nThe paper has been revised to include these experiments in the result **Sec. 6.6**.\n\n\n--- \n> Would clustering be an option for discovering new folds?\n\nWe did not yet explore the option of clustering in latent space. However, our convolutional architecture gives a good basis to build an encoder-decoder. Its latent space could be used in approaches like DEC by Xie et al. \u201cUnsupervised Deep Embedding for Clustering Analysis\u201d ICML 2016.\n\n---\n>Could you compare to multiple sequence alignment?\n\n\nThe revised paper now compares to _HHSuite_ in **Table 3**.\n\nWe see the conclusion that ours (45.0% / 69.7% / 98.9% for fold/superfold/family) performs better than multiple sequence alignment (17.5% / 69.2 % / 98.6%) unaffected.\n\n---\n>Should comparison to  _Bepler, et al_. be done using their weights, not the ones from _Rao et al._?\n\n\nWe downloaded _Bepler et al_\u2019s weights and added results to **Table 2**. The conclusions, including _Ours_ > _Bepler et al._ > _Rao et al._, are unaffected. \n\n---\n>Could you compare to _ProTrans [Elnaggar, et al. 2020]_\n\nWe have downloaded the code from the official repository and trained in our tasks. The revised version of the paper now includes these experiments.\n\n---\n>Could you compare to _Rives, et al. [2019]_ and / or  _Du, et al. [2019]_?\n\nThis comparison was too complex and lengthy and hence we weren't able to conduct it in the rebuttal phase.\n\n---\n>Could you compare to _Anand, et al. [2020]_?\n\n\nUnfortunately, we could not find code or data of that method to compare to.\n\n---\n>Are the names of the fold classification task standard?\n\nThe convention is adopted from Sec. 2.1 and Section I.1.1 of _Hou et al 2018_\u2019s \u201cDeepSF: deep convolutional neural network for mapping protein sequences to folds\u201d, who created the dataset. The same terminology was used by  _Rao et al._, \u201cEvaluating Protein Transfer Learning with TAPE\u201d. \n", "title": "Generalization to new folds and other experiments"}, "ItyLAjusH0Q": {"type": "rebuttal", "replyto": "l0mSUROpwY", "comment": "First, we would like to thank all the reviewers for their valuable comments and suggestions. We have uploaded a revised version of the paper addressing most of their concerns and we answered each reviewer separately summarizing each comment into a sentence followed by the response. \nSincerely, \nThe authors\n", "title": "Thank you for the reviews"}, "yau7nsQ6n7P": {"type": "review", "replyto": "l0mSUROpwY", "review": "__Summary__\nThe authors describe a method to transform 3D protein structures for supervised machine learning. Their method introduces a convolution operation that considers both the intrinsic distances between atoms as defined by their bond structure and the extrinsic distances as defined by 3D proximity. They also introduce interpretable pooling operations developed using known biology of the amino acids. Overall, the method is effective and straightforward to follow due to having avoided unnecessary complexity. The figures greatly aid the reader.\n\nThe authors\u2019 method outperforms a variety of competitive alternatives on protein fold and function classification tasks. These are important problems for which the authors\u2019 model has achieved a significant performance boost. I don\u2019t see why this model wouldn\u2019t work well for any 3D protein structure labels that can be collected. They also perform a through ablation analysis to establish the contribution of the various components of their method.\n\n__Major comments__\n* I wasn\u2019t able to understand what the \u201cneighborhood\u201d ablations represent and how they differ from \u201cconvolution\u201d ablations. Are the neighbors used for anything other than the convolutions? For example, \u201cCovNeigh\u201d uses only the intrinsic distances, similarly to \u201cInConvC\u201d. What makes these different?\n\n__Minor comments__\n* On page 7, a Table 4 is mentioned that doesn\u2019t appear to exist. I think they mean Table 3.", "title": "Clearly described method achieving significant 3D protein structure gains", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "_z76ad0_t6Z": {"type": "review", "replyto": "l0mSUROpwY", "review": "Pros:\n\n- I think the paper is exceptionally well-written and the figures are very carefully designed. Applaud!\n\n- Thank you for proper train/test/validation splits! Glad there are varying degrees of difficulty with proper held-out sequences.\n\n- I very much appreciate proper comparison to other methods. Very thorough.\n\n- Less important, but the model also performs better at these two tasks than any other approach. ( I say this because I believe the field shouldn't always require SoA if there is a significant technical advancement.)\n\nCons:\n\n- The authors site \"over-smoothing\" for why their convolution operator performs better, but provide no direct evidence that this is the case. It needs to be noted that this is either a hypothesis, or more concrete evaluation of this needs to be performed to make this claim.\n\n- Are there any replicates for standard error and ablation studies?\n\n- Table 3 BLAST comparison is weak. JackHMMER or HMMER based tools are more appropriate than BLAST.\n\nNeutral:\n\n- What defines a hydrogen bond? This definition is clear to me in secondary structure, but seems more loose in tertiary structure.\n\n- In your figures, it looks like only carbons, oxygens, and nitrogens are defined. What about hydrogens? If hydrogens aren't parameterized, how do you define hydrogen bonds? This may be good to clarify.\n\n- In Table 2, does the modification of the architecture change the number of parameters?\n\n- Definition of a \"ball query\" might be helpful.\n\n- Are there any sequences with post-translational modifications in the dataset? If so, how are those handled?", "title": "Novel biologically-inspired ML with promising results", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "IFYd1JRAH3": {"type": "review", "replyto": "l0mSUROpwY", "review": "This paper describes a deep learning architecture for representing and performing classifications on protein structures.  The representation involves three different distances: Euclidean distance and the shorted path between two atoms, where edges are either along covalent bonds or also include hydrogen bonds.  Each atom has a vector of associated features, and convolution is accomplished by defining a kernel on all three distances and then summing the features of each neighboring atom, weighted by the kernel value.  The paper also proposes three protein-specific pooling operations to cope with the large input size when representing all atoms in a protein.\n\nOverall, this is an extremely clear paper, and the core ideas appear to be sound.  Furthermore, the experimental validation is quite extensive, and the results are impressively good.  Some positive points are that the authors consider several different tasks, and numerous state-of-the-art methods are included in the comparison.  I particularly appreciated the careful ablation study, demonstrating not just that the entire system works end-to-end but that the various pieces each contribute to its behavior.\n\nThe experimental setup appears to be valid. There is always the chance that these results could be optimistic due to (presumably unintentional) model selection happening during development of the proposed method, or because of a mismatch between the training data used for the published models and the test set used here.  But I can't see how the authors could have done a better job to guard against such issues, other than the obvious step of making their code and trained models publicly available.  It is unfortunate that the manuscript makes no mention of this. \n\nOne drawback to this work is its focus on recent literature.  I found it strange that the earliest citation in the related work section is from 2013.  The tasks being solved here have been the focus of extensive research going back 25 years or more.\n\nThe manuscript is up front about the fact that a drawback of the method is its requirement that the input proteins have known 3D structure.  However, another potential drawback is that the input does not take into account homology information drawn from, e.g., a sequence similarity search over a large protein database.  This information is typically represented as a PSSM column for each observed amino acid.  I would like to have seen this acknowledged, since it seems like a potentially valuable source of additional information.\n\nA minor point: the introduction states that the model captures primary, seconary and tertiary structure, and then says that \"As chain bindings affect the tertiary structure, the quaternary structure is captured implicitly.\"  But of course, this argument could apply to any of the other levels: amino acid sequence implicitly captures secondary and tertiary structure.\n\nIncidentally, the Murzin cite has an incorrect year (1955).\n\n", "title": " A sophisticated deep learning architecture for learning from protein structures, well motivated and well tested", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}