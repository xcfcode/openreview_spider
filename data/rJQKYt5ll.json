{"paper": {"title": "Steerable CNNs", "authors": ["Taco S. Cohen", "Max Welling"], "authorids": ["taco.cohen@gmail.com", "m.welling@uva.nl"], "summary": "", "abstract": "It has long been recognized that the invariance and equivariance properties of a representation are critically important for success in many vision tasks. In this paper we present Steerable Convolutional Neural Networks, an efficient and flexible class of equivariant convolutional networks. We show that steerable CNNs achieve state of the art results on the CIFAR image classification benchmark. The mathematical theory of steerable representations reveals a type system in which any steerable representation is a composition of elementary feature types, each one associated with a particular kind of symmetry. We show how the parameter cost of a steerable filter bank depends on the types of the input and output features, and show how to use this knowledge to construct CNNs that utilize parameters effectively.", "keywords": []}, "meta": {"decision": "Accept (Poster)", "comment": "The AC fully agrees with reviewer #4 that the paper contains a bit of an overkill in formalism: A lot of maths whose justification is not, in the end, very clear. The paper probably has an important contribution, but the AC would suggest reorganizing and restructuring, lessening the excess in formalism. \n\nAs for the PCs, while we believe extending the experiments would further support the claims made in the paper, overall we still believe this paper deserves to appear at the conference as a poster."}, "review": {"S1DrbkkBx": {"type": "rebuttal", "replyto": "ryObh5bEg", "comment": "Thank you for your review. While state of the art results on CIFAR should not be undervalued (it is the most competitive dataset for comparison of CNN architectures), we agree that more large-scale validation would have been nice. We also believe that, as you say, the method may perform even better on problems where geometry plays a dominant role (action recognition, motion estimation, continuous control, etc.) and tasks where there is a clear symmetry (such as astrophysical data, histopathology slides, and so on). CIFAR has approximate rotation symmetry at small scales, but lacks full global symmetry. We see the fact that our method works very well despite this as an encouraging signal.", "title": "no title"}, "BkjFgJkBx": {"type": "rebuttal", "replyto": "B1TOvfQNe", "comment": "Thank you for your review and helpful suggestions. We have incorporated the proposed notational changes: we changed Z^d to Z^2 and now use a prime instead of layer index. We believe that this does indeed make the paper quite a bit easier to read.\n\nOther changes:\n- We have added several references to kernel-era work on equivariance. \n- Added a reference to Lenc & Vedaldi.\n- Fixed Balduzzi & Ghifary reference\n\nThanks again for carefully reading our manuscript, and the constructive feedback.", "title": "no title"}, "S1kCJJkBe": {"type": "rebuttal", "replyto": "H1TCu5EVe", "comment": "Thank you for your review and useful suggestions. We are glad to hear that you agree that steerability is a very important topic of research in deep learning.\n\nWe agree that the pioneering work on steerable filters should be recognized, so we have added references to early works by Simoncelli, Freeman, Adelson, Perona and Greenspan.\n\nYou are right that many of the ideas presented in the paper can be understood without higher mathematics. Still, we believe a mathematical treatment brings a lot of value, because it increases precision and generality, and establishes a bridge between fields.\n\nThe value of generality is exemplified by the fact that the mathematical theory carries over almost without change to the continuous setting.\n\nBy highlighting connections to advanced mathematical concepts and explaining them in a simple manner in the context of CNNs, we hope to foster future cross-fertilization between mathematics and machine learning. On the one hand, our work may provide an entry point for mathematicians and physicists who want to contribute to machine learning. On the other hand, machine learning researchers may benefit from the knowledge in the mathematical literature (as we have), but this requires knowing where to look. For this reason it is useful to know, for instance, that this structure we're dealing with in steerable CNNs is known as the \"induced representation\" by mathematicians, even if you were not familiar with the concept before, and could understand the basic idea without knowing its mathematical name.\n\nRegarding the description of the experiments: we will be releasing our code, which should answer any potential question about the experiments. In the mean time, if there are specific things you think are missing, we will add them.", "title": "no title"}, "H14tolGNx": {"type": "rebuttal", "replyto": "HJkKup-4g", "comment": "Thank you for your questions.\n\nThe mathematical theory can be generalized to continuous transformation groups relatively straightforwardly. The general ideas and concepts (decomposition of representations into irreducibles, intertwiners, etc.) remain roughly the same, but a formally correct treatment would have to be much more technical, which could make the material inaccessible to most machine learning researchers. More importantly perhaps, we have not actually implemented and evaluated our method for continuous groups. Doing so would require dealing with discretization and approximation, which may or may not work well in practice. In summary, we believe discrete groups to be a natural starting point, and believe the method can be extended to continuous groups, but we leave this for future work.\n\nThank you for those references, both look very interesting. I have looked at both papers briefly (and will do a more thorough reading soon). Here is my initial impression.\nKanazawa et al.: this paper proposes a scale-invariant convolution operation. I understand this as a group equivariant convolution (Cohen & Welling 2016) followed by a scale-pooling (It should be noted that Kanazawa et al. precedes our previous work). In our previous paper we found that for rotations, pooling to gain invariance is superior to standard convolution but less effective than equivariant convolution without pooling, but it remains to be seen whether that is true for scaling as well. Another difference to our current work is that Kanazawa et al. do not use representation theory, which allows us to reduce the number of parameters per filter bank, by constraining the latter to lie in the subspace of intertwiners. On the other hand, scaling is a continuous transformation, and hence is beyond the capabilities of our method as presented in this paper.\n\nMarcos et al.: this paper introduces a rotation equivariant convolution + rotation pooling operation, which is implemented by rotating each filter using a fixed set of angles. As mentioned before, we found rotation pooling to be suboptimal. On the other hand, Marcos et al. managed implement the method for an arbitrary set of angles instead of just 4 by using interpolation, and show good results on texture recognition.\n\nWe will discuss both of these references in our paper.", "title": "Answers"}, "HJkKup-4g": {"type": "review", "replyto": "rJQKYt5ll", "review": "1. How can more fine-grained transformations (e.g. rotations by less than 90 degrees, scaling, shear) be represented under the proposed framework? It seems that only transformations that can be achieved by permutation matrices are supported.\n\n2. How do you relate the proposed method w.r.t. the Scale/Rotation CNNs that have been previously proposed? [1][2]\n\n[1] Kanazawa et al., \"Locally Scale-invariant Convolutional Neural Network\", Deep Learning and Representation Learning Workshop, NIPS 2014.\n[2] Marcos et al., \"Learning rotation invariant convolutional filters for texture classification\", arXiv 2016.\nThe authors propose a parameterization of CNNs that guarantees equivariance wrt a large family of geometric transformations.\n\nThe mathematical analysis is rigorous and the material is very interesting and novel. The paper overall reads well; there is a real effort to explain the math accessibly, though some small improvements could be made.\n\nThe theory is general enough to include continuous transformations, although the experiments are restricted to discrete ones. While this could be seen as a negative point, it is justified by the experiments, which show that this set of transformations is powerful enough to yield very good results on CIFAR.\n\nAnother form of intertwiner has been studied recently by Lenc & Vedaldi [1]; they have studied equivariance empirically in CNNs, which offers an orthogonal view.\n\nIn addition to the recent references on scale/rotation deep networks suggested below, geometric equivariance has been studied extensively in the 2000's; mentioning at least one work would be appropriate. The one that probably comes closest to the proposed method is the work by Reisert [2], who studied steerable filters for invariance and equivariance, using Lie group theory. The difference, of course, is that the focus at the time was on kernel machines rather than CNNs, but many of the tools and theorems are relatable.\n\n\nSome of the notation could be simplified, to make the formulas easier to grasp on a first read:\n\nWorking over a lattice Z^d is unnecessarily abstract -- since the inputs are always images, Z^2 would make much of the later math easier to parse. Generalization is straightforward, so I don't think the results lose anything by it; and the authors go back to 2D latices later anyway.\n\nIt could be more natural to do away with the layer index l which appears throughout the paper, and have notation for current/next layer instead (e.g. pi and pi'; K and D instead of K_{l+1} and K_l).\n\nIn any case I leave it up to the authors to decide whether to include these suggestions on notation, but I urge them to consider them (or other ways to unburden notation).\n\n\nA few minor issues: Some statements would be better supported with an accompanying reference (e.g. \"Explicit formulas exist\" on page 5, the introduction of intertwiners on page 3). Finally, there is a tiny mistake in the Balduzzi & Ghifary reference (some extra information was included as an author name).\n\n[1] Lenc & Vedaldi, \"Understanding image representations by measuring their equivariance and equivalence\", 2015\n[2] Reisert, \"Group integration techniques in pattern analysis: a kernel view\", 2008\n\n", "title": "Questions", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "B1TOvfQNe": {"type": "review", "replyto": "rJQKYt5ll", "review": "1. How can more fine-grained transformations (e.g. rotations by less than 90 degrees, scaling, shear) be represented under the proposed framework? It seems that only transformations that can be achieved by permutation matrices are supported.\n\n2. How do you relate the proposed method w.r.t. the Scale/Rotation CNNs that have been previously proposed? [1][2]\n\n[1] Kanazawa et al., \"Locally Scale-invariant Convolutional Neural Network\", Deep Learning and Representation Learning Workshop, NIPS 2014.\n[2] Marcos et al., \"Learning rotation invariant convolutional filters for texture classification\", arXiv 2016.\nThe authors propose a parameterization of CNNs that guarantees equivariance wrt a large family of geometric transformations.\n\nThe mathematical analysis is rigorous and the material is very interesting and novel. The paper overall reads well; there is a real effort to explain the math accessibly, though some small improvements could be made.\n\nThe theory is general enough to include continuous transformations, although the experiments are restricted to discrete ones. While this could be seen as a negative point, it is justified by the experiments, which show that this set of transformations is powerful enough to yield very good results on CIFAR.\n\nAnother form of intertwiner has been studied recently by Lenc & Vedaldi [1]; they have studied equivariance empirically in CNNs, which offers an orthogonal view.\n\nIn addition to the recent references on scale/rotation deep networks suggested below, geometric equivariance has been studied extensively in the 2000's; mentioning at least one work would be appropriate. The one that probably comes closest to the proposed method is the work by Reisert [2], who studied steerable filters for invariance and equivariance, using Lie group theory. The difference, of course, is that the focus at the time was on kernel machines rather than CNNs, but many of the tools and theorems are relatable.\n\n\nSome of the notation could be simplified, to make the formulas easier to grasp on a first read:\n\nWorking over a lattice Z^d is unnecessarily abstract -- since the inputs are always images, Z^2 would make much of the later math easier to parse. Generalization is straightforward, so I don't think the results lose anything by it; and the authors go back to 2D latices later anyway.\n\nIt could be more natural to do away with the layer index l which appears throughout the paper, and have notation for current/next layer instead (e.g. pi and pi'; K and D instead of K_{l+1} and K_l).\n\nIn any case I leave it up to the authors to decide whether to include these suggestions on notation, but I urge them to consider them (or other ways to unburden notation).\n\n\nA few minor issues: Some statements would be better supported with an accompanying reference (e.g. \"Explicit formulas exist\" on page 5, the introduction of intertwiners on page 3). Finally, there is a tiny mistake in the Balduzzi & Ghifary reference (some extra information was included as an author name).\n\n[1] Lenc & Vedaldi, \"Understanding image representations by measuring their equivariance and equivalence\", 2015\n[2] Reisert, \"Group integration techniques in pattern analysis: a kernel view\", 2008\n\n", "title": "Questions", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rkrt94jml": {"type": "rebuttal", "replyto": "HJs5qGjXg", "comment": "Dear Shuang,\n\nThanks for your comments. I've answered your questions below.\n\n- is there code available for this work?\nWe will publish the code, but we would like to clean it up first. We do have code for our previous paper on group equivariant networks, which is a special case of steerable CNNs:\nhttps://github.com/tscohen/GrouPy\nhttps://github.com/tscohen/gconv_experiments\n\nNote that while G-Convs are mathematically equivalent to steerable convs with regular features, they are implemented differently. The G-Conv is implemented as \"filter indexing\" + \"classical convolution\". Filter indexing involves taking a filter bank and turning it into a larger (e.g. 8x) filter bank through a fixed indexing operation. In the steerable convolution, the filter indexing is replaced by a more general block-sparse linear map (the intertwiner basis). In the case of regular features, this linear map is a permutation matrix, and indeed multiplication by a permutation matrix could be implemented as an indexing operation.\n\n- how difficult (time-consuming) to train steerable CNNs on dataset such as ImageNet?\nComputing a steerable convolution (at train time) involves a block-sparse linear transformation to obtain a filter bank, followed by a classical convolution using that filter bank (at test time the block-sparse linear transformation can be pre-computed). The bulk of the computation time is in the classical convolution, so roughly, the computation time is determined by the size of this filter bank. In practice, steerable convolutions allow you to create bigger filter banks, so computation time is increased proportionally.\n\nHowever, because of increased parameter sharing the gradients for G-Convs and steerable convs are much less noisy, and optimization is much faster in terms of number of updates required. In our experience, this largely offsets the increase in computation time that comes from having bigger filter banks, but we have yet to investigate this systematically and quantify it properly.\n\nAt this point (2016), the bottleneck will likely be GPU memory: with a reasonable batch size you will probably run out of memory before you get to the optimal model size. This situation could be improved substantially through code optimization and multi-GPU training (or waiting for better hardware).\n\n- How does steerable CNN compare against common CNNs such as ResNet or Inception in well-benchmarked tasks such as image classification? I feel the experiment section can be strengthened by add such results.\nI agree. While results on CIFAR usually transfer well to imagenet (e.g. ResNets), it would be nice to do more benchmarking. We have relatively modest computational resources so we have not yet tried to run on imagenet yet. I'm currently at OpenAI working on unrelated (deep reinforcement learning) projects, but would be happy to assist anyone wanting to try G-convs and steerable convs on larger datasets.\n\n- Is there any reason besides mathematical simplicity to choose p4m? what about other group in the wallpaper group set?\nThe main reason for working with p4m is indeed mathematical simplicity. Since we are introducing a number of abstract concepts that are likely new for most ML researchers, we think that having a single concrete running example makes the paper more readble.\n\nHowever, the general theory is directly applicable to any discrete group, including all wallpaper groups in 2D and space groups in 3D. The theory also applies to other groups like permutation groups. Permutation-steerable neural networks could be useful for learning from data with permutation symmetry (chapter 5 of the  great book \"Group Representations in Probability and Statistics\" by Persi Diaconis gives some examples). \n\nOf all the wallpaper groups and space groups, the most interesting ones are \"split groups\" (AKA \"symmorphic groups\"). This means that each transformation in the group can be written as the composition of a transformation that leaves the origin invariant (e.g. rotation about the origin) and a translation. For these groups, the steerable convolutions can be implemented efficiently using a single call to the classical conv routine. This is very important if you want to use steerable convolutions now, but in the future all kinds of steerable convolutions can be implemented efficiently  with custom GPU code (in fact, it is likely that the group representation structure can be exploited to make these networks much faster than standard neural nets).\n\n- What are possible huddles to extend it to continuous group? What if we want to just consider finite group such as D_n instead of continuous group such as SO(2)?\nSteerable CNNs can be implemented for any discrete space with a discrete group acting on it. Strictly speaking D_n does not act on Z^2, because it could send integer coordinates (m,n) to non integer points in the plane. It seems like some kind of interpolation would be necessary to deal with this. Before publishing our previous paper \"Group Equivariant Convolutional Networks\", we experimented a little bit with interpolation to rotate filters, but couldn't get it to work very well. From preliminary experiments it seems that the interpolation artefacts / approximation errors would accumulate with depth, eventually destroying equivariance. It is quite possible that with more effort, and perhaps some signal processing tricks, this can be made to work.\n\nNow that we have steerable CNNs, other approaches may be possible as well. In the literature on steerable filters, as well as most of signal processing, the mathematical theory is developed for the continuous case, and the transition to discrete data is either glossed over or justified with some bandlimit assumption. Similarly, we could develop the theory for continuous groups and then discretise somehow. As long as the (irreducible) representations of H are finite-dimensional (which is the case if H is compact), it should be possible to compute (either analytically or numerically) the (approximate) intertwiner bases. Another approach could be to learn representations that are approximately equivariant by introducing some auxiliary loss functions.\n\nTomaso Poggio's group has published a number of interesting theoretical papers that work with locally compact (not compact) topological groups, e.g. [1]. Although these papers don't deal with group representation theory, and are not concerned with implementation details, they could give some hints about how to approach the continuous case.\n\n- PS: In the sentence right after equation (6) there is an equation for \\pi_{l+1}, there is g on the LHS, I assume g should also appear on the RHS? \nYes, that's another typo. Thanks for catching these!\n\n[1] Anselmi, F. J.Z. Leibo, L. Rosasco, J. Mutch, A. Tacchetti, and T. Poggio. Unsupervised learning of invariant representations with low sample complexity: the magic of sensory cortex or a new framework for machine learning?. CBMM Memo No. 001. arXiv:1311.4158v5. March 2014.", "title": "answers"}, "HJs5qGjXg": {"type": "rebuttal", "replyto": "rJQKYt5ll", "comment": "Hi, Taco,\n  Great paper, I have a few comments/questions:\n- is there code available for this work?\n- how difficult (time-consuming) to train steerable CNNs on dataset such as ImageNet?\n- How does steerable CNN compare against common CNNs such as ResNet or Inception in well-benchmarked tasks such as image classification? I feel the experiment section can be strengthened by add such results.\n- Is there any reason besides mathematical simplicity to choose p4m? what about other group in the wallpaper group set?\n- What are possible huddles to extend it to continuous group? What if we want to just consider finite group such as D_n instead of continuous group such as SO(2)?\n\nThanks.\n\nPS: In the sentence right after equation (6) there is an equation for \\pi_{l+1}, there is g on the LHS, I assume g should also appear on the RHS? ", "title": "a few questions"}, "ByaTNddXl": {"type": "rebuttal", "replyto": "rJ1kgKwXx", "comment": "Thank you for catching these, and thanks for the kind words. We will correct these in the next version.", "title": "Correct"}, "S104N_d7x": {"type": "rebuttal", "replyto": "r1YkTXkXg", "comment": "We chose CIFAR because it allows for relatively quick experiments, because it is highly competitive so getting state of the art results is meaningful, and because a strong result on CIFAR demonstrates that the symmetry assumption does not need to be satisfied exactly at all scales. You are right to point out that CIFAR lacks full rotation symmetry at the largest scale (e.g. it does not contains cars in upside down position), but there is still an approximate symmetry at smaller scales. Our results show that this approximate symmetry can be effectively exploited by steerable CNNs, and that the difference in performance is quite substantial for this dataset.", "title": "dataset choice"}, "rJ1kgKwXx": {"type": "rebuttal", "replyto": "rJQKYt5ll", "comment": "- In the sentence right about equation (1), isn't it better to write \"... a linear operator \\pi_0(g): F_0 \\rightarrow F_0.. \" since \\pi_0 is clearly defined for the case l = 0 as indicated by its subscript.\n- right before equation (3), isn't it better to write \" ... we need the filter bank \\Psi: F_l \\rightarrow R^{K_{l+1}} ...\" since F here is for layer l specifically.\n\nI am not sure I am reading the most recent revision, so forgive me if these things have already been fixed.\n\nGreat paper, by the way.\n\nShuang", "title": "a few minor notation corrections"}, "r1YkTXkXg": {"type": "review", "replyto": "rJQKYt5ll", "review": "Considering that the proposed method is supposed to improve spatial accuracy, \nwhy didn't the authors choose a better data-set to demonstrate this? It seems \nthat CIFAR-10/100 requires only very coarse spatial information to infer the class.  \nThis paper essentially presents a new inductive bias in the architecture of (convolutional) neural networks (CNN). The mathematical motivations/derivations of the proposed architecture are detailed and rigorous. The proposed architecture promises to produce equivariant representations with steerable features using fewer parameters than traditional CNNs, which is particularly useful in small data regimes. Interesting and novel connections are presented between steerable filters and so called \u201csteerable fibers\u201d. The architecture is strongly inspired by the author\u2019s previous work, as well as that of \u201ccapsules\u201d (Hinton, 2011). The proposed architecture is compared on CIFAR10 against state-of-the-art inspired architectures (ResNets), and is shown to be superior particularly in the small data regime. The lack of empirical comparison on large scale dataset, such as ImageNet or COCO makes this largely a theoretical contribution. I would have also liked to see more empirical evaluation of the equivariance properties. It is not intuitively clear exactly why this architecture performs better on CIFAR10 as it is not clear that capturing equivariances helps to classify different instances of object categories. Wouldn\u2019t action-recognition in videos, for example, not be a better illustrative dataset? \n", "title": "dataset choice", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "ryObh5bEg": {"type": "review", "replyto": "rJQKYt5ll", "review": "Considering that the proposed method is supposed to improve spatial accuracy, \nwhy didn't the authors choose a better data-set to demonstrate this? It seems \nthat CIFAR-10/100 requires only very coarse spatial information to infer the class.  \nThis paper essentially presents a new inductive bias in the architecture of (convolutional) neural networks (CNN). The mathematical motivations/derivations of the proposed architecture are detailed and rigorous. The proposed architecture promises to produce equivariant representations with steerable features using fewer parameters than traditional CNNs, which is particularly useful in small data regimes. Interesting and novel connections are presented between steerable filters and so called \u201csteerable fibers\u201d. The architecture is strongly inspired by the author\u2019s previous work, as well as that of \u201ccapsules\u201d (Hinton, 2011). The proposed architecture is compared on CIFAR10 against state-of-the-art inspired architectures (ResNets), and is shown to be superior particularly in the small data regime. The lack of empirical comparison on large scale dataset, such as ImageNet or COCO makes this largely a theoretical contribution. I would have also liked to see more empirical evaluation of the equivariance properties. It is not intuitively clear exactly why this architecture performs better on CIFAR10 as it is not clear that capturing equivariances helps to classify different instances of object categories. Wouldn\u2019t action-recognition in videos, for example, not be a better illustrative dataset? \n", "title": "dataset choice", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "SkZBO_yzl": {"type": "rebuttal", "replyto": "rJQKYt5ll", "comment": "In response to the following comment from Kenta Oono, we have uploaded a new version of the paper.\n\n\"I saw your paper submitted to ICLR 2017, Steerable CNNs.\n\nIt is wonderful as it is theoretically well founded with the representation theory and also takes engineering easiness into consideration. Further, it achieves state of the art result in CIFAR datasets. So I would like to understand the paper in detail.\n\nAs I read the paper, I encountered the problem that I could not derive some of equations (specifically, (5) in the paper). [...]\"\n\nThe problem he identified was due to a small mistake in eq. 4 (a missing inverse). In the new version we have fixed this and added an appendix where eq. 5 (the induced representation) is derived.", "title": "Revision uploaded"}}}