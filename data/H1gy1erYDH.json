{"paper": {"title": "CaptainGAN: Navigate Through Embedding Space For Better Text Generation", "authors": ["Chun-Hsing Lin", "Alvin Chiang", "Chi-Liang Liu", "Chien-Fu Lin", "Po-Hsien Chu", "Siang-Ruei Wu", "Yi-En Tsai", "Chung-Yang (Ric) Huang"], "authorids": ["jsaon92@gmail.com", "alvin.chiang.180@gmail.com", "liangtaiwan1230@gmail.com", "gblin75468@gmail.com", "cph@yoctol.com", "raywu0@gmail.com", "ypiheyn.imm02g@g2.nctu.edu.tw", "cyhuang@ntu.edu.tw"], "summary": "An effective gradient-based method for training a text generating GAN", "abstract": "Score-function-based text generation approaches such as REINFORCE, in general, suffer from high computational complexity and training instability problems. This is mainly due to the non-differentiable nature of the discrete space sampling and thus these methods have to treat the discriminator as a reward function and ignore the gradient information. In this paper, we propose a novel approach, CaptainGAN, which adopts the straight-through gradient estimator and introduces a \u201dre-centered\u201d gradient estimation technique to steer the generator toward better text tokens through the embedding space. Our method is stable to train and converges quickly without maximum likelihood pre-training. On multiple metrics of text quality and diversity, our method outperforms existing GAN-based methods on natural language generation.", "keywords": ["Generative Adversarial Network", "Text Generation", "Straight-Through Estimator"]}, "meta": {"decision": "Reject", "comment": "This paper proposes a method to train generative adversarial nets for text generation. The paper proposes to address the challenge of discrete sequences using straight-through and gradient centering. The reviewers found that the results on COCO Image Captions and EMNLP 2017 News were interesting. However, this paper is borderline because it does not sufficiently motivate one of its key contributions: the gradient centering. The paper establishes that it provides an improvement in ablation, but more in-depth analysis would significantly improve the paper. I strongly encourage the authors to resubmit the paper once this has been addressed."}, "review": {"B1elMaV2oS": {"type": "rebuttal", "replyto": "S1gEyFXnjH", "comment": "Reply to the first question: Yes.\n\nThe main purpose of constraining Lipschitz constant is to make the gradient informative even if the supports of real samples and generated samples are completely disjoint (or, make the loss surface between two supports smooth). In this case, the discriminator can still be confident about its output.\n\nWe have cited Arjovsky & Bottou (2017) & Zhou et al. (2019). We hope the detailed discussion about gradient vanishing and gradient uninformativeness of these works can help us explain it.\n\nAfter that, the main problem with continuous relaxation is that the generator is led to produce spiky outputs since it must force it's distribution over tokens to be like the real data, which is a one-hot encoded token.\nSpectral normalization can help continuous relaxations but overall the discriminator will still influence the generator to produce spiky outputs (alternatively, we could let the word embeddings non-trainable to make the input of discriminator be word embeddings instead of probability).\n\n\nReferences:\n- Mart\u00edn Arjovsky and L\u00e9on Bottou. Towards principled methods for training generative adversarial networks. ArXiv, abs/1701.04862, 2017.\n- Zhiming Zhou, Jiadong Liang, Yuxuan Song, Lantao Yu, Hongwei Wang, Weinan Zhang, Yong Yu, and Zhihua Zhang. Lipschitz generative adversarial nets, 2019. \n", "title": "Reply"}, "rylorjQ2jr": {"type": "rebuttal", "replyto": "H1gy1erYDH", "comment": "Summary of major changes\n\nWe thank all the reviewers for their insightful comments. Your suggestions have helped us to make important revisions to our paper. Major changes are as follows:\n\n- A table of notation has been added in Appendix A. \n- A new section (2.1 - Continuous Relaxations) has been added. We hope it is helpful to demonstrate the difference between approaches to non-differentiability. \n- Section 5.5 has been rewritten to better explain the unusually high perplexity in response to Reviewer #3.\n- Section 5.7 has been revised to clarify the contribution of our work.\n\nAdditions that will be made in the final submission:\n- error-bar: More experiments will be conducted (using different random seeds) for providing an average performance and confidence intervals for CaptainGAN.\n- perplexity distribution: A perplexity distribution will be plotted for showing the severity of mode dropping.", "title": "Summary of major changes"}, "rygzfExniB": {"type": "rebuttal", "replyto": "HkxM_SnKjr", "comment": "Sorry for the late reply. \n\nWe've rewritten the section 5.5 and have a response at https://openreview.net/forum?id=H1gy1erYDH&noteId=HkeF9zh9jS . ", "title": "Reply to Reviewer #3 about section 5.5"}, "H1lbVbx2iH": {"type": "rebuttal", "replyto": "rkl9nFTF9H", "comment": "Regarding the contribution:\n\nYes, the straight-through estimator helps avoid the drawback of the score-function estimator by providing extra information, which is the gradient of the discriminator, to the generator from the discriminator. There is technically an infinite number of possible \u201cstraight-through estimators\u201d. The one we think of as the straight-through estimator is just the most obvious way to define the backward gradient (by pretending the activation is an identity function) - but there is no reason to think that it is the best. Thus it is worth searching for modifications.\n\nSpectral normalization is not so much an \u201caddon\u201d as it is a crucial prerequisite for our method. Since we want to incorporate the gradient of the discriminator in the generator, we need to bound the Lipschitz constant of the discriminator (using spectral normalization) and makes it possible for the generator to use gradient of the discriminator effectively. For more details, please see the revised version of section 5.7. \n\nOur experiments show that the recentering trick increases 20% FED compared to the baseline straight-through estimator (both using spectral normalization), which is why we feel it is worth incorporating.", "title": "Reply to Reviewer #2"}, "HkeF9zh9jS": {"type": "rebuttal", "replyto": "HJgZb4nntr", "comment": "Regarding the explanation of unusually high perplexity:\n\nWe\u2019ve rewritten Section 5.5 to better explain the unusually high perplexity. The main reason is CaptainGAN minimizes different objective from MLE models. This objective assigns an extremely low cost to mode dropping and does not force the generator to mimic all aspects of real data. This can result in poor modeling of the likelihood but does not necessarily lead to poor sample generation. For more details, please see the revised version of section 5.5. Moreover, we are planning to add more experiments to measure the severity of mode dropping. Due to the time constraint, we will report the result at the final submission.", "title": "Reply to Reviewer #3 "}, "HJxoXOKqoB": {"type": "rebuttal", "replyto": "HJgZb4nntr", "comment": "Regarding the lack of information about RelGAN:\n\nRelGAN is a GAN architecture using the Gumbel-Softmax estimator. In our revision, we\u2019ve added a subsection (2.1 Continuous Relaxations) to explain the drawback of using the Gumbel-Softmax estimator. Also, we\u2019ve added RelGAN scores to Figure 3 and Figure 6. We show that CaptainGAN is competitive with RelGAN (without additional pretraining before adversarial training) in terms of Bleu/SelfBleu and outperforms RelGAN\u2019s FED score.\n", "title": "Reply to Reviewer #3"}, "BkxpntgtoB": {"type": "rebuttal", "replyto": "HJgZb4nntr", "comment": "Regarding the report of an average performance with confidence interval using different random seeds:\n\nThank you for the suggestion. Providing average performance and confidence intervals is important. However, due to time constraints, we will not be able to add the results before 11/15. Instead, we will try to include the results in our final submission.", "title": "Reply to Reviewer #3"}, "BylGeUlKiS": {"type": "rebuttal", "replyto": "rkl9nFTF9H", "comment": "Regarding the question about the difference between the work of Kusner & Hern\u00e1ndez-Lobato (2016) and our work:\n\nWe\u2019ve added a subsection (2.1 Continuous Relaxations) which explains the difference between the work of Kusner & Hern\u00e1ndez-Lobato (2016) and our work. We specifically do not use Gumbel-Softmax Estimator for text generation. As explained in our revision, using the Gumbel-Softmax Estimator leads to a training interaction with potentially pathological quirks which is not reflective of the actual text generation process.\n\nKeeping training and inference consistent (both using sampled tokens) is why we use the Straight-Through estimator (note: not a \u201cStraight-Through Gumbel estimator\u201d). However, that choice by itself doesn\u2019t guarantee good results. Our main contribution is how to apply the straight through estimator in an ideal way so that performance is acceptable, and that requires ensuring that a useful gradient is available during the backward pass.\n", "title": "Reply to Reviewer #2"}, "rygN2IGOiB": {"type": "rebuttal", "replyto": "rkl9nFTF9H", "comment": "We appreciate your rigorous review of our work. We\u2019ve made several revisions with your feedback in mind.\n\nRegarding notation:\nWe have added an acknowledgment for the usage of notation from Jang et al. (2016). We have also simplified and clarified the notation as follows:\n\n- V = {x_1, \u2026, x_v} stands for a predefined vocabulary of size v.\n- x stands for a discrete token in V.\n- \\hat{x} stands for a discrete token sampled from V by the generator G.\n- \\mathbf{x} stands for a sequence of discrete tokens belong to V.\n- \\hat{\\mathbf{x}} stands for a sequence of discrete tokens sampled from V.\n- \\top stands for the transpose operation. \n\nWe hope these adjustments improve the clarity of our paper.\n", "title": "Reply to Reviewer #2"}, "S1e_Gax_sS": {"type": "rebuttal", "replyto": "BJxaPddyjB", "comment": "Thank you for the friendly reminder. We've uploaded a revision with added citations for RankGAN and MaliGAN.", "title": "Reply to Dianqi Li"}, "HJgZb4nntr": {"type": "review", "replyto": "H1gy1erYDH", "review": "The authors propose CaptainGAN, a method using the straight-through gradient estimator to improve training of the generator for text generation.\n\nThe paper is well-written and the evaluation seems thorough, comparing to relevant baselines.\n\nComments:\n\nFigure 3: the caption refers to Caccia et al. for results on LeakGAN, MaliGAN and seqGAN, but unless I\u2019ve missed it, RelGAN hasn\u2019t yet been introduced by name as a baseline? The citation is given in the opening part of the introduction, in an enumeration, but isn\u2019t revisited later in the text - not even here where the results of the model are introduced. Given that it seems, according to the presented results, to be the most competitive of the GAN models that the authors are comparing to, maybe it\u2019s worth adding more contextual information on RelGAN to the Background section?\n\nFor their method, the authors should report an average performance over several random seeds and provide the standard deviation / confidence intervals, for the readers to be able to assess the stability of the method and the significance of the improvement reported in the results.\n\nI find Section 5.5. particularly interesting, as well as the reported perplexity in Table 2. The authors provide 3 bullet points to explain the unusually high perplexity of the generator on the training and validation data. I feel that the explanations that are given are at the moment vague and not visibly backed by data, therefore being speculative. Obviously, point 1) is hard to quantify - but point 2) could possibly be at least partially quantified - if the hypothesis is that names, places, punctuation marks etc play an important role in the reported perplexity score, then maybe the authors could test this by correlating model perplexity on sentences with whether those sentences contain these types of words?\n", "title": "Official Blind Review #3", "rating": "6: Weak Accept", "confidence": 2}, "HkxIxHwaFB": {"type": "review", "replyto": "H1gy1erYDH", "review": "This paper attempts to solve the problem of non-differentiable connection between the generation and discriminator of a GAN. The authors come up with an estimator of the gradient for the generator from the gradient of the discriminator, which was disconnected previously. With this change, the model should be able to  select better tokens than random selection, which could leads to more robust training. The experiment results on both COCO Image Captions and EMNLP 2017 News datasets justify the authors' argument. ", "title": "Official Blind Review #1", "rating": "6: Weak Accept", "confidence": 1}, "rkl9nFTF9H": {"type": "review", "replyto": "H1gy1erYDH", "review": "The submission proposes to train a GAN on discrete sequences using the straight-through Gumbel estimator introduced in Jang et al. (2016) in combination with gradient centering. The proposed approach is evaluated on COCO and EMNLP News in terms of BLEU and Self-BLEU scores, Fr\u00e9chet Embedding Distance, Language Model Score, and Reverse Language Model Score.\n\nMy assessment is that the submission is below the acceptance bar, mainly due to clarity and novelty concerns. The proposed approach does have empirical backing, but I would argue that it is a very straightforward application of the straight-through Gumbel estimator to GANs, which is itself similar to existing work on applying the Gumbel-softmax estimator to GANs (Kusner & Hern\u00e1ndez-Lobato, 2016). Detailed comments can be found below.\n\nThe submission does not feel self-contained. For instance, it borrows notation from Jang et al. (2016) without explicitly acknowledging it, and my personal experience is that reading Jang et al. (2016) beforehand makes a big difference in terms of clarity in Section 2.2.\n\nThe notation is inconsistent and confusing, and gets in the way of understanding the proposed approach. Here\u2019s a (non-exhaustive) list of examples:\n\n- The reward function is first introduced as f_\\phi(\\mathbf{x}) above Equation 3, but all subsequent mentions of the reward function use f_\\phi(\\hat{\\mathbf{x}}).\n- The \\mathbf{m}_\\theta variable is introduced in Equation 5 and is immediately replaced with \\mathbf{p}_\\theta, which adds notational overhead without any benefit.\n- The difference between \\hat{\\mathbf{x}} and \\hat{x} is not explained in the text. From the context I understand that \\hat{x} is a categorical scalar in {1, \u2026, V}; is this correct?\n- In Equation 6, x_1, \u2026, x_V are used to denote the *values* that \\hat{x} can take. This clashes with the previous convention that \\mathbf{x} is a sequence sampled from p_{data} (Equation 1). Given that convention and the difference between bolded and non-bolded variables discussed above, I would have expected that x_1, \u2026, x_V would correspond to the categorical values of elements of the \\mathbf{x} sequence. That contributes to confusion in Equation 9, where \\mathbf{e}_{x_t} and p_\\theta(x_t) are *not* time-dependent.\n- Equation 8 sums over time steps, but the first summation that appears in Equation 8 does not make use of the temporal index. There is also a symbol collision for T, which is used both as the sequence length and as the \"transpose\" symbol.\n\nAs a result, the proposed centering method and the rationale for it is still not entirely clear to me. In particular, is the gradient centering approach necessary to avoid the drawback of score function-based approaches (i.e. the generator is only given feedback on the tokens it samples), or does the non-centered, straight-through variant of the proposed approach also avoid this drawback?\n\nI\u2019m also not convinced that the centering heuristic is a crucial component of the proposed approach when the biggest improvement observed over the straight-through baseline is obtained by adding spectral normalization. I would argue that the proposed approach is a straightforward application of the straight-through Gumbel gradient estimator to GAN training, which is similar in spirit to work by Kusner & Hern\u00e1ndez-Lobato (2016) (not cited in the submission) -- the main difference being that the latter uses the Gumbel-softmax distribution directly and anneals the temperature parameter over the course of training. A comparison between the two would be warranted.\n\nReferences:\n\n- Kusner, M. J., & Hern\u00e1ndez-Lobato, J. M. (2016). GANs for sequences of discrete elements with the Gumbel-softmax distribution. arXiv:1611.04051.", "title": "Official Blind Review #2", "rating": "3: Weak Reject", "confidence": 3}}}