{"paper": {"title": "Dataset Augmentation in Feature Space", "authors": ["Terrance DeVries", "Graham W. Taylor"], "authorids": ["terrance@uoguelph.ca", "gwtaylor@uoguelph.ca"], "summary": "We argue for domain-agnostic data augmentation in feature space by applying simple transformations to seq2seq context vectors.", "abstract": "Dataset augmentation, the practice of applying a wide array of domain-specific transformations to synthetically expand a training set, is a standard tool in supervised learning. While effective in tasks such as visual recognition, the set of transformations must be carefully designed, implemented, and tested for every new domain, limiting its re-use and generality. In this paper, we adopt a simpler, domain-agnostic approach to dataset augmentation. We start with existing data points and apply simple transformations such as adding noise, interpolating, or extrapolating between them. Our main insight is to perform the transformation not in input space, but in a learned feature space. A re-kindling of interest in unsupervised representation learning makes this technique timely and more effective. It is a simple proposal, but to-date one that has not been tested empirically. Working in the space of context vectors generated by sequence-to-sequence models, we demonstrate a technique that is effective for both static and sequential data.\n", "keywords": ["Unsupervised Learning"]}, "meta": {"decision": "Invite to Workshop Track", "comment": "This paper proposes to regularize neural networks by adding synthetic data created by interpolating or extrapolating in an abstract feature space, learning by an autoencoder.\n \n The main idea is sensible, and clearly presented and motivated. Overall this paper is a good contribution. However, the idea seems unlikely to have much impact for two reasons:\n  - It's unclear when we should expect this method to help vs hurt\n  - Relatedly, the method has a number of hyperparameters that it's unclear how to set except by cross-validation.\n \n We also want to remark that other regularization methods effectively already do closely related things. Dropout, gradient noise, and Bayesian methods, for instance, effectively produce 'synthetic data' in a similar way when the high-level weights of the network are perturbed."}, "review": {"S1QSGO8Pg": {"type": "rebuttal", "replyto": "HJ9rLLcxg", "comment": "In our previous experiments with the Wide ResNet architecture (see our response to Reviewer1's review for details) we tested to see whether using reconstructed inputs, rather than context vectors, still yielded improved model performance. In these tests we encoded CIFAR-10 images with the encoder portion of a sequence autoencoder, extrapolated between the resulting context vectors, and then projected the context vectors back into input space with the decoder to reconstruct augmented images. The newly generated images were then added to the original dataset. We found that this data augmentation approach resulted in worse classification performance compared to the baseline model. However, we also observed that training a model on only reconstructed images (encoded then decoded, with no extrapolation) yielded results much worse than the equivalent test trained on unmodified data. We hypothesized that the decrease in performance from the tests with extrapolation may possibly be attributed to the decoder's reconstruction error rather than the effects of extrapolation. \n\nTo isolate the effects of extrapolation we conducted several more experiments, this time using reconstructed samples for all tests so that reconstruction error affected all tests equally. Any difference between baseline and extrapolation tests could now be contributed solely to the effects of extrapolation. The results from our tests are shown below:\n\nTest 1 - 24x24 reconstructions, center crop: 18.75 +/- 0.24 (% test error)\nTest 2 - 24x24 reconstructions, center crop + extrapolation: 17.72 +/- 0.45 (% test error)\nTest 3 - 24x24 reconstructions, simple data augmentation (shift + mirror): 13.55 +/- 0.15 (% test error)\nTest 4 - 24x24 reconstructions, simple data augmentation + extrapolation: 11.99 +/- 0.11 (% test error)\n\nIn these tests we observed a consistent reduction in classification error when feature space extrapolation is applied: about 1% reduction in test error when applied to 24x24 center crops of the original images, and a 1.5% reduction in test error when coupled with input space data augmentation. We believe that these results demonstrate the potential benefits of the feature space extrapolation technique, which persist even when applied to complex model architectures such as Wide ResNet. As previously mentioned we are currently investigating methods which may reduce the reconstruction error introduced during the decoding process.\n", "title": "Update regarding CIFAR-10 Wide ResNet results"}, "B1Yd0O_Ix": {"type": "rebuttal", "replyto": "ByUItzz4g", "comment": "Thanks for your feedback. We wanted to point out a few simplifications in Reviewer 3\u2019s TLDR statement which we thought unfairly represented the work:\n- When R3 said \u201cthey add noise to some representation space\u201d, this incorrectly represents what we did. We experimented with noise injection, interpolation, and extrapolation in feature space and actually found that adding noise did not work well compared to extrapolation. \n- When R3 said \u201cExperimental results show improvement from author\u2019s baseline on some toy tasks\u201d, there are two errors here. First, our Arabic Digits, Australian Sign Language Signs, and UCFKinect tests all include results that were not our own baselines; they were the best results reported by other groups that we could find on these datasets. Second, while we completely agree that Arabic Digits, AUSLAN, UCFKinect, MNIST, and CIFAR-10 are not large-scale datasets, calling them toy seems unnecessarily punitive. Our aim in choosing these datasets was breadth of modalities.\n- We\u2019re not sure why it was necessary to qualify \u201cwithout the usage of attention\u201d in the TLDR statement as it does not seem relevant to what we are exploring.\n\nWe agree that it would be interesting to explore this approach on Machine Translation (or other text-based applications). However, neither of the authors have experience in this domain and, to our understanding, most existing approaches require significant infrastructure (in terms of datasets and computational resources). We weren't able to introduce such a pipeline in the time frame allotted by the review period, but we will certainly consider it in future work.\n\nDropout on the context vector can be seen as a specific case of our method; it\u2019s a (severe) kind of noise applied to the feature-mapped inputs. We performed some tests by applying dropout to the context vectors and found that it neither increased nor decreased performance significantly.\n\nWe acknowledge the discrepancy between the baseline published by Dai et al. (26% error vs. our 32% error) and while we believe that we have exactly replicated their approach, we cannot explain the discrepancy. We reached out to these authors requesting more detail but have yet to receive a response. We have since tried more sophisticated classification (Wide ResNets), the details of which are in the response to Reviewer 1.\n\nThanks for catching the problem with the references; there was a serious error which we corrected. We have updated the Arxiv papers that were subsequently published. Thanks for taking the time to identify these.", "title": "no title"}, "r18W2vO8x": {"type": "rebuttal", "replyto": "S1qqrWz4l", "comment": "Thank you for your positive feedback on the paper and your constructive suggestions.\n\nWith respect to the more complex baseline, since the reviews were received, we experimented with a more state-of-the-art architecture (Wide ResNets by Zagoruyko and Komodakis, 2016) for the CIFAR-10 task. In all of our tests we held constant the  Wide Residual Network architecture (same as the one used in the Wide ResNets paper) and changed only the data. We conducted tests on the following 6 setups: \nTest 1 \u2013 32x32 input with no data augmentation (8.79% test error)\nTest 2 - 24x24 center crops with no data augmentation (11.21% test error)\nTest 3 - 24x24 center crops, reconstructed from context vectors of the original images, with no data augmentation (18.68% test error)\nTest 4 - 24x24 center crops + extrapolation (14.11% test error)\nTest 5 - 24x24 with simple data augmentation (shifting and horizontal flipping) (7.33% test error)\nTest 6 - 24x24 with simple data augmentation + extrapolation (8.55% test error)\n\nOverall performance improved greatly compared to our current sequence autoencoder + MLP results. In the Test 4 and 6 described above, we used reconstructions of the extrapolated feature vectors (in addition to the original images) to train the classifier. Although visual inspection of the reconstructions looked to us like valid training cases (i.e. objects maintained their class identity and we saw no visible artifacts) training with reconstructed extrapolated context vectors actually worsened performance. We also trained a model on only reconstructions of the original examples mapped to context vectors (i.e. no extrapolation) for Test 3. This test performed considerably worse compared to training on the original examples themselves (Test 2). Therefore we believe that, at least for CIFAR-10, there is significant loss of fidelity of the examples (original or extrapolated) when mapping to and from context vectors. We are currently investigating alternative methods that could be used to reduce the amount of error introduced during the reconstruction process,  such as static encoder-decoder architectures or performing extrapolation within the feature space of the classifier itself.\n\nWe\u2019re still in the process of running these experiments, but will add the Wide ResNet results to the final version.", "title": "Classification on Reconstructed Inputs"}, "rkkaTPd8x": {"type": "rebuttal", "replyto": "rk7Sgr-Eg", "comment": "Thank you for your valuable suggestions for improving the paper.\n\na) This is an interesting suggestion. In the case where noise is the transformation, this would simply amount to noise injection in the hidden layer (which we know works well as a regularizer). However, doing interpolation or extrapolation amounts to something that, to the best of our knowledge, hasn't been reported. For this paper one of our aims was to keep the encoding architecture and transformation in feature space consistent, however, we are very interested in exploring this direction for the next paper.\n\nb) Since the reviews were submitted we conducted some tests on utilizing samples from competing classes for extrapolation and interpolation, however we found that both approaches resulted in worse performance compared to the baseline.\n\nc) We ran some additional synthetic data experiments where we could control the complexity of the class boundaries. We found that extrapolation helped only in the case where there were complex class boundaries, not when the boundaries were simple (e.g. linearly separable, or one class encircling another). However, interpolation did help in these simple cases. Our best explanation at present is that interpolation tends to tighten class boundaries and unnecessarily increase confidence, leading to overfitting. In essence, it may cause the model to ignore informative extremities that can describe a complex decision boundary and produce an unnecessarily smooth decision boundary. High-dimensional, real datasets will typically have complex decision boundaries, and this is the case where we found extrapolation to shine. We have added a discussion on this matter to the conclusion section in the most recent revision of the paper.\n\nd) Please see our response to Reviewer 1 detailing the use of Wide ResNets.", "title": "no title"}, "HJ1RAaR7x": {"type": "rebuttal", "replyto": "HygjiMdQe", "comment": "When extrapolation based augmentation is carried out it is between neighbouring samples from the same class. The amount of extrapolation can be controlled by setting the lambda parameter in Equation 3. For large values of lambda there would definitely be the possibility of generating a sample that appears to belong to a different class, but for smaller values of lambda this risk is much reduced. We found that using a lambda value of 0.5 consistently yielded good results; generated samples were different enough from the original samples so as to contribute helpful diversity to the training set, but still similar enough that they did not appear to come from different classes.", "title": "Re: Is extrapolation based augmentation risky?"}, "HygjiMdQe": {"type": "review", "replyto": "HJ9rLLcxg", "review": "Hi, when extrapolation based augmentation is carried out, do the neighboring context vectors belong to different classes (this is not clear from the paper, it seems they belong to the same class)?  If they are in the same class extrapolation based augmentation feels more risky as it could push a class into a confusable class (e.g. digit 1 into digit 7)?In this paper authors propose a novel data augmentation scheme where instead of augmenting the input data, they augment intermediate feature representations.  Sequence auto-encoder based features are considered, and random perturbation, feature interpolation, and extrapolation based augmentation are evaluated. On three sequence classification tasks and on MNIST and CIFAR-10, it is shown that augmentation in feature space, specifically extrapolation based augmentation, results in good accuracy gains w.r.t. authors baseline.\n\nMy main questions and suggestions for further strengthening the paper are:\n\na) The proposed data augmentation approach is applied to a learnt auto-encoder based feature space termed \u2018context vector\u2019 in the paper.  The context vectors are then augmented and used as input to train classification models. Have the authors considered applying their feature space augmentation idea directly to the classification model during training, and applying it to potentially many layers of the model?  Also, have the authors considered convolutional neural network (CNN) architectures as well for feature space augmentation?  CNNs are now the state-of-the-art in many image and sequence classification task, it would be very valuable to see the impact of the proposed approach in that model.\n\nb) When interpolation or extrapolation based augmentation was being applied, did the authors also consider utilizing nearby samples from competing classes as well?  Especially in case of extrapolation based augmentation it will be interesting to check if the extrapolated features are closer to competing classes than original ones.\n\nc) With random interpolation or nearest neighbor interpolation based augmentation the accuracy seems to degrade pretty consistently.  This is counter-intuitive.  Do the authors have explanation for why the accuracy degraded with interpolation based augmentation?\n\nd) The results on MNIST and CIFAR-10 are inconclusive.  For instance the error rate on CIFAR-10 is well below 10% these days, so I think it is hard to draw conclusions based on error rates above 30%.  For MNIST it is surprising to see that data augmentation in the input space substantially degrades the accuracy (1.093% -> 1.477%).  As mentioned above, I think this will require extending the feature space augmentation idea to CNN based models.", "title": "Is extrapolation based augmentation risky?", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "rk7Sgr-Eg": {"type": "review", "replyto": "HJ9rLLcxg", "review": "Hi, when extrapolation based augmentation is carried out, do the neighboring context vectors belong to different classes (this is not clear from the paper, it seems they belong to the same class)?  If they are in the same class extrapolation based augmentation feels more risky as it could push a class into a confusable class (e.g. digit 1 into digit 7)?In this paper authors propose a novel data augmentation scheme where instead of augmenting the input data, they augment intermediate feature representations.  Sequence auto-encoder based features are considered, and random perturbation, feature interpolation, and extrapolation based augmentation are evaluated. On three sequence classification tasks and on MNIST and CIFAR-10, it is shown that augmentation in feature space, specifically extrapolation based augmentation, results in good accuracy gains w.r.t. authors baseline.\n\nMy main questions and suggestions for further strengthening the paper are:\n\na) The proposed data augmentation approach is applied to a learnt auto-encoder based feature space termed \u2018context vector\u2019 in the paper.  The context vectors are then augmented and used as input to train classification models. Have the authors considered applying their feature space augmentation idea directly to the classification model during training, and applying it to potentially many layers of the model?  Also, have the authors considered convolutional neural network (CNN) architectures as well for feature space augmentation?  CNNs are now the state-of-the-art in many image and sequence classification task, it would be very valuable to see the impact of the proposed approach in that model.\n\nb) When interpolation or extrapolation based augmentation was being applied, did the authors also consider utilizing nearby samples from competing classes as well?  Especially in case of extrapolation based augmentation it will be interesting to check if the extrapolated features are closer to competing classes than original ones.\n\nc) With random interpolation or nearest neighbor interpolation based augmentation the accuracy seems to degrade pretty consistently.  This is counter-intuitive.  Do the authors have explanation for why the accuracy degraded with interpolation based augmentation?\n\nd) The results on MNIST and CIFAR-10 are inconclusive.  For instance the error rate on CIFAR-10 is well below 10% these days, so I think it is hard to draw conclusions based on error rates above 30%.  For MNIST it is surprising to see that data augmentation in the input space substantially degrades the accuracy (1.093% -> 1.477%).  As mentioned above, I think this will require extending the feature space augmentation idea to CNN based models.", "title": "Is extrapolation based augmentation risky?", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "Bk7OI5lXg": {"type": "rebuttal", "replyto": "SkSN1t0fx", "comment": "Thanks for your interest and positive feedback. We view random noise as a type of \u201crandom corruption\u201d. If we have correctly understood your question, perhaps you are referring to a more structured type of corruption? Yes, this should work within our framework but if the corruption process is domain-specific then we lose one of the advantages of our method, which is that it requires no domain knowledge.\n", "title": "Re: Random corruption"}, "SkSN1t0fx": {"type": "review", "replyto": "HJ9rLLcxg", "review": "The proposed method is interesting and the paper is well presented. Just some thoughts on the augmentation methods. Besides adding random noise, interpolation and extrapolation, one other way of improving model robustness is to randomly corrupt the representation. Wondering how that works within the proposed framework. The concept of data augmentation in the embedding space is very interesting. The method is well presented and also justified on different tasks such as spoken digits and image recognition etc.\n\nOne comments of the comparison is the use of a simple 2-layer MLP as the baseline model throughout all the tasks. It's not clear whether the gains maintain when a more complex baseline model is used. \n\nAnother comment is that the augmented context vectors are used for classification, just wondering how does it compare to using the reconstructed inputs. And furthermore, as in Table 4, both input and feature space extrapolation improves the performance, whether these two are complementary or not? ", "title": "Random corruption", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "S1qqrWz4l": {"type": "review", "replyto": "HJ9rLLcxg", "review": "The proposed method is interesting and the paper is well presented. Just some thoughts on the augmentation methods. Besides adding random noise, interpolation and extrapolation, one other way of improving model robustness is to randomly corrupt the representation. Wondering how that works within the proposed framework. The concept of data augmentation in the embedding space is very interesting. The method is well presented and also justified on different tasks such as spoken digits and image recognition etc.\n\nOne comments of the comparison is the use of a simple 2-layer MLP as the baseline model throughout all the tasks. It's not clear whether the gains maintain when a more complex baseline model is used. \n\nAnother comment is that the augmented context vectors are used for classification, just wondering how does it compare to using the reconstructed inputs. And furthermore, as in Table 4, both input and feature space extrapolation improves the performance, whether these two are complementary or not? ", "title": "Random corruption", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}