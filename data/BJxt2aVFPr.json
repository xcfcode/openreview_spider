{"paper": {"title": "Optimizing Data Usage via Differentiable Rewards", "authors": ["Xinyi Wang", "Hieu Pham", "Paul Michel", "Antonios Anastasopoulos", "Graham Neubig", "Jaime Carbonell"], "authorids": ["xinyiw1@cs.cmu.edu", "hyhieu@cmu.edu", "pmichel1@cs.cmu.edu", "aanastas@andrew.cmu.edu", "gneubig@cs.cmu.edu", "jgc@cs.cmu.edu"], "summary": "", "abstract": "To acquire a new skill, humans learn better and faster if a tutor, based on their current knowledge level, informs them of how much attention they should pay to particular content or practice problems. Similarly, a machine learning model could potentially be trained better with a scorer that \u201cadapts\u201d to its current learning state and estimates the importance of each training data instance. Training such an adaptive scorer efficiently is a challenging problem; in order to precisely quantify the effect of a data instance at a given time during the training, it is typically necessary to first complete the entire training process. To efficiently optimize data usage, we propose a reinforcement learning approach called Differentiable Data Selection (DDS). In DDS, we formulate a scorer network as a learnable function of the training data, which can be efficiently updated along with the main model being trained. Specifically, DDS updates the scorer with an intuitive reward signal: it should up-weigh the data that has a similar gradient with a dev set upon which we would finally like to perform well. Without significant computing overhead, DDS delivers strong and consistent improvements over several strong baselines on two very different tasks of machine translation and image classification.", "keywords": ["data selection", "multilingual neural machine translation", "data usage optimzation", "transfer learning", "classification"]}, "meta": {"decision": "Reject", "comment": "The paper proposes an iterative learning method that jointly trains both a model and a scorer network that places a non-uniform weights on data points, which estimates the importance of each data point for training.  This leads to significant improvement on several benchmarks.  The reviewers mostly agreed that the approach is novel and that the benchmark results were impressive, especially on Imagenet.  There were both clarity issues about methodology and experiments, as well as concerns about several technical issues.  The reviewers felt that the rebuttal resolved the majority of minor technical issues, but did not sufficiently clarify the more significant methodological concerns. Thus, I recommend rejection at this time."}, "review": {"rkgz2PwHYB": {"type": "review", "replyto": "BJxt2aVFPr", "review": "The paper proposes an iterative method that jointly trains the model and a scorer network that places a non-uniform distribution over data sets.  The paper proposes a gradient method to learn the scorer network based on reinforcement learning, which is novel as to what the reviewer knows.\n\nThere are several concerns/questions:\n\n1) The paper doesn\u2019t define the D_{dev} clearly. How is D_{dev} chosen? Is it a subset of D_{train}? \n\n2) In section 2.1, why \u201csmaller development set D_{dev} is much closer to the P_{test}(X,Y)\u201d? P_{test}(X,Y) is supposed to be not observed during training?\n\n3) In Eq (5), if D_{dev} is s subset of D_{train}, if \\theta* is the minimal of J, it means the gradient \nat  \\theta* is 0. To calculate the gradient of J with respect to \\psi, by chain rule, it need to calculate gradient to \\theta* first then \\theta* to \\psi. If gradient of \\theta* is 0, the product is also 0? So the \\psi will not be updated if D_{dev}  is sufficiently similar to D_{train} ?\n\n4) In Section 2.3, it omits the second order Hessian term. How does that influence the performance? \n\n5) it mentions \u201cwithout significant computing overhead\u201c in abstract, which is not demonstrated elsewhere.\n\n6) In the experiments, table 1, it seems the major improvement comes from retrain and TCS rather than DDS? In figure 3, it is better to show the weights of an image without DDS and comparing that with DDS.\n\n7) The paper contains many typos such as Eqn.11 is not defined in the main paper, the \u201cEqn ??\u201d Appears in the appendix, \u201ctha minimizes\u201d etc.\n\nIn general, the idea of the paper is natural and the results seem promising. I am looking forward to the reply to my questions/concerns. \n\n#############\n\nI have read the author's feedback. I think the clarity of both methodology and experiment does not reach the acceptance level and would maintain my current rating. \n", "title": "Official Blind Review #1", "rating": "3: Weak Reject", "confidence": 2}, "Byed72zfiS": {"type": "rebuttal", "replyto": "r1lqmp15YS", "comment": "We thank the reviewer for providing the feedback and suggestions. Please see our response to Reviewer #1, question 4). We have also updated the paper to add some clarifications. We would really appreciate if you could check whether our response has cleared your concern, and that you could consider improving the overall assessment. We would love to continue the discussion and make improvements to our paper. ", "title": "Response to reviewer #2"}, "BygqK5GfiB": {"type": "rebuttal", "replyto": "Skgt9dG-9H", "comment": "We thank the reviewer for providing many good suggestions and questions. We have addressed your concerns here and updated the paper with some clarifications. We would appreciate if you could check our response and revisions (and if these have indeed clarified the concerns, revise the overall assessment). We would also be happy to continue the discussion and make any additional modifications as deemed necessary.\n\nreviewer #3 question1: scoring network architecture\n\nresponse:\nWe are sorry for the lack of clarity with respect to this! This was simply an oversight.\n\nFor image classification, we use an identical network architecture with the main model, but with independent weights and a regressor to predict the score instead of a classifier to predict image classes. For the multilingual NMT experiments, since we only want to model a simple distribution over n training languages, we use a fully connected 2-layer perceptron network. For each target sentence and its corresponding source sentences, the input feature is a n-dimensional vector of 0 and 1, where 1 indicates a source language exists for the given target sentence. We have updated the image classification and NMT instantiation section, as well as the appendix, with clarifications of the network structure, and will release our code once the paper is accepted. \n\n\nreviewer #3 question2: The authors report that their method takes 1.5x to 2x longer to run than the uniform baseline. Yet, they ran all methods for the same number of steps / epochs. It seems to me that a fairer comparison might be letting all methods enjoy the same total budget measure roughly by wall time.\n\nresponse:\nThe main objective of DDS is to improve model performance, while remaining much simpler and more efficient than other methods that optimize a data selector using reinforcement learning that require multiple independent training runs. For example, in the IMDB movie review experiment in  [1], the data filtering agent is also trained for 200 episode, where each episode uses around 40% of the whole dataset, requiring a total of 80x more training time than a single training run. Therefore, the 1.5-2x increase in time afforded by DDS is much more manageable.\n\nFor image classification, training the standard baseline for longer does not help, since the main model will start to overfit, which indicates that spending more time on the baseline would not have a positive effect.\n\nreviewer #3 question3:  I didn't follow why the computation of the per example gradient grad l(x_i, y_i, theta_t-1) is so onerous. Isn't that computed on line 5 already?\n\nresponse:\nIn practice, a single gradient is computed with respect to a mini-batch of training data of size n to improve computational efficiency. However, using the per-example gradient requires one to compute the gradient for each example in a batch, which essentially slows down training by a factor of n. Therefore, we propose the simplification in Eqn. 7 to compute the per example gradient.\n\n\n[1] Learning what data to learn https://arxiv.org/pdf/1702.08635.pdf\n", "title": "response to reviewer #3"}, "BJerJhMGiB": {"type": "rebuttal", "replyto": "Byl59sfzjB", "comment": "Reviewer #1 question 4): In Section 2.3, it omits the second order Hessian term. How does that influence the performance? \n\nResponse:\nOur gradient derivation in Eqn. 6 uses the Markov assumption that in the previous step $\\psi_{t-1}$ is already updated with regard to $\\theta_{t-1}$, so the effect of $\\psi$ on $\\theta_{t-1}$ is likely to be minimal. This assumption can simplify and speed up computation. Moreover, this allows us to have a natural interpretation of the update rule for the data scorer: it should up-weight the training data that have similar gradient direction with the dev data. \n\nThe use of the Markov assumption is based on its use and empirical success in previous work on bi-level optimization, such as Hyper Gradient Descent [1] and many others. Of course, this is a simplifying assumption, but we believe that our empirical results show that the proposed method is useful nonetheless.\n\nRelaxing this assumption would be an interesting avenue for future work. However at the same time how to do so without resulting in large increases in complexity, both with respect to difficulty in implementation,and with respect to computation/memory complexity, is a challenge that would require additional methodological advantages beyond the scope of the current work.\n\n\nReviewer #1 question 5): it mentions \u201cwithout significant computing overhead\u201c in abstract, which is not demonstrated elsewhere.\n\nResponse:\nIn Section 4.2, we describe the nominal increase in training time for DDS. Please see our full response to Reviewer #3, Question 2.\n\nReviewer #1 question 6) In the experiments, table 1, it seems the major improvement comes from retrain and TCS rather than DDS? In figure 3, it is better to show the weights of image without DDS and comparing that with DDS.\n\nResponse:\nIn table 1, the retrained-DDS is still using DDS. We train a scorer with the model until convergence using DDS, then reinitialize the model and train both the scorer and the model again using DDS. Essentially, the first pass of the DDS training moves the scorer parameters to have a good prior distribution over the training data, so that the second DDS training pass is able to improve even further. \nFor the multilingual training, TCS+DDS simply initializes the scorer distribution with the TCS distribution before training using DDS. We compare TCS+DDS with the best baseline, including using only TCS. This shows that DDS brings significant gains over TCS for all four languages.\nThe description of retrained-DDS and TCS+DDS can be found at the end of section 4.1 In the paper.\n\nReviewer #1 question 7): The paper contains many typos such as Eqn.11 is not defined in main paper, the \u201cEqn ??\u201d Appears in appendix, \u201ctha minimizes\u201d etc.\n\nResponse:\nThank you very much for pointing out the typos and providing other good feedback. We have corrected the typos and updated the paper along with the appendix.  \n\n[1] Online learning rate adaptation with hypergradient descent  https://arxiv.org/abs/1703.04782", "title": "Continue response to Reviewer #1"}, "Byl59sfzjB": {"type": "rebuttal", "replyto": "rkgz2PwHYB", "comment": "Thank you very much for providing many pieces of good feedback and clarification questions. We believe that in both the response and the revised draft we have clarified or rectified all of the reservations that were stated in the original review. We would appreciate if you could check our response and revisions (and if these have indeed clarified the concerns, revise the overall assessment). We would also be happy to continue the discussion and make any additional modifications as deemed necessary.\n\nReviewer #1 question 1): The paper doesn\u2019t define the D_{dev} clearly. How is D_{dev} chosen? Is it a subset of D_{train}? \n\nResponse:\nFor our machine translation tasks, $D_{dev}$ is simply the dev set that comes with the dataset.\n\nFor our image classification tasks, for $D_{dev}$ we hold out about 10% of the *training* data. For example, in CIFAR-10 (4,000), $D_{dev}$ is the last 400 images, while in ImageNet-10%, since we use the first 102 TFRecord shards, $D_{dev}$ consists of the last 10 shards. Here, \u201clast\u201d follows the order in which the data is posted on their website for CIFAR-10, and the order in which the TFRecord shards are processed for ImageNet. All data in $D_{dev}$ are excluded from $D_{train}$. Thus, for example, with CIFAR-10 (4,000), $|D_{train}| = 3600$, ensuring that in total, we are only using the amount of data that we claim to use.\n\nThus, in all cases, there is no overlap between $D_{train}$ and $D_{dev}$, or $D_{test}$ and $D_{dev}$ (as is standard in machine learning experiments). We have added a clarification in the method section of the paper, and we also updated the details in the appendix.\n\nReviewer #1 question 2): In section 2.1, why \u201csmaller development set D_{dev} is much closer to the P_{test}(X,Y)\u201d? P_{test}(X,Y) is supposed to be not observed during training?\n\nResponse:\nIt is correct that P_{test}(X, Y) is not observed, but practically in model training it is commonly more possible to collect a dev set that reflects the test scenario. To take the example of the multilingual NMT, in this case we would like to use training data from *many different languages* to improve the performance of *a particular low-resource language*. Here, D_{train} is the aggregation of data from all languages, while D_{dev} could be a separate small set of data from the low-resource language we are interested in. This small dev set is possible to gather, even if we can\u2019t gather a large training set in the language. P_{test}(X, Y) in this case is the distribution of the low-resource language, which is much better captured by the small D_{dev} from this low-resource language.\n\nSimilar settings can easily be thought of in other scenarios as well: in a domain adaptation setting we can obtain a small dev set in the target domain, or in a setting of training on noisy data we can often obtain a small clean dev set. We have updated the method section of the paper to clarify this issue.\n\nFinally, even if the training set and dev set come from *exactly* the same data distribution, likelihood on the dev set is still going to be a better estimator of test performance, as the model is not able to train on the dev set directly (which is why we use dev sets in standard machine learning setups in the first place).\n\nReviewer #1 question 3): In Eq (5), if D_{dev} is s subset of D_{train}, if \\theta* is the minimal of J, it means the gradient at  \\theta* is 0. To calculate the gradient of J with respect to \\psi, by chain rule, it need to calculate gradient to \\theta* first then \\theta* to \\psi. If gradient of \\theta* is 0, the product is also 0? So the \\psi will not be updated if D_{dev}  is sufficiently similar to D_{train} ?\n\nResponse:\nAs we mentioned in point (1), $D_{dev}$ does not overlap with $D_{train}$, so these gradients will be inherently different.\n\n\n", "title": "Response to reviewer #1"}, "r1lqmp15YS": {"type": "review", "replyto": "BJxt2aVFPr", "review": "This paper presents a reinforcement learning approach towards using data that present best correlation with a validation set\u2019s gradient signal. The broader point of this paper is that there is inevitably some distribution shift going from train to test set - and the validation set can be a small curated set whose distribution is closer to the testing distribution than what the training dataset's distribution is. \n\nThe problem setup bears relationship to several areas including domain adaptation/covariate shift problems, curriculum learning based approaches amongst others. One assumption that I see which needs to be understood more is equation (6) - wherein, somehow, there is a Markov assumption used to zero out the contribution of the scoring network on parameters unto previous time step. Trying to understand the implications of this assumption (how the performance varies with/without this assumption) would be instructive for understanding potential shortcomings of this framework.\n\nI think the paper is well written, handles an important question. That said, I am not too aware of recent work in this area to make a decisive judgement on this paper\u2019s novelty/contributions. ", "title": "Official Blind Review #2", "rating": "6: Weak Accept", "confidence": 1}, "Skgt9dG-9H": {"type": "review", "replyto": "BJxt2aVFPr", "review": "Summary: This paper introduces a simple idea to optimize the weights of a weighted empirical training distributions. The goal is to optimize the population risk, and the idea is to optimize a distribution over the training examples to maximize the cosine similarity between training set gradients and validation set gradients. The distribution over the training set is parameterized by a neural network taking as arguments the\n\nStrengths:\n- The method is quite simple.\n- The results appear to be strong, although I am less familiar with the NMT baselines. The imagenet results seem quite strong to me.\n\nWeaknesses:\n- I couldn't find a particularly clear description of the scoring networks architecture. Given that it observes the whole dataset, this seems like a critical choice that could have a big impact on the complexity of this approach. At the very least, this should be clearly reported, and I recommend a more thorough investigation of this choice.\n- The authors report that their method takes 1.5x to 2x longer to run than the uniform baseline. Yet, they ran all methods for the same number of steps / epochs. It seems to me that a fairer comparison might be letting all methods enjoy the same total budget measure roughly by wall time.\n\nQuestions:\n- I didn't follow why the computation of the per example gradient grad l(x_i, y_i, theta_t-1) is so onerous. Isn't that computed on line 5 already?", "title": "Official Blind Review #3", "rating": "6: Weak Accept", "confidence": 2}}}