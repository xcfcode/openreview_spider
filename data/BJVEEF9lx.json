{"paper": {"title": "Learning Approximate Distribution-Sensitive Data Structures", "authors": ["Zenna Tavares", "Armando Solar-Lezama"], "authorids": ["zenna@mit.edu", "asolar@csail.mit.edu"], "summary": "We model mental representations as abstract distribution-sensitive data types and synthesize concrete implementations using deep networks from specification", "abstract": "We present a computational model of mental representations as data-structures which are distribution sensitive, i.e., which exploit non-uniformity in their usage patterns to reduce time or space complexity.\nAbstract data types equipped with axiomatic specifications specify classes of concrete data structures with equivalent logical behavior.\nWe extend this formalism to distribution-sensitive data structures with the concept of a probabilistic axiomatic specification, which is implemented by a concrete data structure only with some probability.\nWe employ a number of approximations to synthesize several distribution-sensitive data structures from probabilistic specification as deep neural networks, such as a stack, queue, natural number, set, and binary tree.", "keywords": ["Unsupervised Learning"]}, "meta": {"decision": "Reject", "comment": "The consensus of the reviewers, although their reviews where somewhat succinct, was that the paper proposes an interesting research direction by training neural networks to approximate datastructures by constraining them to (attempt to) respect the axioms of the structure, but is thin on the ground in terms of evaluation and comparison to existing work in the domain (both in terms of models and \"standard\" experiments\"). The authors have not sought to defend their paper against the reviewers' critique, and thus I am happy to accept the consensus and reject the paper."}, "review": {"BkWKYjOQl": {"type": "rebuttal", "replyto": "HkwMKgkQl", "comment": "Thank you for your questions; let us address them one by one.\n\n- Could you briefly state why you selected these particular ones for more detailed discussion than the others?\n\nWe compared a stack and queue because they are more meaningfully comparable in the sense that push and pop have similar meanings to enqueue and dequeue.\nFor this reason we hypothesized that the internal representations could turn out to be similar or even identical (with only the interface functions differing).\nThis turned out not to be the case; the internal representations in the examples are markedly different.\n\nA second reason is that there are a number of referenced examples in the literature of differentiable stacks and queues.\nThese examples showcase the difference (both in result and motivation) between this approach and manually designing a differentiable data structure.\n\nThat said, our architecture makes it extremely simple to synthesize new data-structures.\nWe have already updated the paper with observations on the internal representation of natural numbers (learned from peano's axioms); and will do so for the remaining data-structures.\n\n- For the implementation, you used a specific single layer architecture. Did you experiment with others than this specific one? If so, can you speculate why the one you used in the paper performed better than the others?\n\nWe experimented with a small number of architectures, in particular a number of residual convolutional networks and a conventional residual neural network.\nIn practice, the convolutional networks performed better substantially better, but increasing the number of layers, or size of residual blocks did not have much effect.\nOne reason may be that because of the nested nature of the axioms (e.g. push(push(push(empty_stack, image1), image2), image3)), which makes training similar to that of recurrent networks.\nFor all the examples we tried however, we were able to synthesize a solution with the architecture stated.\n\n\n- In Figure 1 and Figure 3 the initialization for the stack data-structure is different. Does this originate from different training runs, i.e., do you backpropagate up to the initialization of the datastructure to find an optimal initialization? If not, how do you find the initialization for the empty datastructure? Do you think this influences the model performance?\n\nWe do simultaneously learn the representation of the initial (empty) stack / queue and potentially any constant; we will update the paper to make this more clear.\nAs you have observed these initial representations differ, which wee highlighted this in figure 3's caption.  It suggests there are actually multiple good kinds of representations, and which one is found depends on the optimization procedure.\n\nFor both examples we get good performance, essentially almost zero error.  One question we can investigate is if we make the problem substantially more difficult, (e.g. to stack 10 digits rather than 3), whether the representations that are learned are most consistent.", "title": "Response to comments"}, "SyPNYSkQl": {"type": "review", "replyto": "BJVEEF9lx", "review": "I'm not entirely sure I understand the unrolling procedure. Do you create a loss function as a finite composition of neural networks representing e.g. push / pop, and optimize that? A summary of the algorithm along with a concrete example for e.g. a stack would be useful.\n\nThe paper is motivated as a computational model of mental representations, but little to no evidence is provided for the psychological plausibility of the model. Is there any such evidence? (If not, the psychological / philosophical points should be removed in my opinion; the work could be motivated from an AI perspective instead)A method for training neural networks to mimic abstract data structures is presented. The idea of training a network to satisfy an abstract interface is very interesting and promising, but empirical support is currently too weak. The paper would be significantly strengthened if the method could be shown to be useful in a realistic application, or be shown to work better than standard RNN approaches on algorithmic learning tasks.\n\nThe claims about mental representations are not well supported. I would remove the references to mind and brain, as well as the more philosophical points, or write a paper that really emphasizes one of these aspects and supports the claims.", "title": "Unrolling & Evidence for psychological claims", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "Sy20Q1MNl": {"type": "review", "replyto": "BJVEEF9lx", "review": "I'm not entirely sure I understand the unrolling procedure. Do you create a loss function as a finite composition of neural networks representing e.g. push / pop, and optimize that? A summary of the algorithm along with a concrete example for e.g. a stack would be useful.\n\nThe paper is motivated as a computational model of mental representations, but little to no evidence is provided for the psychological plausibility of the model. Is there any such evidence? (If not, the psychological / philosophical points should be removed in my opinion; the work could be motivated from an AI perspective instead)A method for training neural networks to mimic abstract data structures is presented. The idea of training a network to satisfy an abstract interface is very interesting and promising, but empirical support is currently too weak. The paper would be significantly strengthened if the method could be shown to be useful in a realistic application, or be shown to work better than standard RNN approaches on algorithmic learning tasks.\n\nThe claims about mental representations are not well supported. I would remove the references to mind and brain, as well as the more philosophical points, or write a paper that really emphasizes one of these aspects and supports the claims.", "title": "Unrolling & Evidence for psychological claims", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "HkwMKgkQl": {"type": "review", "replyto": "BJVEEF9lx", "review": "While you state that you \"successfully synthesized approximate distribution-sensitive data-structures from a number of\nabstract data types:\n* Natural number (from Peano\u2019s axioms)\n* Stack\n* Queue\n* Set\n* Binary tree\"\nyou showcase results for queue and stack.\n\n1. Could you briefly state why you selected these particular ones for more detailed discussion than the others?\n2. For the implementation, you used a specific single layer architecture. Did you experiment with others than this specific one? If so, can you speculate why the one you used in the paper performed better than the others?\n3. In Figure 1 and Figure 3 the initialization for the stack data-structure is different. Does this originate from different training runs, i.e., do you backpropagate up to the initialization of the datastructure to find an optimal initialization? If not, how do you find the initialization for the empty datastructure? Do you think this influences the model performance?\n\nThank you!\nThe paper presents a framework to formulate data-structures in a learnable way. It is an interesting and novel approach that could generalize well to interesting datastructures and algorithms. In its current state (Revision of Dec. 9th), there are two strong weaknesses remaining: analysis of related work, and experimental evidence.\n\nReviewer 2 detailed some of the related work already, and especially DeepMind (which I am not affiliated with) presented some interesting and highly related results with its neural touring machine and following work. While it may be of course very hard to make direct comparisons in the experimental section due to complexity of the re-implementation, it would at least be very important to mention and compare to these works conceptually.\n\nThe experimental section shows mostly qualitative results, that do not (fully) conclusively treat the topic. Some suggestions for improvements:\n* It would be highly interesting to learn about the accuracy of the stack and queue structures, for increasing numbers of elements to store.\n* Can a queue / stack be used in arbitrary situations of push-pop operations occuring, even though it was only trained solely with consecutive pushes / consecutive pops? Does it in this enhanced setting `diverge' at some point?\n* The encoded elements from MNIST, even though in a 28x28 (binary?) space, are elements of a ten-element set, and can hence be encoded a lot more efficiently just by `parsing' them, which CNNs can do quite well. Is the NN `just' learning to do that? If so, its performance can be expected to strongly degrade when having to learn to stack more than 28*28/4=196 numbers (in case of an optimal parser and loss-less encoding). To argue more in this direction, experiments would be needed with an increasing number of stack / queue elements. Experimenting with an MNIST parsing NN in front of the actual stack/queue network could help strengthening or falsifying the claim.\n* The claims about `mental representations' have very little support throughout the paper. If indication for correspondence to mental models, etc., could be found, it would allow to hold the claim. Otherwise, I would remove it from the paper and focus on the NN aspects and maybe mention mental models as motivation.\n", "title": "Details for experiments and discussion", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "ryztRFW4e": {"type": "review", "replyto": "BJVEEF9lx", "review": "While you state that you \"successfully synthesized approximate distribution-sensitive data-structures from a number of\nabstract data types:\n* Natural number (from Peano\u2019s axioms)\n* Stack\n* Queue\n* Set\n* Binary tree\"\nyou showcase results for queue and stack.\n\n1. Could you briefly state why you selected these particular ones for more detailed discussion than the others?\n2. For the implementation, you used a specific single layer architecture. Did you experiment with others than this specific one? If so, can you speculate why the one you used in the paper performed better than the others?\n3. In Figure 1 and Figure 3 the initialization for the stack data-structure is different. Does this originate from different training runs, i.e., do you backpropagate up to the initialization of the datastructure to find an optimal initialization? If not, how do you find the initialization for the empty datastructure? Do you think this influences the model performance?\n\nThank you!\nThe paper presents a framework to formulate data-structures in a learnable way. It is an interesting and novel approach that could generalize well to interesting datastructures and algorithms. In its current state (Revision of Dec. 9th), there are two strong weaknesses remaining: analysis of related work, and experimental evidence.\n\nReviewer 2 detailed some of the related work already, and especially DeepMind (which I am not affiliated with) presented some interesting and highly related results with its neural touring machine and following work. While it may be of course very hard to make direct comparisons in the experimental section due to complexity of the re-implementation, it would at least be very important to mention and compare to these works conceptually.\n\nThe experimental section shows mostly qualitative results, that do not (fully) conclusively treat the topic. Some suggestions for improvements:\n* It would be highly interesting to learn about the accuracy of the stack and queue structures, for increasing numbers of elements to store.\n* Can a queue / stack be used in arbitrary situations of push-pop operations occuring, even though it was only trained solely with consecutive pushes / consecutive pops? Does it in this enhanced setting `diverge' at some point?\n* The encoded elements from MNIST, even though in a 28x28 (binary?) space, are elements of a ten-element set, and can hence be encoded a lot more efficiently just by `parsing' them, which CNNs can do quite well. Is the NN `just' learning to do that? If so, its performance can be expected to strongly degrade when having to learn to stack more than 28*28/4=196 numbers (in case of an optimal parser and loss-less encoding). To argue more in this direction, experiments would be needed with an increasing number of stack / queue elements. Experimenting with an MNIST parsing NN in front of the actual stack/queue network could help strengthening or falsifying the claim.\n* The claims about `mental representations' have very little support throughout the paper. If indication for correspondence to mental models, etc., could be found, it would allow to hold the claim. Otherwise, I would remove it from the paper and focus on the NN aspects and maybe mention mental models as motivation.\n", "title": "Details for experiments and discussion", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}}