{"paper": {"title": "On the Convergence of FedAvg on Non-IID Data", "authors": ["Xiang Li", "Kaixuan Huang", "Wenhao Yang", "Shusen Wang", "Zhihua Zhang"], "authorids": ["smslixiang@pku.edu.cn", "hackyhuang@pku.edu.cn", "yangwhsms@gmail.com", "shusen.wang@stevens.edu", "zhzhang@math.pku.edu.cn"], "summary": "", "abstract": "Federated learning enables a large amount of edge computing devices to jointly learn a model without data sharing. As a leading algorithm in this setting, Federated Averaging (\\texttt{FedAvg}) runs Stochastic Gradient Descent (SGD) in parallel on a small subset of the total devices and averages the sequences only once in a while. Despite its simplicity, it lacks theoretical guarantees under realistic settings. In this paper, we analyze the convergence of \\texttt{FedAvg} on non-iid data and establish a convergence rate of $\\mathcal{O}(\\frac{1}{T})$ for strongly convex and smooth problems, where $T$ is the number of SGDs. Importantly, our bound demonstrates a trade-off between communication-efficiency and convergence rate. As user devices may be disconnected from the server, we relax the assumption of full device participation to partial device participation and study different averaging schemes; low device participation rate can be achieved without severely slowing down the learning.  Our results indicate that heterogeneity of data slows down the convergence, which matches empirical observations. Furthermore, we provide a necessary condition for \\texttt{FedAvg} on non-iid data: the learning rate $\\eta$ must decay, even if full-gradient is used; otherwise, the solution will be $\\Omega (\\eta)$ away from the optimal.", "keywords": ["Federated Learning", "stochastic optimization", "Federated Averaging"]}, "meta": {"decision": "Accept (Talk)", "comment": "This manuscript analyzes the convergence of federated learning wit hstragellers, and provides convergence rates. The proof techniques involve bounding the effects of the non-identical distribution due to stragglers and related issues. The manuscript also includes a thorough empirical evaluation. Overall, the reviewers were quite positive about the manuscript, with a few details that should be improved. "}, "review": {"Bkxft2PptH": {"type": "review", "replyto": "HJxNAnVtDS", "review": "This paper analyzes the convergence of FedAvg, the most popular algorithm for federated learning. The highlight of the paper is removing the following two assumptions: (i) the data are iid across devices, and (ii) all the devices are active. For smooth and strongly convex problems, the paper proves an O(1/T) convergence rate to global optimum for learning rate decaying like 1/t with time. It is also shown that with constant learning rate eta, the solution found can be necessarily Omega(eta) away from the optimum (for a specific problem instance), thus justifying the decaying learning rate used in the positive result.\n\nFederated learning has been an important and popular research area since it models a highly distributed and heterogeneous learning system in real world. Previous theoretical analysis of FedAvg was quite scarce and either made the iid data assumption or required averaging all the devices. This work is the first to prove a convergence guarantee without these two assumptions. In particular, it only requires averaging a (random) subset of devices each round, which is much more realistic than averaging all.\n\nI don't quite have an intuition for why you need strong convexity. I hope the authors could explain this in words and maybe comment on what are the challenges of removing this assumption.\n\n\n------\nThanks to the authors for their response.", "title": "Official Blind Review #1", "rating": "8: Accept", "confidence": 1}, "SkxS2tZ-sH": {"type": "rebuttal", "replyto": "rkl4PWCsKB", "comment": "We greatly appreciate the reviewer's effort. Thanks for your positive reviews.", "title": "Thank you for the supportive review"}, "Hyx97qWbsS": {"type": "rebuttal", "replyto": "Bkxft2PptH", "comment": "We greatly appreciate the reviewer's effort. Here are our responses to your comments.\n\nThere are several benefits when we assume strong convexity.\nFirst, it facilitates our analysis.\nWe have more ways to prove the convergence since there is no difference when we prove convergence for $\\|w_t - w^*\\|$ or $f(w_t) - f(w^*)$.\nSecond, strong convexity and smoothness mean fast convergence rate $O(1/T)$. \nSince FedAvg is a distributed variant of SGD, it couldn't achieve faster convergence than SGD.\nWe can remove the strong convexity assumption but the convergence rate is $O(1/\\sqrt{T})$ (see Khaled et al. (2019)).\nThird, in Theorems 1 and 2, we require the learning rate $\\eta_t = 2/(\\gamma + t) 1/\\mu$, which makes the use of a positive $\\mu$.", "title": "Thank you for your supportive review"}, "B1gL_cb-jS": {"type": "rebuttal", "replyto": "SyeCOwkk9r", "comment": "We greatly appreciate the reviewer's effort. Here are our responses to your comments.\n\n1. Yes, transformed Scheme II is the scaling trick described at the end of Section 3.3. We will clarify its definition.\n\n2. Since FedAvg is a distributed variant of SGD, it couldn't achieve faster convergence than SGD.\nFor strongly convex and smooth optimization problems, the best convergence of SGD is $\\Theta(1/t)$.\nIn our case, if $\\eta_t$ that is decaying slower than $\\Theta(1/t)$, you might not obtain the convergence rate $O(1/t)$.\nBased on Eq. (11), when $\\eta_t = 1/(\\mu\\sqrt{t})$, we will obtain the convergence rate $O(1/\\sqrt{t})$ by a similar argument.\n\n3. We will correct these typos in its revision.", "title": "Thank you for your valuable review"}, "rkl4PWCsKB": {"type": "review", "replyto": "HJxNAnVtDS", "review": "This paper presents convergence rates for straggler-aware averaged SGD for non-identically but independent distributed data. The paper is well-written and motivated with good discussions of the algorithm and the related works. The proof techniques involve bounding how much worse can the algorithm do because of non-identical distribution and introduction of stragglers into the standard analysis of SGD-like algorithms. The presented theory is useful, and also provides new insights such as a new sampling scheme and an inherent bias for the case of non-decaying step size. The empirical evaluation is adequate and well-presented. I think this paper is a strong contribution and should spark further discussions in the community. ", "title": "Official Blind Review #4", "rating": "8: Accept", "confidence": 3}, "SyeCOwkk9r": {"type": "review", "replyto": "HJxNAnVtDS", "review": "Federated learning is distinguished from the standard distributed learning in the following sense: \n1) training is distributed over a huge number (say N) of devices and communication between the central server and devices are slow.\n2) The central server has no control of individual devices, and there are inactive devices that does not respond to the server; full participation of all devices is unrealistic.\n3) The local data distribution at each device is different from each other; i.e., the data is non-iid.\n\nDue to property 1), communication-efficient algorithms such as Federated Averaging (FedAvg) have been proposed and studied. FedAvg runs SGD in parallel on K (\u2264N) local devices using their local datasets, and updates the global parameter after E local iterations by aggregating the updates from the local devices.\n\nProperties 2) and 3) makes analysis of FedAvg difficult, and previous results have proven convergence of FedAvg assuming that the data is iid and/or all devices are active. In contrast, this paper studies FedAvg on the non-iid data and inactive devices setting and shows that, with adequately chosen aggregation schemes and decaying learning rate, FedAvg on strongly convex and smooth functions converges with a rate of O(1/T). \n\nOverall, I enjoyed reading this paper and I would like to recommend acceptance. This is the first result showing convergence rate analysis of FedAvg under presence of properties 2) and 3), which is a nontrivial, important, and timely problem. The paper is well-written and reads smoothly, except for some minor typos. The convergence bounds provide insights of practical relevance, e.g., the optimal choice of E, the effect of K in convergence rate, etc. The authors also provide empirical results supporting their theoretical analysis.\n\nSome questions I have in mind:\n- What is \"transformed Scheme II\"? Is it the scaling trick described at the end of Section 3.3? The name appears in the experiment section before being defined.\n- What happens if we choose \\eta_t that is decaying but slower than O(1/t), say O(1/\\sqrt t)? Can convergence be proved? If so, in what rate?\n\nMinor typos:\n- Footnote 3: know -> known\n- Assumptions 1 & 2: f in $f(w)$ is math-bold\n- Choice of sampling schemes: \"If the system can choose to active...\" -> activate\n- mnist balanced and mnist unbalanced: the description after them suggests they should be switched\n- Apdx D.1: widely -> wide, summary -> summarize", "title": "Official Blind Review #3", "rating": "6: Weak Accept", "confidence": 1}}}