{"paper": {"title": "SpreadsheetCoder: Formula Prediction from Semi-structured Context", "authors": ["Xinyun Chen", "Petros Maniatis", "Rishabh Singh", "Charles Sutton", "Hanjun Dai", "Max Lin", "Denny Zhou"], "authorids": ["~Xinyun_Chen1", "~Petros_Maniatis1", "~Rishabh_Singh1", "~Charles_Sutton1", "~Hanjun_Dai1", "whlin@google.com", "~Denny_Zhou1"], "summary": "", "abstract": "Spreadsheet formula prediction has been an important program synthesis problem with many real-world applications. Previous works typically utilize input-output examples as the specification for spreadsheet formula synthesis, where each input-output pair simulates a separate row in the spreadsheet. However, such a formulation does not fully capture the rich context in real-world spreadsheets. First, spreadsheet data entries are organized as tables, thus rows and columns are not necessarily independent from each other. In addition, many spreadsheet tables include headers, which provide high-level descriptions of the cell data. However, previous synthesis approaches do not consider headers as part of the specification. In this work, we present the first approach for synthesizing spreadsheet formulas from tabular context, which includes both headers and semi-structured tabular data. In particular, we propose SpreadsheetCoder, a BERT-based model architecture to represent the tabular context in both row-based and column-based formats. We train our model on a large dataset of spreadsheets, and demonstrate that SpreadsheetCoder achieves top-1 prediction accuracy of $42.51\\%$, which is a considerable improvement over baselines that do not employ rich tabular context.", "keywords": ["neural program synthesis", "spreadsheet formula prediction"]}, "meta": {"decision": "Reject", "comment": "This paper clearly has great ideas and reviewers appreciated that. However, the lack of experiments that can be validated by the community (only 1 experiment on the proprietary dataset) is an issue. We don't know if the reported accuracy is a respectable one (in the public domain).   Having a proprietary dataset is a plus, but no public benchmark raises concerns about reproducibility. \nWe recommend the authors to add some tasks and benchmarks for the community to check for themselves that the numbers reported are non-trivial.  "}, "review": {"14-eofWkiA": {"type": "rebuttal", "replyto": "E05dI3CqacF", "comment": "Thanks for appreciating our work and your insightful comments! We have incorporated your comments in our revision, and we respond to your questions and comments below.\n\n1. Formula accuracy\n\nWe agree that for the same input specification, it is possible to synthesize different semantically equivalent formulas. To evaluate the formula accuracy, we compare whether the predicted formula is exactly the same as the single ground truth formula that is included in the spreadsheet. Therefore, we consider any other predicted formula that is different from the ground truth as a wrong, even if it is semantically equivalent to the ground truth. Note that it is hard to systematically define the semantic equivalence in our evaluation, because we aim to support a wide range of operators in the spreadsheet language. Therefore, we still focus on our current metric to measure the formula accuracy, even if it is an under-estimate of the semantic equivalence. A similar discussion could be found in our response to R2 about the evaluation metric, and we have revised Section 4.2 in the paper to make this point clearer.\n\n2. Pre-trained BERT for headers only\n\nThanks for your great suggestion! We indeed have tried using a pre-trained BERT for headers and a randomly initialized BERT for data cells. However, the performance is 2~3% lower than using a pre-trained BERT for both. One possible reason could be that the model becomes harder to train because more BERT architectures are included in the model.\n\n3. Noisy data/header\n\nFor the dataset we collected, the headers of many spreadsheet tables only provide vague descriptions. For example, in Figure 1 (a), it is a non-trivial job to predict the formula based on the header \u201cStatus\u201d, while our model still provides the correct prediction. In Figure 6 (b), we provide an example of wrong formula prediction when the model does not include the full tabular cell data as the formula specification, and the main reason could be that the header \u201cQuality of reports\u201d is not informative. The ambiguity of the formula specification, e.g., the noisy headers, is one key challenge for spreadsheet formula prediction. Our results show that by training on a large-scale dataset, our model appropriately captures the desired formula functionality from the headers, even when sometimes they do not explicitly convey the meaning of the data. We have moved the sample model predictions in the appendix to Section 4.3 in the main paper, and added more discussion to make this point clearer.\n\n4. Dataset availability & more samples\n\nSince the dataset was collected from an industrial setting, we will not be able to release the full dataset as it is. However, in Appendix C, we have revised the paper to add more discussion of the dataset statistics. Specifically, we presented the distribution of formula lengths, and discussed the most commonly appearing operators.\n\n5. Related work\n\nThanks for pointing out these papers! These are very interesting works on neural program synthesis, and we have revised the related work section to include the discussion of these papers.", "title": "Clarification and discussion"}, "HineHF7hYGM": {"type": "rebuttal", "replyto": "OEva2ZLOxQV", "comment": "Thanks for appreciating our work, and your thoughts on the evaluation metric! We agree that it is difficult to precisely evaluate the semantic equivalence in our case. Based on your suggestion, we revised Section 4.2 to add more related discussion, including the difficulty of evaluating the execution accuracy.", "title": "Follow-up discussion of the formula accuracy"}, "pTbMmCR56-": {"type": "rebuttal", "replyto": "refmbBH_ysO", "comment": "We thank reviewers for their insightful feedback and appreciating our work! We have revised the paper with the following major changes to incorporate the comments.\n\n1. Based on R2\u2019s suggestion on adding more qualitative examples of synthesized formulas in the main paper, we moved sample predictions from the appendix to Section 4.3 in the main paper.  Based on R1\u2019s comments, we also added discussion of these examples in the main paper, to emphasize that our formula specifications, e.g., the headers, are inherently noisy.\n\n2. Based on R1 and R2\u2019s questions about the evaluation metric, we have revised Section 4.2 and added more discussion of our formula accuracy metric.\n\n3. Based on R1\u2019s question on dataset statistics, in Appendix C, we added the description of formula length distribution, and discussed the commonly used spreadsheet functions and operators.\n\n4. Based on R2\u2019s question, we have revised Section 2 (the paragraph \u201cThe spreadsheet language\u201d) and Appendix C to make it clearer that we do not handle absolute ranges in this work.\n\n5. Based on R1\u2019s suggestion on the related work discussion, we have revised the related work section, and added the discussion of the suggested papers on neural program synthesis for different tasks.", "title": "Response and revision"}, "e7IKkQRRdjO": {"type": "rebuttal", "replyto": "txJeQj0oFG", "comment": "Thanks for appreciating our work and your insightful comments! We have incorporated your comments in our revision, and we respond to your questions and comments below.\n\n1. Novelty of our approach\n\nWe agree that our approach is designed for tasks with similar formulations to the spreadsheet formula prediction application evaluated in our work. However, there are various programming-by-spreadsheet applications where complex actions are described as formulas in spreadsheet tables, including CAD software and home-automation systems. For example, ShapeSheet spreadsheets are used to store the information of objects in Microsoft Visio, and these spreadsheets include formulas to determine the object attributes. Similarly, SketchUp allows users to import table data from a spreadsheet for 3D modeling. In our experiments, we evaluated on spreadsheets for general-purpose data processing, but our approach could also potentially be used for more specialized applications as mentioned above, where domain expertise is required and thus assistance is beneficial. In addition, we mentioned in Appendix A that our encoder design could potentially be adapted for other spreadsheet applications besides formula prediction, e.g., bug detection and clone detection.\n\n2. Including the user-provided ranges as part of the model input\n\nThanks for your great suggestion! We have indeed tried a similar approach. Specifically, for the decoding process, we feed in the ground truth cell ranges when the decoder is supposed to predict them. In this case, the accuracy becomes similar to the sketch accuracy. In fact, this is part of the motivation for presenting the breakdown accuracies on sketch and range prediction, because even partially correct formula predictions could be helpful in practice.\n\n3. Providing more examples of model predictions in the main paper\n\nThanks for your suggestion! We have revised the paper accordingly, and moved the sample predictions in the appendix to Section 4.3 in the main paper.\n\n4. Beam search results and inference time\n\nFor the beam search, we didn\u2019t explicitly impose any constraints on the decoded formulas. Therefore, it is possible that the synthesized formula may not be valid, e.g., an operator may call cell values with data types not supported in the function definition. However, empirically we observe that with a sufficiently large dataset for training, the synthesized formulas by well-trained models are mostly valid. This is the case with both our full formula specification and the FlashFill-style specification. About the inference time, with TPU it takes 100ms for the beam size of 5.\n\n5. Evaluation metric\n\nTo measure the formula accuracy, because we only consider a predicted formula to be correct when it is exactly the same as the ground truth, for those predicted formulas that are semantically equivalent but different from the ground truth, they will be considered wrong in our evaluation. Indeed, sometimes the model predicts semantically equivalent but different formulas from the ground truth. For example, to predict arguments for SUM and MULTIPLY, the model could predict the cell ranges in a different order. However, it is hard to systematically define the semantic equivalence in our evaluation, because we aim to support a wide range of operators in the spreadsheet language. Therefore, we still focus on our current metric to measure the formula accuracy, even if it could be an under-estimate of the semantic equivalence. A similar discussion could be found in our response to R1 about the formula accuracy, and we have revised Section 4.2 in the paper to make this point clearer.\n\n6. How to handle absolute ranges\n\nOur model only predicts relative cell references within a local range, and currently it does not support the prediction of absolute ranges. Augmenting our vocabulary with tokens for absolute cell references is a good choice, but we need to add a large number of tokens to systematically represent different possible cell positions. Thus, we focus on predicting relative cell ranges in this work, and we consider predicting other types of cell references as future work. We have revised Section 2 (the paragraph \u201cThe spreadsheet language\u201d) and Appendix C to make this point clearer.", "title": "Clarification and discussion"}, "kQNWTvhDCRb": {"type": "rebuttal", "replyto": "ERTfya3WR7s", "comment": "Thanks for your review. We are happy to address any concerns regarding our work. However, it would be helpful if you could explain your comments with some more details. \n\n1. \u201cThe motivation for the task of predicting formulas given table is not very clear. It would have been better if authors could explain a real world example application for their task.\u201d, \u201cCan you please explain motivation/real world application for the task and technique in details?\u201d\n\nWe have explained the real-world applications in Section 1 (Introduction) and Section 2 (Problem Setup). Our approach and problem setup could be used for predicting formulas in spreadsheets, e.g., those written in Google Sheets. We want to do this because many end-users of spreadsheets may not be familiar with spreadsheet formulas. We want to automatically suggest formulas to a user that they may want to use, based on the data that they have already entered into the spreadsheet. Even for expert users, writing the desired formulas can sometimes take a long time as they may not know the exact Formula syntax to use. We demonstrated the results of our system that automatically predicts formulas on a dataset of real-world spreadsheets.\n\n2. \u201cThe paper is difficult to follow especially the motivation, problem setup and architecture part.\u201d \n\nCould you please point us to the specific parts that were difficult to follow? We are happy to revise our paper and provide more details if anything is missing.\n\n3. \u201cThe dataset is not publicly available for everyone to use to the idea is not reproducible. Authors write in the paper that dataset is publicly available in their organization, I don\u2019t understand what do they mean by that.\u201d\n\nGoogle Sheets enables users to share their documents with other users within the same organization, e.g., the same university or the same company. Our dataset includes spreadsheets that are shared within our organization. Since the dataset was collected from an industrial setting, we will not be able to release the full dataset as it is. However, our modeling technique could also be applied to datasets from other organizations.\n\n4. \u201cComparison with state of the art neural symbolic machine/ function generators is missing. I didn\u2019t find the baselines to be strong enough.\u201d\n\nWe have compared with strong baselines for related tasks, including: (1) RobustFill, the state-of-the-art neural network approach for the FlashFill task; and (2) different variants of models with BERT, where BERT-based models have achieved the state-of-the-art for many semantic parsing and question answering benchmarks. \n\n5. \u201cFigure-1 is not clear, it needs some more intuition and discussion. A running example would have really helped.\u201d\n\nIn Section 2, we provide a detailed description of how to decode the formulas in Figure 1. Please let us know what specific questions you would like us to discuss more in the paper and/or in the response. \n\n6. \u201cwhy authors have not reported results for other related tasks like taskfill using their technique?\u201d\n\nTo our knowledge, we don\u2019t know if there is any task called \u201ctaskfill\u201d. Feel free to include the reference for \u201ctaskfill\u201d. If you mean \u201cFlashFill\u201d instead, we presented the results for comparison with RobustFill in Section 4.3.3.\n\n7. \u201cHow different their task is from semantic parsing for table question answering?\u201d\n\nWe have discussed the differences in Section 5 on page 8, with a whole paragraph starting from \u201cIn terms of the model input format, our spreadsheet formula prediction task is related to existing benchmarks on semantic parsing over a tabular database\u201d. As noted in that paragraph, there are two main differences: (1) table question answering includes a question in the program specification, while our task does not, and thus our program specification is more ambiguous; and (2) our spreadsheet tables are typically less structured than the tables for question answering tasks.\n\nWe request you to kindly reconsider your review in light of this discussion. If you have more specific questions, we are happy to provide more clarification and revise our paper accordingly.", "title": "Please provide more concrete suggestions on how to improve our work"}, "E05dI3CqacF": {"type": "review", "replyto": "refmbBH_ysO", "review": "### Paper summary\nThis paper addresses the problem of inferring spreadsheet formula from surrounding cell values and headers (i.e. brief description of each column). Compared to the standard programming-by-example line of work, which concerns synthesizing a program from a set of independent input/output examples, the problem setup proposed in this paper is more realistic and allows a model to synthesize a program by incorporating the contextual information. To this end, the paper proposes a framework that is specially designed to encode the header and the data from multiple rows and columns. To alleviate the difficulty of decoding a program from scratch, it proposes to first produce a program sketch that consists of formula operators and literals, and then predict the relative range which specifies where the formula operators should be applied. The experiments compare the performance of baselines as well as the proposed framework and its variations. The experimental results show that the proposed framework outperforms the rest and justify many design choices (e.g. leveraging a pre-trained BERT model, predicting a program sketch first, encoding rows and columns independently, etc.) I believe this work proposes an interesting and promising research problem as well as a framework that can achieve reasonable performance. Therefore, I vote for acceptance.\n\n### Paper strengths\n**motivation & problem setup**\nThe motivation for incorporating contextual information for programming by example is convincing. I believe this will make the neural program synthesis line of work more applicable to real-world problems.\n\n**novelty & technical contribution**\n- As far as I am concerned, the problem setup is novel, since it includes header information, does not consider different rows independently, predicts a formula/program in a specified target cell, and allows to reference multiple cells.\n- Leveraging a pre-trained BERT model seems crucial (~10% performance gap).\n- Encoding row and column information separately and merging them with convolutions is compelling.\n- Predicting a program sketch first to alleviate the difficulty of sequentially producing each token of a program is convincing. This paper presents an effective way to implement this idea.\n\n**clarity**\nThe writing is very clear and the figures illustrate the ideas well. Also, the organization of the paper is easy to follow.\n\n**ablation study**\nAblation studies are comprehensive. The proposed framework consists of multiple components. The provided ablation studies help analyze the effectiveness of each of them, including\n- using a row BERT encoder only / using a column BERT encoder only / removing convolution layers that merge BERT's output\n- decoding a program sketch and its range altogether (without the proposed two-stage decoding)\n- using a BERT model that is not pre-trained on text corpora\n\n**experimental result**\nThe presentation of the experimental results is very clear. The authors present insightful information, which includes:\n- top-n accuracy\n- performance vs. different program sketch lengths\n- sketch only accuracy and range only accuracy\nThe analysis of the experiment results is detailed and insightful.\n\n### Paper weaknesses\n**formula accuracy**\nIf I understand correctly, it is possible to synthesize a formula differently from how the ground truth formula is written. If this is the case, I wonder how formula accuracy is computed as one would need to enumerate all the possible ways of writing a particular formula to do so.\n\n**pre-trained BERT for headers only**\nGiven the sampled shown in the paper, I am not sure if it is good to\u00a0employ a pre-trained BERT to encode the content of the spreadsheet except for the header. Therefore, I would like to know if the authors have tried to use a pre-trained BERT for encoding headers only while using a BERT learning from scratch to encode the rest of the spreadsheet. \n\n**noisy data/header**\nI wonder how the proposed framework can deal with headers that do not properly/correctly indicate the meaning of the data.\n\n**dataset availability & more samples**\nIt would be great if the dataset was provided so that the readers can better judge the difficulty of the problem and the performance of the models. Even if it is not possible to make the dataset publicly available, it would be better if a set of randomly selected data points\u00a0(spreadsheet + target formula) were included. Also, providing some statistics of the dataset would be helpful, such as the length distribution of the target formula, the most commonly used operators, etc.\n\n**reproducibility**\nGiven the clear description in the main paper and the details provided in the appendix, I believe implementing the proposed framework is possible. Yet, without access to the dataset, it is still impossible to reproduce the results.\n\n**related work**\nWhile the related work sections in the main paper and the appendix sufficiently cover most of the relevant works, I believe this paper can still be benefit from including the following papers\n- Improving Neural Program Synthesis with Inferred Execution Traces\n- Execution-Guided Neural Program Synthesis\n- Neural Scene De-rendering\n- Learning to Describe Scenes with Programs\n- Neural Program Synthesis from Diverse Demonstration Videos\u2028\n- NL2Bash: A Corpus and Semantic Parser for Natural Language Interface to the Linux Operating System", "title": "Review", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "txJeQj0oFG": {"type": "review", "replyto": "refmbBH_ysO", "review": "**Summary:**\n\nThis paper presents an interesting formulation for spreadsheet formula synthesis. Instead of taking the input output pairs as input, as is done in the programming by example (PBE) approaches, the proposed approach takes the semi-structured tabular context as input for predicting a formula for the target cell. A neural network architecture is presented which uses a BERT-based encoder to leverage the natural language meta-data.\n\n**Strengths:**\n\n* The paper is clear and well written. Problem formulation, model architecture and evaluation setup are presented in sufficient details.\n* I found the program formulation quite interesting. For synthesizing a spreadsheet formula, instead of taking the input output pairs as input, the paper proposes to take the tabular context as input (without an explicit specification) . This is much closer to the real world application where spreadsheets are typically semi-structured and contain rich metadata. \n* Supports the full  \u201cGoogle Sheets Language\u201d with rectangular ranges. This is much more complex than Flashfill and brings many challenges which the paper does well to address.\n* The proposed approach out-performs the neural network approaches for programming by examples. It achieves reasonable accuracy on a large-scale benchmark to be usable in practice.\n* Evaluation and ablation studies are quite thorough. In-depth analysis of results gives insight into the contribution of various architectural choices towards the overall result. The results are inline with the design rationale.\n* The work is well situated and relation to the related work is discussed in sufficient details.\n\n**Weaknesses:**\n\n* I find the problem formulation interesting but would rate the overall approach as medium on novelty. The problem formulation is very specific to the task at hand and has a limited scope of being applicable to outside it (To be fair, the paper doesn\u2019t claim so.) Nothing to take away, however, from the flawless execution. \n* I couldn\u2019t find any glaring weakness but here are a few questions/suggestions.\n* Although the formulation takes into account the rich metadata of the semi-structured spreadsheets, it misses out on certain inputs that would have been easier for the user to provide. For example, users can provide the ranges as input. I believe this would improve the accuracy further since the sketch prediction accuracy is already higher. Have the authors tried something similar?\n* It would help to add a few qualitative examples of synthesized formulas in the main paper to get the feel of the results.\n* It is not clear to me if the output of the model/beam search always results in a valid program. It would also like to know the wall-clock time required for synthesis of top-5 formulas.\n* Does the model come up with formulas that are semantically equivalent but syntactically different from the ground truth? How do you handle this in the evaluation?\n* It is not clear to me if you handle formulas involving absolute as well as relative ranges. Are the absolute ranges part of the sketch in such cases?\n\n**Overall Remark**\n\nI believe that overall problem formulation and the architecture would be valuable to the community considering that the proposed system supports the full \u201cGoogle Sheet Language\u201d and performs reasonably well to be used in practice. The spreadsheet formula synthesis is an important domain with a wide audience. \n", "title": "Novel problem formulation", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "ERTfya3WR7s": {"type": "review", "replyto": "refmbBH_ysO", "review": "The motivation for the work is not very clear to me. The paper is difficult to follow especially the motivation, problem setup and architecture part. The dataset is not publicly available for everyone to use to the idea is not reproducible. Authors write in the paper that dataset is publicly available in their organization, I don\u2019t understand what do they mean by that. Comparison with state of the art neural symbolic machine/ function generators is missing. I didn\u2019t find the baselines to be strong enough. \n\nOverall:  I found this paper to be hard to follow. The motivation for the task of predicting formulas given table is not very clear. It would have been better if authors could explain a real world example application for their task. Figure-1 is not clear, it needs some more intuition and discussion. A running example would have really helped. I found introduction to be a bit disconnected.\n\nQuestion: why authors have not reported results for other related tasks like taskfill using their technique? Can you please explain motivation/real world application for the task and technique in details? How different their taks is from semantic parsing for table question answering?\n", "title": "Summary: This paper presents a technique to generate formulas given table context in spreadsheet (even though I am not very clear about motivation and usecase). Authors propose a BERT based model to learn dependencies  between table rows and columns.", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}}