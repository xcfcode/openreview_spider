{"paper": {"title": "Linear Time Complexity Deep Fourier Scattering Network and Extension to Nonlinear Invariants", "authors": ["Randall Balestriero", "Herve Glotin"], "authorids": ["randallbalestriero@gmail.com", "glotin@univ-tln.fr"], "summary": "This paper proposes an extension of the Scattering Network in the Fourier domain and with nonlinear invariant computation for fast and scalable unsupervised representations", "abstract": "In this paper we propose a scalable version of a state-of-the-art deterministic time-\ninvariant feature extraction approach based on consecutive changes of basis and\nnonlinearities, namely, the scattering network. The first focus of the paper is to\nextend the scattering network to allow the use of higher order nonlinearities as\nwell as extracting nonlinear and Fourier based statistics leading to the required in-\nvariants of any inherently structured input. In order to reach fast convolutions and\nto leverage the intrinsic structure of wavelets, we derive our complete model in the\nFourier domain. In addition of providing fast computations, we are now able to\nexploit sparse matrices due to extremely high sparsity well localized in the Fourier\ndomain. As a result, we are able to reach a true linear time complexity with in-\nputs in the Fourier domain allowing fast and energy efficient solutions to machine\nlearning tasks. Validation of the features and computational results will be pre-\nsented through the use of these invariant coefficients to perform classification on\naudio recordings of bird songs captured in multiple different soundscapes. In the\nend, the applicability of the presented solutions to deep artificial neural networks\nis discussed.", "keywords": ["Unsupervised Learning", "Applications", "Deep learning"]}, "meta": {"decision": "Reject", "comment": "This paper proposes a to use squared modulus nonlinearities within convolutional architectures. Because point-wise squaring can be written as a convolution in the Fourier domain, when doing all the operations in the Fourier this architecture becomes 'dual': convolutions become pointwise operations, and pointwise square-nonlinearities become convolutions. \n The authors study this architecture in the context of scattering transforms and produce a complexity analysis that exploits the previous property, along with preliminary numerical experiments. \n \n All reviewers agreed that, while this is an interesting paper with potentially useful outcomes, its exposition and current experimental section are insufficient. The AC agrees with this assessment, and therefore recommends rejection. \n I agree that the main unanswered question and a 'show-stopper' is the lack of comparisons with its most immediate baseline, scattering using complex modulus, both in terms of accuracy and computational complexity."}, "review": {"SJ0_xhsLl": {"type": "rebuttal", "replyto": "H1P1uFo8g", "comment": "Thank you for your questions.\n\nSo first of all concerning the complexity I think there is also a parameter missing in your computation namely the number of wavelet per octave Q. In fact, this determines directly the actual localization of the wavelet in the Fourier domain and the temporal domain and as Q grows the frequency support shrinks considerably. Also as Q grows the filter-bank grows and thus the number of filter to apply grows. As a result it is clear that the standard scattering transform complexity grows.\nHowever in our case, as Q grows the needed convolution in the Fourier domain become less and less complex (since the support shrinks) and this for all the wavelets.\nAs a result I do agree with you that for low Q (probably between 1 and 4) the standard scattering transform will be faster by definition. The problem is that for audio tasks this frequency resolution leads to poor results (as opposed to images where Q=1 is efficient according to Mallat's papers). In fact, it is often considered for audio tasks to take at least Q=16 which is roughly the same frequency resolution as the human hear with semi tone.\nConcerning the GPU implementation, it is not clear to me if it would lead improvements for a few signals. Of course if one consider only the computation time then the gain will be huge since parallelization of all the used operators is straightforward. However when also including the time cost of transporting a signal into the GPU memory required before any GPU computation I think the gain would not be clear anymore given the already low computation time required. However for large dataset, then as the number of signals grows the more it would be interesting since GPU computation can be done while already transporting the next signal into the GPU. In fact, I will indeed implement the proposed approach in Theano making it transparent from CPU to GPU.\n\nFinally, I am probably not going to be able to present a better result comparison yet you can compare the proposed results with the paper \"Fast Chirplet Transform to Enhance CNN Machine Listening\" which is applied on the same dataset. However I can say that the raw scattering led to poorer results as ii has been used in the bird song challenge and was not the winning solution which used ensemble methods yet we showed that our approach led to as good results.\n\nPlease feel free to ask any points not clear in my answer !\n\nRegards.\n\n\n", "title": "Answer to Reviewer1"}, "H1_rIK8Ux": {"type": "rebuttal", "replyto": "HJFSKrgNe", "comment": "Thank you for your comments and review.\n\nDuring the whole paper, the sparsity always define the norm of the representation, it goes from the l1 norm to the 0 norm (number of nonzero coefficients) depending on the context, either the qualitative aspect of the representation or the the Fourier domain sparsity leading to sparse computation and storage as it is for sparse matrices : exactly 0 coefficients.\n\nThe whole aim of the paper is to introduce a way to perform computations in a large scale setting by deriving the whole model in the Fourier domain, and not to present a \"better\" scattering transform. The \"variance\" feature presented as explained in my other answers can mostly be seen as a way to retrieve the remaining energy at any given layer and is interesting by its simplicity to be computed still in the Fourier domain, it is not the milestone of the approach though.\n\nThe wavelet presented is indeed not an analytical wavelet since it does not fulfill mathematically the admissibility criteria. However in practice and as well for you 10^-1000 example, the value of its mean is negligible. In fact, the whole paper brings a approximation/speed approach where one is willing to sacrifice some exact modeling and computation in order to be able to compute all the transformation of a deep scattering network on large dataset. \nIn addition, for the 10^-1000 example, this would be effectively 0 to a computer which makes it irrelevant in this context of sparse approximation.\n\nWe indeed apply multiple FFT however they are all on a support of much smaller size than the input signal (they are applied only on the support of the wavelet for each wavelet which by definition are extremely small compared to the input signal, making the M log(M) complexity smaller than N the size of the input signal.\n\nSimply by the fact that we do not have to inverse the Fourier transform to compute the |.| nonlinearity and apply the Fourier transform again to convolve at the next layer means that the presented approach is faster. Also do not forget than in the scattering transform the number of FFT you have to perform for this grows exponentially with each of the added \\lambda_l for each layer.\nAlso, the presented computation gains seem to be more important than you suggest. In the case of large scale problems, the presented gains can help save tremendous days of computations, for only one signal of course all of this is irrelevant.\n\nThe variance coefficients can indeed be retrieve through a linear computation of the following S as mentioned in the paper yet it means that you need many layers of the scattering network to encoded all of them. Whereas if you stop at layer L you can still retrieve the sum of all the next S by computing this feature, which helps to reduce the number of required layer to capture all the signal energy.\n\nYou complexity computation is correct. And in fact, our approach has an asymptotic time complexity equivalent to the scattering transform which is N log (N). However, in practice, the observed gain is much more important and this is mainly due to the fact that you do not just have less computation but more efficient memory access. Whatever operation applied in our setting access contiguous memory blocks whereas the periodization of the signal after element wise multiplication with the wavelet is quite harmful in practice, just as an example. So we indeed do not reduce the asymptotic complexity yet the practical results are more than encouraging for large scale datasets. \nFinally, when looking at the gains layer per layer, the most gain is obtained at the first layers.\n\nFinally, in Table 2 we show that the construction of the filter-bank grows linearly with the signal size which is thus satisfactory especially since (and as for the scattering network) usually it is created only one time and then applied on all the signals.\n\nPlease feel free to ask any clarification. Also what has not been mentioned here has been changed in the new uploaded version of the paper !\n\nRegards\n", "title": "Answer to Reviewer 1"}, "Sy0ZC_IUe": {"type": "rebuttal", "replyto": "B1wW-ZQEx", "comment": "Thank you for you consideration.\n\nConcerning the equation, they indeed could be 1 line shorter (not 2 since this would lead to margin problems though) yet I think for clarification purposes, the extra line presents the fact the at each level a new \\lambda parameter is introduced which would not be clear otherwise.\n\nYou are indeed right on the fact that whatever other concatenated feature by definition could lead to better discrimination. However the main argument actually comes from the fact that the \"variance\" feature actually contains the aggregated energy of all the scattering coefficients from the current layer till \"infinity\" this means that when used at the last layer, it retrieves the remaining energy that otherwise would required more depth in the scattering network.\n\nPlease feel free to ask any clarification.\n\nRegards", "title": "Answer to Reviewer 2"}, "HkLJ3_88g": {"type": "rebuttal", "replyto": "H1tUNKVNx", "comment": "Thank you for your comments and ideas.\n\nThe main motivation for the higher order nonlinearity comes from the induced operation inf the Fourier domain which leads to its computation in the Fourier domain very effectively. Also, with the right input signal normalization, this will collapse all the coefficients to 0 at a quicker rate than in the standard scattering transform meaning that one needs a reduced number of layers to capture all the energy in the scattering coefficients.\nAll the writing issues have been changed in the new updated version of the paper.\n\nAdding new descriptors as the one proposed is only intended to show that at the final layer, if not all the energy has been captured yet in the scattering coefficients because the signal was very chaotic, then the remaining energy can be encoded in it since by definition it corresponds to the aggregation of all the scattering coefficients from the given layer to \"infinity\".\n\nPlease let me know if anything needs more clarification.\n\nRegards", "title": "Answer to Reviewer3"}, "S1kwov77x": {"type": "rebuttal", "replyto": "HkHBqhRMe", "comment": "\nI do not understand the notion of \u201chigher order non-linearity\u201d. In (Waldspurger 2016), I might be wrong, but I understand \u201chigher order non-linearity\u201d as scattering (or deep features) coefficients of order (e.g. the number of intermediary non-linearity) equal to or more than 3. Could you clarify? Why is your operator a \u201csecond order\u201d operator?\n\n->Higher order nonlinearity refers to |x|^2 instead of |x| as it is usually done in the scattering network.\n\nThe non-linearity you use is non-expansive only when the values are in [-1,1]. Even if ||x||<=1, it does not imply that |a|+|b|<=1. For example, take x2=y2=x1=-y1=1/sqrt(2), then ||x||=1,||y||=1 and |x2|+|y2|=2/sqrt(2)=sqrt(2)>1. A correct proof should use the fact |f(x)-f(y)|<=||f\u2019||_\\infty ||x-y|| If the goal is to reduce the SNR, could you replace the square modulus by a soft-thresholding, for instance? It seems to verify the sparsity and contraction property as well, while being used a lot in the signal processing litterature. Besides, the coefficients might be quickly very small, even just after the first layer: did it lead to numerical errors? How did you normalize them? What is the variance of your representation?\n\n->Soft-thresholding is indeed popular for denoising but the need to estimate the noise standard deviation is problematic as well as the assumption that the noise has constant variance over time. Yes, after many layers, all the coefficients will converge to 0 by definition, however in practice and as it was demonstrated in Mallat's paper, only 2 layers are needed in practice. At most 3 when dealing with extremely chaotic signals. As a result, we did not experienced any numerical errors. Your suggestion of using the infinite norm is correct.\n\nWith analytic wavelets, one can roughly consider that the modulus non-linearity provides a smooth envelop of the signal, which means that the frequency of the signal will be concentrated around 0: a low-pass filtering will keep more energy. Is it still the case with a squared modulus? How did you select the path of frequencies you will finally compute?(are they still increasing paths?)\n\n->It is still the case for the proposed nonlinearity since in the Fourier domain is represents an auto-correlation which by definition has an argmax at 0 which is the mean of the signal in Fourier. As a result,  you will also \"re-concentrate\" the energy around 0 with this nonlinearity.\n    What do you mean by path ?\n\n\n\nIn the equation (12), I do not understand why you introduce S_n. Wouldn\u2019t it be simpler to introduce V_n only as X_n * (I-phi)  or to write it an as empirical variance?\n\n->As is S defined for the scattering where it could be denoted as an empirical mean, this notation is for clarity purpose so that the corresponding definition is highlighted.\n\nIn equation (15), I'm slightly confused: it seems you are mentionning a compact support Fourier filters, but you seem to define the support in space.\n\n->Everything was derived in the Fourier domain.\n\nIn the equation (23), isn't it possible to simplify FoF?\n\n->It can be simplified, but the whole point is to not simplify it to take advantage of the different supports for each step.\n\nFor a fair comparison, did you compare the computation time between your implementation and a scattering implementation with modulus? Besides, I think the complexity should be explicitely computed with the constants: it depends on the number of filters and the number of fft/ifft performed.\n\n->As mentioned in the paper, only one FFT is needed, namely on the raw input. Once this is done or if the input was given already in the Fourier domain then only local FFT have to be applied (by local we mean on a really small support size). And thus it is dependent on all the J Q and T parameters. We don't see the motivation to derive the exact complexity as opposed to the asymptotic complexity since in all the scattering papers only the asymptotic complexity is derived, as a result no extra comparison could be done.\n\nCould you explain why you claim that the features are more discriminative?\n\n->The features are more discriminative by the addition of the V features. Since they provide new information about the signal, the concatenation of both features can only be equal or better to the S features alone.\n\nI do not understand the figure 4, can you explain it?\n\n->This figure represent the number of nonzeros coefficients in the Fourier domain w.r.t to the input size as well as the sparsity which is simply the ratio of nonzeros coefficients over the total number of coefficients.\n\nIn 2.2, why is it important to be invariant to permutations?\n\n->This is simply a property from the total time invariance property. It is highlighted for more general applications and has not a fundamental sense in our case of bioacoustic signals. \n\nThank you very much for you questions. Please feel free to ask any other one.\nRegards", "title": "Answers"}, "HkHBqhRMe": {"type": "review", "replyto": "SJiFvr9el", "review": "I have few questions:\n\nI do not understand the notion of \u201chigher order non-linearity\u201d. In (Waldspurger 2016), I might be wrong, but I understand \u201chigher order non-linearity\u201d as scattering (or deep features) coefficients of order (e.g. the number of intermediary non-linearity) equal to or more than 3. Could you clarify? Why is your operator a \u201csecond order\u201d operator?\n\nThe non-linearity you use is not non-expansive when the values are in [-1,1]. Even if ||x||<=1, it does not imply that |a|+|b|<=1. For example, take x2=y2=x1=-y1=1/sqrt(2), then ||x||=1,||y||=1 and |x2|+|y2|=2/sqrt(2)=sqrt(2)>1. It is however non expansive for smaller values. If the goal is to reduce the SNR, could you replace the square modulus by a soft-thresholding, for instance? It seems to verify the sparsity and contraction property as well, while being used a lot in the signal processing litterature. Besides, the coefficients might be quickly very small, even just after the first layer: did it lead to numerical errors? How did you normalize them? What is the variance of your representation?\n\nWith analytic wavelets, one can roughly consider that the modulus non-linearity provides a smooth envelop of the signal, which means that the frequency of the signal will be concentrated around 0: a low-pass filtering will keep more energy. Is it still the case with a squared modulus? How did you select the path of frequencies you will finally compute?(are they still increasing paths?)\n\nIn the equation (12), I do not understand why you introduce S_n. Wouldn\u2019t it be simpler to introduce V_n only as X_n * (I-phi)  or to write it an as empirical variance?\n\nIn equation (15), I'm slightly confused: it seems you are mentionning a compact support Fourier filters, but you seem to define the support in space.\n\nIn the equation (23), isn't it possible to simplify FoF?\n\nFor a fair comparison, did you compare the computation time between your implementation and a scattering implementation with modulus? Besides, I think the complexity should be explicitely computed with the constants: it depends on the number of filters and the number of fft/ifft performed.\n\nCould you explain why you claim that the features are more discriminative?\n\nI do not understand the figure 4, can you explain it?\n\nIn 2.2, why is it important to be invariant to permutations?\n\nThanks.Overview: This work seems very promising, but I believe it should be compared with more baselines, and more precisely described and explained, from a signal processing point of view.\n\nPros:\nNew descriptor\nFast implementation\n\nCons:\na) Lack of rigor\nb) Too long accordingly to the content\nc) The computational gain of the algorithm is not clear\nd) The work is not compared with its most obvious baseline: a scattering transform\n\nI will detail each cons.\n\na) Section 1:\nThe author\u00a0 motivates the use of scattering transform because it defines a contraction of the space that relies on geometric features.\n\" The nonlinearity used in the scattering network is the complex modulus which is piecewise linear.\"\nA real modulus is piecewise linear. A complex modulus has a shape of bell when interpreting C as R^2. Could you clarify?\n\\Omega is not introduced.\n\nCould you give a precise reference (page+paper) of this claim: \u201cHigher order nonlinearity refers to |x|^2 instead of |x| as it is usually done in the scattering network.\u201d ?\n\nSection 2:\nThe motivation of the non-linearity is not clear. First, this non-linearity might potentially increase a lot the variance of your architecture since it depends on higher moments(up to 4). I think a fair analysis would be to compute numerically the normalized variance (e.g. divided by the averaged l^2 norm), as a sanity check. Besides, one should prove that the energy is decreasing. It is not possible to argue that this architecture is similar to a scattering transform which has precise mathematical foundations and those results are required, since the setting is different.\n\nPermutation is not a relevant variability.\n\nThe notion of sparsity during the whole paper sometimes refers to the number of 0 value, either the l^1 norm. Mathematically, a small value, even 10^-1000 is still a non 0 value.\n\nDid you compute the graph of the figure 4 on the bird dataset? You might use a ratio instead for clarity. \n\nThe wavelet that is defined is not a morlet wavelet ( https://en.wikipedia.org/wiki/Morlet_wavelet ). It is close to be a gabor wavelet, and actually it has not a 0 averaging. The measure of the \"sparsity of the filters\" is extremely unclear, is it the ratio between the support of the filter and its size? A good criteria might be for instance to understand the amount of the energy that has been neglected.\n\nBesides, a filter with compact support has a bad localisation property. However, this topic is not  reached in the paper. For instance, Cauchy wavelets are not used in many applications.(However in mathematical proofs, they often are)\n\nIn Subsection 3.4 you write that V^(l)(x)=Sum_{j>l} S^(j)(x), but also that you do compute only the 2 first order coefficients because they can be neglected. Besides, you specifically write that adding the variance coefficients improve the representation, whereas they can be obtained as linear combination of S.\n\nYou claim you apply only one FFT, whereas you apply several FFTs.\n\nb) From \"One of the great...\" to \"iof the\ninput.\" section 3.1, the text is not clear. The motivation is that a convolution in space is slower that performing a convolution in the Fourier domain. This whole paragraph can be summarised in few sentences.\nThe section 3.4 is long and corresponds to implementation details. Maybe it could be removed.\n\nc) The table 2 seems to indicate that the generation of the filters is one of the bottleneck of your software. Is this really true?\n\nOne of the main claim of the paper is that sparse filters and staying in Fourier domain speed up the computations. Let us compare the computation of the first order scattering coefficients at scale j with this setting. One has to compare the complexity to compute sum |x*psi_j| and sum |x*psi_j|^2\n\nA downsampling is always performed with wavelets, yet it bears approximation. In a Fourier resolution implementation, one adjust the degree of approximation and speed of computation with the over sampling parameters. Assume a FFT of size N costs C*N*log N, then,\n\nComputing \\hat x costs in both case C*N*log N. \nST: Then, the signal is multiplied with the fourier transform of the filter, which has a cost of N. In a fourier multi resolution implementation, one periodises the signal by a factor j, such that its size is N/2^j. Then, the FFT has cost C*N/2^j*log(N/2^j), and modulus has cost say N. Then, one applied the averaging that has complexity N/2^j.\n\nHere: The signal is multiplied with the fourier transport of the filter that has a support of N/2^j. Then, you convolve it with itself, that has thanks to the padding and the FFT a cost of C*N/2^(j-1)*log(N/2^(j-1))+N/2^(j-1). And you take the 0 frequency.\n\nI might be wrong, since this it not my work to do those calculus, but if you claim that your implementation is theoretically faster, you need to prove it, since I do not know any papers where scattering transform claims to be fastly implemented. Here, one sees that the difference is not that significant. Please correct me if I did a mistake.\n\nd) It is essential to compare your work with the representation of a scattering transform. First, in term of speed of computation, with a fair implementation (e.g. not MATLAB) and secondly in term of accuracy on the dataset you did use: it is a natural baseline.", "title": "Non-linearity questions", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "HJFSKrgNe": {"type": "review", "replyto": "SJiFvr9el", "review": "I have few questions:\n\nI do not understand the notion of \u201chigher order non-linearity\u201d. In (Waldspurger 2016), I might be wrong, but I understand \u201chigher order non-linearity\u201d as scattering (or deep features) coefficients of order (e.g. the number of intermediary non-linearity) equal to or more than 3. Could you clarify? Why is your operator a \u201csecond order\u201d operator?\n\nThe non-linearity you use is not non-expansive when the values are in [-1,1]. Even if ||x||<=1, it does not imply that |a|+|b|<=1. For example, take x2=y2=x1=-y1=1/sqrt(2), then ||x||=1,||y||=1 and |x2|+|y2|=2/sqrt(2)=sqrt(2)>1. It is however non expansive for smaller values. If the goal is to reduce the SNR, could you replace the square modulus by a soft-thresholding, for instance? It seems to verify the sparsity and contraction property as well, while being used a lot in the signal processing litterature. Besides, the coefficients might be quickly very small, even just after the first layer: did it lead to numerical errors? How did you normalize them? What is the variance of your representation?\n\nWith analytic wavelets, one can roughly consider that the modulus non-linearity provides a smooth envelop of the signal, which means that the frequency of the signal will be concentrated around 0: a low-pass filtering will keep more energy. Is it still the case with a squared modulus? How did you select the path of frequencies you will finally compute?(are they still increasing paths?)\n\nIn the equation (12), I do not understand why you introduce S_n. Wouldn\u2019t it be simpler to introduce V_n only as X_n * (I-phi)  or to write it an as empirical variance?\n\nIn equation (15), I'm slightly confused: it seems you are mentionning a compact support Fourier filters, but you seem to define the support in space.\n\nIn the equation (23), isn't it possible to simplify FoF?\n\nFor a fair comparison, did you compare the computation time between your implementation and a scattering implementation with modulus? Besides, I think the complexity should be explicitely computed with the constants: it depends on the number of filters and the number of fft/ifft performed.\n\nCould you explain why you claim that the features are more discriminative?\n\nI do not understand the figure 4, can you explain it?\n\nIn 2.2, why is it important to be invariant to permutations?\n\nThanks.Overview: This work seems very promising, but I believe it should be compared with more baselines, and more precisely described and explained, from a signal processing point of view.\n\nPros:\nNew descriptor\nFast implementation\n\nCons:\na) Lack of rigor\nb) Too long accordingly to the content\nc) The computational gain of the algorithm is not clear\nd) The work is not compared with its most obvious baseline: a scattering transform\n\nI will detail each cons.\n\na) Section 1:\nThe author\u00a0 motivates the use of scattering transform because it defines a contraction of the space that relies on geometric features.\n\" The nonlinearity used in the scattering network is the complex modulus which is piecewise linear.\"\nA real modulus is piecewise linear. A complex modulus has a shape of bell when interpreting C as R^2. Could you clarify?\n\\Omega is not introduced.\n\nCould you give a precise reference (page+paper) of this claim: \u201cHigher order nonlinearity refers to |x|^2 instead of |x| as it is usually done in the scattering network.\u201d ?\n\nSection 2:\nThe motivation of the non-linearity is not clear. First, this non-linearity might potentially increase a lot the variance of your architecture since it depends on higher moments(up to 4). I think a fair analysis would be to compute numerically the normalized variance (e.g. divided by the averaged l^2 norm), as a sanity check. Besides, one should prove that the energy is decreasing. It is not possible to argue that this architecture is similar to a scattering transform which has precise mathematical foundations and those results are required, since the setting is different.\n\nPermutation is not a relevant variability.\n\nThe notion of sparsity during the whole paper sometimes refers to the number of 0 value, either the l^1 norm. Mathematically, a small value, even 10^-1000 is still a non 0 value.\n\nDid you compute the graph of the figure 4 on the bird dataset? You might use a ratio instead for clarity. \n\nThe wavelet that is defined is not a morlet wavelet ( https://en.wikipedia.org/wiki/Morlet_wavelet ). It is close to be a gabor wavelet, and actually it has not a 0 averaging. The measure of the \"sparsity of the filters\" is extremely unclear, is it the ratio between the support of the filter and its size? A good criteria might be for instance to understand the amount of the energy that has been neglected.\n\nBesides, a filter with compact support has a bad localisation property. However, this topic is not  reached in the paper. For instance, Cauchy wavelets are not used in many applications.(However in mathematical proofs, they often are)\n\nIn Subsection 3.4 you write that V^(l)(x)=Sum_{j>l} S^(j)(x), but also that you do compute only the 2 first order coefficients because they can be neglected. Besides, you specifically write that adding the variance coefficients improve the representation, whereas they can be obtained as linear combination of S.\n\nYou claim you apply only one FFT, whereas you apply several FFTs.\n\nb) From \"One of the great...\" to \"iof the\ninput.\" section 3.1, the text is not clear. The motivation is that a convolution in space is slower that performing a convolution in the Fourier domain. This whole paragraph can be summarised in few sentences.\nThe section 3.4 is long and corresponds to implementation details. Maybe it could be removed.\n\nc) The table 2 seems to indicate that the generation of the filters is one of the bottleneck of your software. Is this really true?\n\nOne of the main claim of the paper is that sparse filters and staying in Fourier domain speed up the computations. Let us compare the computation of the first order scattering coefficients at scale j with this setting. One has to compare the complexity to compute sum |x*psi_j| and sum |x*psi_j|^2\n\nA downsampling is always performed with wavelets, yet it bears approximation. In a Fourier resolution implementation, one adjust the degree of approximation and speed of computation with the over sampling parameters. Assume a FFT of size N costs C*N*log N, then,\n\nComputing \\hat x costs in both case C*N*log N. \nST: Then, the signal is multiplied with the fourier transform of the filter, which has a cost of N. In a fourier multi resolution implementation, one periodises the signal by a factor j, such that its size is N/2^j. Then, the FFT has cost C*N/2^j*log(N/2^j), and modulus has cost say N. Then, one applied the averaging that has complexity N/2^j.\n\nHere: The signal is multiplied with the fourier transport of the filter that has a support of N/2^j. Then, you convolve it with itself, that has thanks to the padding and the FFT a cost of C*N/2^(j-1)*log(N/2^(j-1))+N/2^(j-1). And you take the 0 frequency.\n\nI might be wrong, since this it not my work to do those calculus, but if you claim that your implementation is theoretically faster, you need to prove it, since I do not know any papers where scattering transform claims to be fastly implemented. Here, one sees that the difference is not that significant. Please correct me if I did a mistake.\n\nd) It is essential to compare your work with the representation of a scattering transform. First, in term of speed of computation, with a fair implementation (e.g. not MATLAB) and secondly in term of accuracy on the dataset you did use: it is a natural baseline.", "title": "Non-linearity questions", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}}