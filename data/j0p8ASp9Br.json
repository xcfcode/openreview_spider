{"paper": {"title": "Real-time Uncertainty Decomposition for Online Learning Control", "authors": ["Jonas Umlauft", "Armin Lederer", "Thomas Beckers", "Sandra Hirche"], "authorids": ["~Jonas_Umlauft1", "armin.lederer@tum.de", "~Thomas_Beckers1", "~Sandra_Hirche1"], "summary": "The paper proposes a real-time capable epistemic uncertainty estimation with sample-free inference which allows online learning control applications for which we demonstrate the benefits of aleatoric/epistemic uncertainty decomposition.", "abstract": "Safety-critical decisions based on machine learning models require a clear understanding of the involved uncertainties to avoid hazardous or risky situations. While aleatoric uncertainty can be explicitly modeled given a parametric description, epistemic uncertainty rather describes the presents or absence of training data. This paper proposes a novel generic method for modeling \nepistemic uncertainty and shows its advantages over existing approaches for neural networks on various data sets. It can be directly combined with aleatoric uncertainty estimates and \nallows for prediction in real-time as the inference is sample-free. We exploit this property in a model-based quadcopter control setting and demonstrate how the controller benefits from a differentiation between aleatoric and epistemic uncertainty in online learning of thermal disturbances.", "keywords": ["uncertainty decomposition", "epistemic uncertainty", "online learning", "real-time control"]}, "meta": {"decision": "Reject", "comment": "This paper aims to do efficient epistemic uncertainty quantification for model-based learning for control. It does so by augmenting the dataset with synthetic data around the true data points, and trying to classify whether a point is close to the training set or not. I agree with many of the criticisms that R3 and R5 brought fourth. Namely, it's not clear why a kernel density estimate couldn't be used instead (runtime complexity is cited as the reason, but could be addressed through approximations, inducing points etc). It is not clear how to set the sampling distribution for X_epi. Also, since efficiency is a motivation for the work, I suggest that the authors look at and cite:\n\nhttps://arxiv.org/abs/2002.06715 \n\nI think at the moment the paper is not ready for publication, but the idea is interesting. Aside from comparing with the work above, what would improve this paper is an automatic way to select the distribution, or at least the covariance, of X_epi.  "}, "review": {"4tHorJFHdk": {"type": "review", "replyto": "j0p8ASp9Br", "review": "Summary\n--------\nThe authors consider the problem of efficient modeling of epistemic uncertainty, separated from aleatoric uncertainty,  for neural networks. They propose a novel methodology, involving automatically constructing a epistemic uncertainty support data set used to extend a given NN with an epistemic uncertainty output. The method is compared with previous, less efficient, approaches and is applied to the important problem of data-efficient online learning of a controller for real-time use with convincing results.\n\nStrong points\n------------- \n1. The paper is well written, and the important problem considered is clearly presented and motivated.\n2. The proposed approach with *epi points*, although seemingly simplistic at first glance due to its heavy dependence on a useful distance metric, is demonstrated to be quite effective for learning control in euclidean space. \n3. The proposed method is demonstrated empirically in an online learning setting using real disturbance data, making the applicability convincing. \n\n\nWeak points\n-------------\n1. While I recognizing that it is problematic to compare *bounded* (e.g probability value) and *unbounded* (e.g. regression target variance) epistemic uncertainty predictions, I wonder if isn't warranted to consider making the comparison fairer w.r.t. the baselines? Since the experimental maximum value for either baseline method depends on the choice of window size (i.e. $x\\in [-4 , 4]$), a fairer comparison might be to find (optimize) a scaling parameter $\\alpha \\in [0,1]$ of the computed normalized epistemic uncertainty prediction, which minimizes (6). Basically a worst-case situation w.r.t. the proposed method, with the baselines performing the best they could have given any upper bound (larger than observed within the window) on their epistemic uncertainty prediction. I still expect that the proposed method will perform comparatively well based on for example the functional forms in Figure 1.\n2. It is stated in the paper that \"*... (Dropout and BNN) have a larger total discount on the training set than on the test set.*\" (3.4, last bullet point). Can this be due to different maximum values between training and test when normalizing their epistemic uncertainty prediction?\n3. I regard the inclusion of the Vanilla GP model baseline as important. A major concern, however, is about the treatment of this baseline in the experiment methodology:\n   1. The epistemic uncertainty estimate for the GP is calculated based on the predictive variance. Is it not more appropriate to use the predictive standard deviation instead, such that the uncertainty has the same unit as the target? (The same applies to Dropout and BNN too?)\n   2. The data in *1D center* and *1D split* is very well suited for GP regression with an SE ARD kernel and should report a well calibrated epistemic regression uncertainty in input ranges where training data is absent. I find the miss-match between the left figure (showing the the GP mean prediction deviation) and the right figure (showing the epistemic uncertainty estimate) in Figure 1 odd. Implementing 3.1. might alleviate this issue?\n   3. I find it odd that EpiOut outperform the GP model on *1D center* and *1D split*, taking into consideration the performance metric (6). Maybe it is a consequence of issue 3.1.?\n   4. Table 4 and Table 5 in the appendix: It is odd that the GP test discount is smaller than the GP training discount on 2D Gaussian. It would indicate, as mentioned in the paper, that the epistemic uncertainty estimate is off for the GP model. Figure 3 (appendix) does indeed seem odd (or unclear) for the GP model, as does Figure 2 (appendix). Maybe it is a consequence of issue 3.1.? \n4. I am missing details on the online learning for the experiment, e.g: How long is each NN training and how is it related to the real-time aspects? Will the quadcopter fly far into state for which the current NN designates as high epistemic uncertainty before the NN is updated with new data points and  retrained such that the epistemic uncertainty is reduced? Or is the simulation paused and waiting for the NN training to complete on every new data point? If so this should be made clear in the paper.\n\nReason for score\n----------------\nIt is a good paper on an important topic, with supportive empirical evaluation of the applicability of the proposed novel approach. My major concern is with certain aspects of the comparative evaluation and about the clarity of the online learning experiment.\n\nMinor comments\n--------------\n1. I suggest that references to material in the appendix are made in the paper. Technicalities such as the online learning algorithm and relevant results would be made clearer.\n2. Figure 4: Left and middle figures are a bit hard to interpret. It seems like the figures show multiple runs, which makes them even more difficult. They might benefit from a thinner marker/stroke, transparency and/or a 3D effect such as a color gradient for view depth etc. They could also be changed to plotted against time instead of against space.\n3. GP regression with a squared exponential (SE) automatic relevance determination (ARD) kernel has, for a given training data (X,Y), a maximum epistemic regression uncertainty, given by the signal variance parameter $\\sigma_f$ of the kernel: As $d(x^*, x)$ grows the exponential in the kernel decrease towards 1 rapidly, where $x$ is a training data point and $x^*$ is an arbitrary data point. The epistemic uncertainty is consequently bounded for the selected choice of kernel family.\n\n3.5, bullet list, first bullet: \n  \"\\textit{EpiOut}model\" -> \"\\textit{EpiOut} model\"\n  \"\\textit{EpiOut}is\" -> \"\\textit{EpiOut} is\"\n  \n4.1, paragraph 1: \n  \"\\textit{EpiOut}approach\" -> \"\\textit{EpiOut} approach\"\n  \"\\textit{EpiOut}\\eta(\\cdot)\" -> \"\\textit{EpiOut} \\eta(\\cdot)\"\n\nEdit: Markdown problem with nested lists\n\nEdit: Upgraded rating due paper improvements\n\n------------\nThank you for addressing my concerns.\n\nFigure 1 is not updated (it looks the same w.r.t. the GP, but the change from variance to std should be noticeable?).", "title": "Good paper, but questions are raised about the experiments.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "Z7JHMAPSIa2": {"type": "review", "replyto": "j0p8ASp9Br", "review": "**Update**\n\nMy assessment remains unchanged. See the comments for details.\nThe proposed approach is circular---it tries to sample points at a \"sufficient distance\" from the data, then tries to learn this\n\"sufficient distance\" by predicting the points. This circular dependency should be broken somehow. The current paper set this distance arbitrarily by sampling from a Gaussian with covariance $I$.\n\n**Summary of work**\n\nThey propose an epistemic uncertainty estimation method (though it\nis not really estimating the uncertainty, but just whether a datapoint\nexisted in the dataset or not). The proposed method samples new\npoints $x_{epi}$ in the vicinity of the training data points $x_{tr}$\nfrom a Gaussian distribution (they set the covariance to $I$).\nThen it creates a dataset where the target\nis 1 for $x_{epi}$ and 0 for $x_{tr}$ (with some tweaks on removing N\ndatapoints from $x_{epi}$, which were the closest to training data points,\nbut the main principle is roughly the same). Then they train a network to\npredict this target, and this estimate is called $\\eta$.\n\nThey compare their new model against Gaussian processes, Bayesian neural\nnetworks, Dropout uncertainty estimation on some datasets. To evaluate,\nthey propose a new weighted mean squared error metric, where the mean squared\nerror is weighted by $1-\\eta$ and the mean is taken w.r.t. the sum of the\n$1-\\eta$ terms. For the other methods, $\\eta$ is computed by dividing the\nuncertainty for the prediction with the largest uncertainty in the data.\nTheir method outperformed the other methods using this metric, except for\nGPs on some datasets, but they said that GPs do not scale, and are not\nsuitable for real-time applications.\n\nThey use these networks in a quadcopter simulation control task. Their \nepistemic uncertainty estimation was used to decide whether to add a\ndata point to their data set (if the epistemic uncertainty is high) or\nto discard it. The performance of their method including a disturbance\nestimation model that uses their EpiOut approach improved the tracking\nperformance compared to not using any disturbance estimation model at all.\n\n**Strengths and weaknesses**\n\nStrengths:\n- The exposition was good.\n\nWeaknesses:\n- It is not clear to me how to pick the covariance for the sampling distribution\nof $x_{epi}$.\n- It is not clear to me that there is a good justification for the method.\n- It is not clear to me that using the largest uncertainty in the dataset\nfor computing the $\\eta$ values for the other methods is appropriate. What if\nthe other method just predicts an infinite uncertainty somewhere? It seems\narbitrary to use the maximum, and it may be biasing the results to favor\nthe newly proposed approach. I have not seen this metric used anywhere else.\n- The implementations use different frameworks, e.g. the GPs are based on\nGPy using numpy (where there are other frameworks e.g. GPyTorch, Pyro,\nor GPFlow that allow using GPUs), the BNN, dropout and EpiOut use tensorflow.\n- The use in the quadcopter task was unclear to me. Why not just store all\nof the data, or use each data point for a gradient update of the model, then\ndiscard it?\n- As far as I understood, in the experiment on the quadcopter the comparison\nwas between not using a disturbance model at all, and using a disturbance\nmodel with EpiOut. It would be better to remove only the EpiOut component\nto show that the uncertainty estimation was necessary, rather than just\nany arbitrary disturbance estimation model.\n- It seemed the number of data points gathered was around 150, which should\nbe easily handled with GPs, so the task does not seem to suggest that GPs\nwill not scale to it.\n- The paper made up a new set of benchmarks for everything, and never tested\non an existing benchmark to prior works.\n\n**Recommendation**\n\nI recommend rejecting the paper with the main reason that I did not see\nany principle behind the newly proposed method, and how the $x_{epi}$ dataset\ncould be constructed in a sensible way. Currently the covariance of the\nGaussians seemed to be set arbitrarily, but there should be a principled\nway to set this covariance. Unless I have greatly misunderstood something,\nI do not see how the paper could be modified for me to recommend it for\nacceptance. I was also not convinced by the proposed quadcopter application for\nthe binary uncertainty estimation, and the other weaknesses listed above\nalso make me tend towards suggesting to reject.\n\n\n**Questions**\n\nPlease clarify if there were misunderstandings.\n\n**Additional feedback**\n\nBelow are some raw notes and additional thoughts from when I was reviewing\nthe paper.\n\n\"However, sampling the network during inference is a high computational\nburden and is therefore not suitable in real-time critical control\ntasks.\"\nReally? With parallel computing it may not be that heavy. Do you have any\nevidence for your claims? I see that in the appendix you have some\ncomputational times, but it would have been good to point to this in the\nmain text.\n\n\"An extension to heteroscedastic GP regression is presented in\n(Lazaro-Gredilla & Titsias, 2011), how-ever, it is a variational\napproximation and further increases the computational complexity of\nGPs,which is prohibitive when employing them for large data sets.\"\nAs far as I know, it is basically training two GPs, and the computational\ncomplexity is the same, and differs only by a constant factor. Do you\nhave more evidence for your claim?\n\n\"preformed\" -> performed\n\n\"considering a new data point takes $O(N_{tr}^3)$ computations\"\nNo, I believe it takes $O(n^2)$ computation to add one new data point\nusing block matrix inversion.\n\nWhy was GPy used, and not some other framework with GPU support such as\nGPyTorch, Pyro or GPFlow.\n\nThe Bayesian neural network was not clear, because it was a link to a\nblogpost with many codes including numpy and tensorflow. (the code\ncleared this up though)\n\n\"The measure in equation 6 relies on epistemic uncertainty prediction\nin the interval[0, 1].  This is only ensured for the\nproposed EpiOut approach and therefore the uncertainty measures provided\nbythe GP, Dropout and BNN are scaled to the unit interval based on the\nevaluation on all test points.\"\nIs this a fair evaluation method? If one of the other methods gives an\ninfinite uncertainty on some point, this will negatively affect its entire\nscore, even though the uncertainty predictions for the other points may\nbe fine. The evaluation method does not appear sound to me, and no\nreferences were provided for other works using such an evaluation method.\n\nBeing only confident close to the data trajectory may not be the best\napproach. The model should be confident when the prediction is likely to\nbe accurate. For example if the model is smooth, then it should be\npossible to interpolate reasonably accurately, and it should be OK\nfor the model to be confident as long as it has been able to learn\nthe structure sufficiently well.\n", "title": "Unclear whether the method is principled. Update: review remains unchanged.", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "14lqhWmT-dB": {"type": "rebuttal", "replyto": "jJzSk4wQxy", "comment": "Thank you for your constructive and detailed feedback. Here are a few thoughts based on your comments: \n\n\n*> Similarly, the current work should provide a method to learn what is a suitable scale for the sampling distribution...*\n\nYou are right and we will work on an extension which picks up this idea: The norm of the gradient of the \"regular\" output of the NN (which is fitted to the training data with a mse or likelihood loss function) might be helpful in choosing the covariance. \n\n\n*> Finally, it is not clear that a neural network would be necessary for evaluating the uncertainty: you could also try to just compute the distance to the nearest epi-point*\n\nSimilar to kernel density estimation methods, this would make the computational complexity not constant in the number of training points.\n\n\n*> It would help to know the specifications of a real world task*\nThanks for pointing this out. We will do our best to set up an experiment, which actually includes these real-world constraints.\n ", "title": "Thank you for the constructive feedback"}, "8_lWvYPulvL": {"type": "rebuttal", "replyto": "Z7JHMAPSIa2", "comment": "We would like to thank the reviewer for the effort to evaluate and improve the submitted manuscript. Here are our responses to the raised concerns:\n\n**Responses to Weaknesses**\n\n*>> It is not clear to me how to pick the covariance..*\n\nWe agree, that this is a crucial factor and not easy to choose. We want to make two important comments on this point: \nFirst, by scaling the input space to ensure that all training data points lie within $[0,1]^n$, the spread of the training data points Is standardized. This allowed us to use to same covariance on all evaluated data sets.\nSecond, we must chose how far from data we want to trust our model (similar to GP SE lengthscales). If a Lipschitz constant is known, it can be used to tune the covariance of the Epi-samples: More spread out epi points lead to low epistemic uncertainty also outside of the training region, which holds for small Lipschitz constant, and vice versa.\nFor the benchmarks, we did not want to use further knowledge and left the covariance at one.\n\n\n*>> It is not clear to me that  there is a good justification for the method. It is not clear to me that using the largest uncertainty...*\n\nWe understand that this scaling requires special attention as concerns were also raised by another reviewer. In consequence introduceded a parameter $a \\in [0,1]$ to scale $\\eta$ optimally with respect to the performance measure. It shows no significant change on empirical evaluation.\n\n\n*>> The implementations use different frameworks...*\n\nThat is correct, but we do not see a concern here, as the three approaches, which we actually compare with respect to computation time (*EpiOut*, *BNN*, *Dropout*) all operate on the same library.\n\n\n*>> The use in the quadcopter task was unclear to me...*\n\nFirst, thinking of the quadcopter as a time-continuous system, makes it difficult to decide what \u201call data\u201d means as arbitrarily many data is available. Our event-triggered designs resolves this difficulty and is also popular in network control [1] and learning control [2].\nSecond, data-efficiency becomes a necessity for most system with a sample rate in the kHz range, as storage on mobile systems must be considered to be limited. \nThird, we assumed that each measurement is associated with some cost, which is valid for the quadcopter: If the data is processed onboard (e.g. gradient updates at kHz range), battery life time is reduced. If the processing is not performed locally, the transmission puts high load on the communication channel.\n[1] Dimarogonas, Dimos, et al. \"Distributed event-triggered control for multi-agent systems.\" IEEE TAC, 2011\n[2] Solowjow, Friedrich and Sebastian Trimpe. \"Event-triggered learning.\" Automatica, 2020\n\n\n*>> As far as I understood, in the experiment on the quadcopter...*\n\nThank you for this suggestion. We now compare it to the same model (without*EpiOut*), which gathers data uniformly. It shows a worse tracking performance while using more data points, because *EpiOut* triggers many measurements at the first round and benefits later from an improved model. \n\n\n*>> The paper made up a new set of benchmarks...*\n\nWe assume this refers to eq. (6). We are not aware of a measure to evaluate the quality of the epistemic uncertainty and the regression. If any of the reviewers is familiar with such a measure, we would be happy to use it.\nWe believe, that (6) is a quite natural choice under the assumption, that the epistemic uncertainty is bounded. One could argue, that it  grows infinitely as distance to the training set increases, but e.g. GPs with SE kernels also consider it to be bounded.\nSarcos is \u2013 from our perspective - a well-established data set in the field of real-time regression for control, first published in [1] and utilized in [2,3,4] (among others).\n[1] Vijayakumar, Sethu, and Stefan Schaal. \"Locally weighted projection regression: An o (n) algorithm for incremental real time learning in high dimensional space.\" ICML 2000.\n[2] Gijsberts, Arjan, and Giorgio Metta. \"Real-time model learning using incremental sparse spectrum gaussian process regression.\" NN 2013\n[3] Meier, Franziska, et al. \"Incremental local Gaussian regression.\" NeurIPS 2014\n[4] Andreas Doerr, et al. \u201cProbabilistic Recurrent State-Space Models.\u201c ICML 2018\n\n\n\n**Responses to additional feedback**\n\nOf course parallelization can be of great help here. But for resource constraint (mobile) systems operating at khz this imposes a computational challenge.\nTo avoid this misleading impression that heteroscedastic GPs scales worse, we have updated the cited statement in the paper.\nWe now added to the paper that a block inversion can be achieved in quadratic time.\n\n\n*>> Being only confident close to the data trajectory may not be...*\n\nYou are right, that additional knowledge should be used wherever possible and we are thinking of extensions, where the distance function $d$ (for sorting the epi points) is not simply an Euclidean distance, but- similar to a GP kernel \u2013 encodes prior knowledge. ", "title": "Author response"}, "X_jTWuEpMkS": {"type": "rebuttal", "replyto": "4tHorJFHdk", "comment": "We would like to thank the reviewer for the effort to evaluate and improve the submitted manuscript. Here are our responses to the raised concerns:\n\nResponses to Weak points\n--------------------------------------\n**Answer to (1)** \nThanks for providing us with this improved idea for the evaluation. We have implemented it and now report the updated results, which have - as you already guessed \u2013 not changed significantly. \n\n**Answer to (2)** \nYes, you are right. On the initially presented data, we considered training and test data separately from each other and therefore the normalization was not harmonized. Rerunning the evaluation with the same normalization shows that now also BNN and Dropout show consistent results, i.e. lower average epistemic uncertainty on the training than on the test set. Thank you for pointing this out. We have updated the numbers accordingly and removed the cited statement. \nNevertheless, we would like to  emphasize, that the key performance measure, the weighted mean square error on the test set, is not affected by this change, as it concerns mainly the predicted epistemic uncertainty on the training data set. Furthermore, this different method of evaluation further underlines the difficulty to rank a epistemic uncertainty prediction as \u201chigh\u201d or \u201clow\u201d if it is not normalized.\n\n**Answer to (3)**\nFor *Dropout* and *BNN* we are considering the predictive standard deviation and now also consider it for the *GP model*. We agree that standard deviation is a better measure due to the arguments you have brought forward and will state this more clearly in a future revision of the paper. Nevertheless, we have not seen a significant difference in the empiric evaluation.\n\n**Answer to (4)**\nWe are afraid, we do not understand which miss-match you are pointing out here. From our perspective, the *GP model* fits the true function perfectly for $|x|<3$ where it also predicts a low epistemic uncertainty, vice versa for $|x|>3$. For $|x|<-1$ one might expect a larger epistemic uncertainty estimate due to missing data but does not become a problem as long as the mean prediction is also accurate in this area. \n\n**Answer to (5)**\nWe have reconfirmed the results with the posterior standard deviation of the GP, so it is not a consequence of the provided issue in 3.1. While the GP shows \u2013 from our perspective - the desired behavior in terms of the epistemic uncertainty estimate, it is not guaranteed to be optimal with respect to the performance metric in (6). Therefore, we do not see a problem in outperforming the GP as it is not a baseline in a sense that it achieves the best possible result here.\n\n**Answer to (6)**\nYou are right here, that this inconsistency is resolved when scaling the epistemic uncertainty for the training and the test set in the same way. Thus, it is not a consequence of 3.1 but of 2.\n\n**Answer to (7)**\nAround the training of the NN there are a lot of design choice being made. Currently, the NN is retrained with every incoming data point for (2 epochs, learning rate 0.01). But we tested it also if it is retrained every n-th data point with more epochs per training. While it leads to less frequent training, it accumulates more training data points, because high epistemic uncertainty is predicted by the outdated model in the proximity of measured (but not trained) data points. \nAt the current state, the simulation is paused until the training is complete, but our future work aims towards an asynchronous implementation, where the training is performed in background and an outdated model is used until training completes. Such a design has already been used in [1].\nTo make this clear to the reader, we have now provided a pseudo code in the main paper. \nMore important with respect to the real-time capability was to make the epistemic uncertainty prediction fast because this is performed at a much higher rate than the training.\n\n[1] Lutter, Michael, Christian Ritter, and Jan Peters. \"Deep Lagrangian networks: Using physics as model prior for deep learning.\" International Conference on Learning Representations (ICLR)\n\nResponses to Minor comments\n-------------------------------------------\n**Answer to (1)**\nThanks for the advice. We have moved the algorithm to the main paper and point to the supplementary material where necessary.\n\n**Answer to (2)**\nThe figure shows only a single run, but each run consists of 3 labs/rounds. We have now stated the desired trajectory explicitly. Furthermore, based on your other comments, we decided to move this particular plots to the supplementary material to make space for more insightful graphics.\n\n**Answer to (3)**\nYes, we agree. If we have stated something conflicting in the paper, please let us know and we will correct it.\n\nThanks for pointing out the typos. We have updated the manuscript accordingly.\n", "title": "Author response"}, "snfy07Fole": {"type": "rebuttal", "replyto": "GWdh4M-2w7G", "comment": "We would like to thank the reviewer for the effort to evaluate and improve the submitted manuscript. Here are our responses to the raised concerns:\n\n**Answer to (1)** As we sample around each training point individually, we specifically account for spread out data. To evaluate this empirically, we created a new dataset with only 2 training data points (labelled as 1D sparse) and *EpiOut* still shows meaningful epistemic uncertainty estimates (as opposed to *BNN* or *Dropout*) as shown in the updated supplementary material.\n\n**Answer to (2)** Thanks for the advice. We have updated the illustrations accordingly.", "title": "Author response"}, "QojqGqVQ85X": {"type": "rebuttal", "replyto": "P6tt2yGZ1jM", "comment": "We would like to thank the reviewer for the effort to evaluate and improve the submitted manuscript. Here are our responses to the raised concerns:\n\n**Answer to (1)**\nThank you for pointing us to further relevant literature. We agree that our epistemic uncertainty estimate corresponds to the domain shift as a quantification between the source and target domain. We therefore added the suggested work [1] on domain shift in control to our literature review. It has a slightly different focus as the desired trajectory can be actively chosen for exploration and guarantees safety, while our work passively follows a given trajectory.\nWe rather see our work in line with adaptive control or also dual control, which considers the task of simultaneously controlling and identifying an unknown system [2] and we have added further references to our literature review. The key difference we see is that adaptive control typically works on a time-triggered base while our adaptation is event-triggered, which is only used in the minority of previous work and shows promising results, e.g. in [3] or [4].\nThe mentioned work on ensemble methods [5] uses a similar technique as MC-dropouts as it also preforms predictions at the same inputs with all members of the ensemble to obtain a distribution over the output. Due to the low number of nets in the ensemble, this might be possible in a real-time constrained situation but the approach in does not differentiate between aleatoric and epistemic uncertainty. We will include it in the related work of the paper.\n[1] Liu, Anqi, et al. \"Robust regression for safe exploration in control.\" Learning for Dynamics and Control. 2020.\n[2] Wittenmark, Bj\u00f6rn. \"Adaptive dual control methods: An overview.\" Adaptive Systems in Control and Signal Processing. 1995\n[3] Solowjow, Friedrich, and Sebastian Trimpe. \"Event-triggered learning.\" Automatica. 2020.\n[4] Umlauft, Jonas, and Sandra Hirche. \"Feedback linearization based on Gaussian processes with event-triggered online learning.\" IEEE Transactions on Automatic Control (2019).\n[5] Lakshminarayanan, Balaji,  et al. \"Simple and scalable predictive uncertainty estimation using deep ensembles.\" Advances in neural information processing systems. 2017.\n\n**Answer to (2)**\nThank you for drawing our attention to KDE as alternative approach. Like GPs, kernel density estimation is a non-parametric approximator, i.e. the computational effort of the prediction grows with the number of data points. Since the epistemic uncertainty prediction in our control application is used to determine whether a new data point is accepted or not, it is evaluated quite often (compared to a training of the model). The computational effort for prediction with *EpiOut* is constant in the number of training data points. We understand that this requires further explanation and will discuss KDE in the related work.\nThe idea to employ continuous values from 0 to 1 for $\\tilde{y}$ sounds interesting and we will investigate its effect in the future. We have pointed out this idea in \u201cfuture work\u201d.\n\n**Answer to (3)**\nThank you for pointing this out. As we see one main contribution in the *EpiOut* algorithm and the other in the control design, we decided that the aleatoric uncertainty estimation should not have such a prominent position (as it also has limited novelty). However, we now illustrate the NN structure in the experimental section and hope that this puts more focus on the uncertainty decomposition. We have also rewritten parts of the introduction and the problem formulation to adjust the structure based on your comment.\nThe uncertainty decomposition is a prerequisite for the gain tuning method as it is based on the aleatoric uncertainty only.\n\n**Answer to (4)**\nThank you for the great advice. To visualize the uncertainty decomposition, we have added a schematic drawing of the employed neural network and also present the pseudo code showing the data collection strategy.\nRegarding the specific dynamics, we have added a citation to the given resource [1] since we consider the \u2018\u2019classical\u2019\u2019 quadcopter dynamics. We made it now more clearly, that these dynamics are known to the controller denoted as $g(\\cdot,\\cdot)$ in our problem formulation. The unknown part is the disturbance given by the thermals, which our model estimates. To clarify these, we have completely restructured Section 4.\n[1] Shi, Guanya, et al. \"Neural lander: Stable drone landing control using learned dynamics.\" International Conference on Robotics and Automation (ICRA). 2019.\n", "title": "Author response"}, "GWdh4M-2w7G": {"type": "review", "replyto": "j0p8ASp9Br", "review": "Epistemic uncertainty is a useful measure to have from a learned model. This paper proposes to output epistemic uncertainty from NN by training with samples outside the training set. My concerns are listed below:\n\n1. The paper samples epi points around the training set. How does this perform when training set is very sparse or very spread out. \n2. Changing the yellow line to something darker and also making the thick black line to be a lighter color would improve clarity of the results.", "title": "Epistemic uncertainty is output from NN using data sampled outside training data", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "P6tt2yGZ1jM": {"type": "review", "replyto": "j0p8ASp9Br", "review": "**Pros and the Key Idea**\nThis paper studies uncertainty quantification (UQ) in model-based learning for control, which is a timely and important research direction. The proposed method (EpiOpt) trains a neural network to predict the epistemic uncertainty directly. The training data for epistemic uncertainty prediction is artificially generated based on a simple nearest neighbor principle. The key ideas are: given the labeled training dataset $X_{tr},Y_{tr}$ (the data size $|X_{tr}|=N_{tr}$), this paper first randomly samples $X_{epi}$ around $X_{tr}$, where $|X_{epi}|=N_{epi}=k\\times N_{tr}$. Then this paper labels $x\\in X_{epi}$ by $1$ if the minimum distance from $x$ to $X_{tr}$ is far, and by $0$ if the distance is short. Finally, a neural network is trained for this binary classification task. \n\nFinally, this paper uses this idea in online control: the learned epistemic uncertainty is for adaptive data collection, and the aleatoric uncertainty is for control gain tunning. The advantage of this framework is that it is very simple, and doesn't need sampling or test-time dropout at the inference time.\n\n**Cons and Suggestions**\n(1) Many related work is missing especially for domain shift and adaptive control. As mentioned in this paper, the epistemic uncertainty is mainly from the data distribution shift, but there is no discussion about domain shift in this paper. The main idea of domain shift in ML is to *quantify the \"distance'' between the source and target domains*, which is similar to the epistemic uncertainty prediction $\\eta(\\cdot)$ in this paper. People also considers domain shift in control and learning (http://proceedings.mlr.press/v120/liu20a.html, https://arxiv.org/abs/2006.13916 and many others). \nAlso, adaptive control can handles epistemic uncertainty in an online manner as well. It would be great to discuss the difference between adaptive control. \nThe ensemble method (e.g., https://proceedings.neurips.cc/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf) is also an active method for UQ.\n\n(2) The key method, *EpiOpt*, is a bit too simple and there are no theoretical justifications or insights, such that it is hard to convince me about the generalirity and robustness of this method. As I mentioned above, the key idea of *EpiOpt* is to train a \"distance function\" $\\eta(\\cdot)$ to quantify the distance between the source and target data. This idea has been both theoretically and empiracally studied in domain shift and transfer learning. A few questions pop up from this paper: \n* Why do you need to sample $X_{epi}$ around $X_{tr}$? Since the goal is to get $\\eta(\\cdot)$, why don't you consider some analytical solutions such as KDE (kernel density estimation) to derive $\\eta(\\cdot)$? In other words, you could just use $X_{tr}$ to estimate a density function for the source data, and then evaluating this density function to get $\\eta(\\cdot)$. I didn't see a clear reason to *train* a neural network to estimation this distance.  \n* In equation (5), this paper labels $X_{epi}$ either $1$ or $0$. Why isn't it a continuous value from $0$ to $1$? For example, you can rank $d_j$ to get this continuous value.\n\n(3) The title and abstract of this paper emphasize a lot on *epistemic and aleatoric uncertainty decomposition*. However, the key method *EpiOpt* is only about the epistemic uncertainty, and how to deal with the aleatoric uncertainty only appears in the experimental section in equation (9). I highly recommend the authors discuss about these two types in the method section (Section 3) and give a general framework. The current aleatoric uncertainty is more like a gain tunning method, which is not related to *uncertainty decomposition* .\n\n(4) The experimental section is a bit vague. I highly recoomend the authors present the concrete learning and control problem first, e.g., Which part in the dynamics is learned? How to collect data? How to decompose the epistemic and aleatoric parts? A good example is https://ieeexplore.ieee.org/abstract/document/8794351, where the task is very similar. \n\n**Code-of-Ethics**\nI see no ethic issues in this paper.", "title": "An interesting paper about uncertainty quantification in dynamics learning for control. The proposed method EpiOut is sample-free at the inference time and it outperms some baselines. But there are no theoretical justification or insights, and the binary epistemic output is too simplified.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}}