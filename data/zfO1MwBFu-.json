{"paper": {"title": "Information Theoretic Regularization for Learning Global Features by Sequential VAE", "authors": ["Kei Akuzawa", "Yusuke Iwasawa", "Yutaka Matsuo"], "authorids": ["~Kei_Akuzawa1", "~Yusuke_Iwasawa1", "~Yutaka_Matsuo1"], "summary": "To assist sequential VAEs with global latent variable, we propose a new information theoretic regularization method for disentangling the global factors.", "abstract": "Sequential variational autoencoders (VAEs) with global latent variable $z$ have been studied for the purpose of disentangling the global features of data, which is useful in many downstream tasks. To assist the sequential VAEs further in obtaining meaningful $z$, an auxiliary loss that maximizes the mutual information (MI) between the observation and $z$ is often employed. However, by analyzing the sequential VAEs from the information theoretic perspective, we can claim that simply maximizing the MI encourages the latent variables to have redundant information and prevents the disentanglement of global and local features. Based on this analysis, we derive a novel regularization method that makes $z$ informative while encouraging the disentanglement. Specifically, the proposed method removes redundant information by minimizing the MI between $z$ and the local features by using adversarial training. In the experiments, we trained state-space and autoregressive model variants using speech and image datasets. The results indicate that the proposed method improves the performance of the downstream classification and data generation tasks, thereby supporting our information theoretic perspective in the learning of global representations.", "keywords": ["variational autoencoder", "VAE", "disentanglement", "global features", "sequential models", "representation learning", "mutual information"]}, "meta": {"decision": "Reject", "comment": "This paper presents a representation method for time series data in the sequential VAE, where the global feature z and local features  s are better disentangled. The intuition behind learning z is to maximize the mutual information between z and input x, while minimizing the mutual information between z and s. The second mutual information is estimated with a discriminator in the DRT framework. Overall, the methodology can be seen as reasonable applications of the disentanglement principle to sequential data. The authors have shown that z and s learned in this way is better disentangled as compared to beta-VAE. In the end, the reviewers feel that while there is good intuitions/technical ingredients, the derivations in Section 3 are not very smooth, and several approximations/choices are not very carefully justified (e.g., choice of alpha, choice of DRT vs. other MI estimators), and perhaps stronger baselines than beta-VAE can be used.\n\nThe reviewers rate this paper to be borderline."}, "review": {"8ytlnHIEGln": {"type": "review", "replyto": "zfO1MwBFu-", "review": "Update after rebuttal:\nI agree with Reviewer 5 that this paper has good ingredients, and the discussion and update of the draft clarifies the novelty and provides better review on the related work. However, the experiments presented in this paper are not very comprehensive, particularly the baselines and the ablation/alternative studies. I am not fully convinced by the authors response of \"because MI-VAE performed worse than $\\beta$-VAE in PixelCNN-VAEs ... we expected that a similar tendency would be observed.\" PixelCNN-VAE uses an autoregressive decoder, which are known to exhibit issues that are not observed from non-autoregressive ones like DSAE. This explanation of why MI-VAE was emitted seems slightly hand-wavy. I decided to decrease the rating to 6 to reflect the insufficiency in experiments, but hope that this experiment can be added if the paper is accepted.\n\nSummary:\nThis paper aims to learn representations that capture global features in structured data, such as the speaker information within speech or the digit class in an image. The authors argue that previous work regularizing the representation $z$ by maximizing its mutual information $I(x; z)$ with the data $x$ has the side effect of simultaneously maximizing the mutual information between $z$ and local features $s$. This may cause the global feature $z$ to encode unwanted local information or vice versa. To address this issue, the authors propose to regularize $z$ through maximizing $I(x;z) - I(z;s)$, which is a lower bound of the conditional MI $I(x;z|s)$. The proposed regularization is further estimated using the density ratio trick, which employs a discriminator to estimate the ratio $\\dfrac{q(z,s)}{p(z)q(s)}$ via a binary classification task and provide training signals to the encoder. The proposed regularization is applied to DSAE and PixcelCNN-VAE to demonstrate its effectiveness.\n\nPros:\n- The paper is well written and easy to follow. Motivations of this work are clear, and related studies are also properly described to contrast the difference from this work.\n- The formulation of the regularization seems novel to me. Derivation and approximations also make sense.\n- Experiments conducted on multiple domains (speech and images) demonstrate superior performance compared to the baseline methods (no regularization or MI-based regularization). Multiple metrics are adopted for evaluation of different aspects (e.g., AoLR/EER evaluates linear separability, mCAS indirectly evaluates diversity)\n\nCons/Questions:\n- The experiments on images compared the proposed method with both beta-VAE and MI-VAE. I am curious why the authors only compare with beta-VAE for the speech experiments but not MI-VAE. The EER reported in Hsu et al. (2017) is much lower than the results in this paper, and as mentioned by the authors, that work regularizes the representations with a discriminative objective that approximates $H(x|z)$ and therefore can be seen as a form of MI-VAE. The authors should also compare with such regularization for the speech experiments since it\u2019s shown effective in the previous work.\n- The authors state that approximating both $I(x;z)$ and $I(z;s)$ may complicate optimization, and avoid doing so by forcing alpha in Eq.8 to be 1 to enable rearrangement in Eq.10. However, it would be informative to show the results of approximating both terms with the density ratio trick and see how much it would affect the performance. By doing so, the strength of regularizing $I(z;s)$ can be independently tuned.\n", "title": "Review", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "WIoGXqSMrOU": {"type": "review", "replyto": "zfO1MwBFu-", "review": "**Update after discussion with authors**\nI want to thank the authors for their incredibly detailed responses and engaging so actively in the discussion. Some of my criticism could be addressed, while other issues are still somewhat open. If the main merit of the paper is to make the \"sequential VAE community\" aware of issues that have been discussed and addressed before, then I think the paper does an OK job at that (though I'm not entirely sure what community that is, the issues have been discussed before in the fields of vision and VAEs with autoregressive decoders). \n\nI want to strongly encourage the authors to be as precise as possible when describing the novelty - maximizing the mutual information that a representation carries w.r.t. some relevance variable while simultaneously minimizing information that it carries w.r.t. to another variable is NOT novel. What is novel is the application of that principle to separating \"global\" from \"local\" information in sequential data (and how to actually perform this originally intractable optimization in practice). I also want to encourage the authors to state what's known and what's new as clearly as possible and improve the quality and clarity of the \"educational\" review of why maximizing mutual information is not enough as much as possible.\n\nViewing the paper as \"showing how a known problem also appears when separating global from local information, and how to apply known solution-approaches to the problem in this specific context\", shifts the relative importance of the issues raised by me. Essentially, that view emphasizes the paper as mostly an application paper (rather than a novel theoretical contribution). Accordingly (but please make sure that that shift in view is also clear in the final paper), I am weakly in favor of accepting the paper and have updated my score accordingly.\n\n---\n\n**Summary**\nThe paper tackles the problem of separating \u2018global\u2019 from \u2018local\u2019 features in unsupervised representation learning. In particular, the paper tackles a common problem in autoencoders where the decoder (generative model) is autoregressive and conditioned on a variable. Ideally, the latter variable captures all global information (such as e.g. speaker identity) whereas the autoregressive model deals with generating local structure (such as e.g. phonemes). As the paper points out, capturing only global information (and all of it) in the conditioning variable alone is notoriously difficult with standard variational autoencoder objectives, and several solutions have been proposed in the past. In this paper the idea is to add an explicit penalty for statistical dependence (mutual information) between the global and the local random variable. This intractable objective is simplified with a series of approximations, leading to a novel training objective. Results are shown for speech data, and MNIST/FashionMNIST, where the proposed training objective outperforms a beta-VAE objective and an objective that explicitly aims to maximize information on the global variable.\n\n---\n**Contributions, Novelty, Impact**\n\n1) Analysis of shortcomings of mutual-information maximization to regularize latent representations into capturing \u2018global\u2019 features. This topic has been widely discussed in the literature before, typically in the context separating nuisance factors from relevant variations in the data, or more broadly: separating relevant from irrelevant information (which is canonically addressed in the information bottleneck framework of course). Most of this previous discussion was aimed at supervised learning ([2]), but there is a considerable body of work in unsupervised learning as well ([1] discusses the same issue but with more clarity), and some recent, very relevant work targeting VAEs with autoregressive decoders as well ([3] is among the state-of-the-art models). The paper provides a recap of this literature, but misses some key references, and the clarity of the writing (pages 1-4) could be improved (see my comments on clarity below). Therefore I would rate the impact of this contribution as low.\n\n2) Proposal of a novel regularizer. The main idea behind the regularizer Eq. (8) is good, but certainly not novel - it has been broadly discussed in the literature and implemented in various ways. The merit is thus in the particular derivation and approximations that lead to the objective in Eq. (13) and (14). To me the derivation seems correct, though the precise motivation is somewhat unclear (what shortcomings of alternative approaches are addressed here, e.g. using the density ration trick?). I personally think that there is sufficient novelty, but in the current manuscript it is hard to assess whether the novel method has benefits compared to strong competitor methods (which are unfortunately missing from the experiments).\n\n3) Experiments on a speech dataset (using a state-space-model decoder), and MNIST/FashionMNIST (using a PixelCNN). Results indicate that the extracted latent space does capture global features slightly better than a beta-VAE, or (quite a bit better than) a MI-maximizing VAE. There is also some indication that local features capture less global information with the proposed method compared to a beta-VAE. These results are promising, but not surprising since beta-VAE and MI-VAE were not designed to solve the shortcomings that the method is trying to address. For results to be more convincing and stronger, it would be good to compare against alternative approaches that have the same objective, such as e.g. [1] and [3]. Additionally more control experiments and ablations as well as reporting more metrics (l(x;z) and I(z;s), or proxies/approximations thereof) would strengthen the findings and thus the potential impact (see my comments on improvements below).\n\n(I am not an author of any of these)\n[1] Moyer et al. Invariant Representations without Adversarial Training, 2018\n[2] Jaiswal et al. Discovery and Separation of Features for Invariant Representation Learning, 2019\n[3] Razavi et al. Generating Diverse High-Fidelity Images with VQ-VAE-2, 2019\n\n---\n**Score and reasons for score**\nThe paper addresses an important problem that has received attention in the literature for at least two decades (the InfoBottleneck framework lays the theoretical foundations here). The particular application to: (i) unsupervised learning, and (ii) global-conditioned autoregressive (VAE) models is very timely and has received less attention in the literature (but there are some papers). \n\nMy main issue is that the paper addresses two problems: (A) separating global from local information, (B) avoiding that autoregressive decoders ignore the global latent variable. Clearly stating both problems, reviewing the literature for each of them, and then showing how the paper solves both of them (and showing experimental results for both of them) would really help with clarity and readability of the paper. It would also help flesh out the novel contributions made by the paper. Additionally, it is not entirely clear how well the proposed objective actually addresses (A) and (B) in the experiments. There is some good indication for (A), but it is not directly measured (e.g. by estimating I(x:z) and I(s;z)), the effect is only shown indirectly via AoLR and mCAS (or Err(z) and Err(s)). The same is true for (B): there is some that the generative model does not ignore the global latent code via the mCAS experiments, but it is quite indirect (also looking at the generated examples in appendix K raises some doubts about diversity of the generative model). \n\nOverall I think the ingredients for a good paper are there, but they are not quite coming together yet. A deeper look into the empirical results (control experiments, additional metrics), and a comparison against strong competitor methods are needed. My recommendation would also be to really focus on the new objectives (Eq. 13 and 14) and discuss in more detail how they differ from competitor approaches and what the theoretical/empirical advantages of these differences are (for instance I am personally not yet fully convinced that using the density-ratio-trick with a neural network classifier will always work well in practice). If all of that were in place, I think the paper would be significantly stronger and could potentially have wide impact. I thus recommend a major revision of the work, which is not possible within the rebuttal period. Below are concrete suggestions for improvements, and I will of course take into account the other reviews and authors\u2019 response.\n\n---\n**Strengths**\n\n1) The problem (separation of global and local info in variational unsupervised representation learning with autoregressive decoders) is timely and important, and has been somewhat neglected in the representation learning community (though there is work out there, and the same problem has been discussed extensively in a related context, such as e.g. supervised learning).\n\n2) The Method builds on a body of previous great work and applies it in an interesting context (global vs. local features).\n\n---\n**Weaknesses**\n\n1) Merits of the method somewhat unclear - the motivation/derivation when going from Eq. 8 to Eq. 13, 14  is a bit ad-hoc. What alternatives are there to the choices/approximations made? What are the advantages/disadvantages of these? Answering this might also involve some control experiments and ablations.\n\n2) The experiments show somewhat indirectly that the goals were achieved. There is some empirical evidence that the method is working to some degree, but it remains unclear whether e.g. the learned z capture only global information (and all of it), and whether s captures only local information (and how much of it). What\u2019s needed here are additional results/experiments.\n\n3) The current writing is ok but could be improved. I think it would be helpful to clearly state the problems and previous approaches of solving them (and the issues with these previous approaches). This would make it easier to see how the proposed method fits into the wider picture and which specific problem it addresses/improves upon. I think Alemi 2018 (cited in the paper) and [1] mentioned above do a very good job of describing the overall problem..\n\n---\n**Correctness**\nThe derivation of the method looks ok to me, though it would be nice to justify the approximations made and attempt to empirically verify that they do not have a severe impact on the solution. The conclusions drawn from the experiments are broadly ok, but since the evaluation measures the desired properties in a quite indirect way, the generality of the findings and the extent to which the method solves the problem (quantitatively) remain somewhat unclear.\n\n---\n**Clarity**\nIt took me a bit longer to follow the main line of arguments than it should have (which might of course be my fault). It\u2019s a bit hard to pinpoint to a specific paragraph, but perhaps the following suggestions are helpful for improving readability. It might be worth clearly stating the main problems (denoted (A) and (B) further up in \u2018Score and Reasons for Score\u2019) and separately discussion how they have been addressed (and what the remaining issues are) and how the paper addresses them. Currently this is entangled in the derivation of the method.\n\nIt would probably also help to have a short paragraph that summarises the novel contributions clearly (which makes it clear what\u2019s novel and what\u2019s been proposed before).\n\n---\n**Improvements (that would make me raise my score) / major issues**\n\n1) Comment on all assumptions made when going from Eq (8) to (13), (14). Are these assumptions justified in practice? Would there be alternative choices, and if yes what are the downsides of these alternative choices? Some of the assumptions will then lead to further control experiments that would ideally be included in the paper. One example (perhaps the most important one) is below in 2)\n\n2) Neural network classifiers are notoriously known to be ill-calibrated (typically having over-confident probability estimates). This could be problematic in the DRT approximation since the discriminator\u2019s output probability crucially matters! Is the discriminator well calibrated in practice? How robust is the method against calibration issues? Is the problem expected to get worse when scaling to more complex data and bigger network architectures? This needs to be discussed, but ideally some points are also verified empirically.\n\n3) beta-VAE and MI-VAE are ok baselines, but are not sufficient to show that the method performs very well. These two baseline methods have not been designed to address the main issue (separating global from local information) - it is thus not too surprising that the proposed method performs well. What\u2019s needed is comparisons against strong baselines, e.g. a (hierarchical) VQ-VAE2 (ref [3] further up). Given that the method only slightly outperforms beta-VAE on the metrics shown (which has no explicit incentive to capture global information) this is important.\n\n4) Report additional metrics (for each experiment it would be good to also report: reconstruction error, estimates of I(x;z) and I(z;s)). As \\gamma is varied, does the method lead to consistent increase in I(x;z) and decrease in I(z;s)? Are the values for the latter two significantly better than when using beta-VAE/MI-VAE?\n\n5) Reporting AoLR and mCAS with a logistic regressor/classifier is ok, because it says something about latent-space geometry which could be interesting. But for the paper it is more important to capture the exact amount of global information captured by z and s. Therefore it would be good to show additional results for AoLR and mCAS where the regressor/classifier is a powerful nonlinear model (a deep neural net).\n\n6a) Alemi et al. 2018 gets cited quite a bit in the paper, but is not very well represented in the paper. In particular: the paper proposes a quantitative measure as a diagnostic to see how much information is captured by the latent variable and how much of that is used/ignored by the decoder (which leads to the definition of several operating regimes, such as the \u201cauto-decoding\u201d regime). Why not report the same measure in the current method?\n\n6b) Alemi et al. 2018 actually propose a modified objective to target a specific rate. They empirically observe that a beta-VAE with beta<1 *in their experiments* leads to the VAE operating in the desired regime. As far as I understand they do not propose this as a general solution to fix decoders ignoring latent codes. This should be mentioned in the paper. As a consequence 6a) becomes even more important, or without any verification beta-VAE becomes an even weaker baseline, meaning that comparison against strong methods becomes more important.\n\n---\n**Minor comments**\n\na) Eq. (10) should be an inequality, because I(z;s) is upper bounded on r.h.s.?\n\nb) How was it determined that \u201calpha=1 works reasonably\u201d, is this based on some control experiments?\n\nc)  Eq (13). Why this particular mixing in of the KL-term, why not multiply KL(s) with (1-\\gamma) as well?\n\nd) Table 1: report the reconstruction error. In particular, for high \\gamma is there still reasonable reconstruction performance (and thus separation into global z and local s), or is all information except global information discarded and s essentially does not capture much meaningful information anymore, making good reconstruction impossible?\n\ne) Fig 3a - is the x-axis ELBO or KL?\n\nf) Fig 3, Table 1: ideally report multiple repetitions with error bars.\n\ng) For \\gamma=0.6 in appendix K, there seems to be very little diversity in samples drawn from either model. This should be mentioned more clearly in the main text.\n", "title": "Good main idea, but hard to judge whether approximations are justified and whether method would work well on more complex data", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "DSIrdcP0e_v": {"type": "rebuttal", "replyto": "tzFJPgSNiws", "comment": "**A3 \"the most interesting part is in how to make it tractable\"**\nThank you for your clarification.\nWe acknowledge that \"how to make it tractable\" is an interesting part, and have already clarified the merit of DRT compared to alternative choices in B1 and B2.\nAlso, we have already clarified the difference between Eq. (8) and [1-3] in A4;\nthen, we would appreciate it if you could suggest another prior methods \"that look very much like Eq. (8)\", which would be very helpful in clarifying the novel contributions and separating them from what's known.", "title": "Author Response (2/3) "}, "7N4Q0WucCAj": {"type": "rebuttal", "replyto": "PsU_QZq1Lrs", "comment": "**B3 \"beta-VAE and MI-VAE are very strong baselines to beat\"**\nThank you for your query.\nHere we explain why we think that they are the valid baselines.\nFirstly, our method is the first to regularize $I(x; z)$ and $I(z; s)$ at the same time (see, A3).\nTherefore, we think that a valid baseline should be (i) regularizing only $I(x; z)$, or (ii) regularizing only $I(z; s)$.\nThe comparison against these baselines can support our claim: not to achieve state-of-the-art results, but to show that regularizing $I(x; z)$ and $I(z; s)$ are complementary (see, A1).\nAmong them, (ii) would not work well because without regularizing $I(x; z)$, the model suffers from posterior collapse and $z$ has little meaningful information as reported in previous studies (e.g., Alemi et. al.).\nTherefore, (i) would be the only valid baseline, and $\\beta$-VAE and MI-VAE are the instances of (i).\nSecondly, we acknowledge that the comparison against [3] would improve our paper;\nhowever, our proposal is orthogonal to [3].\nIt is because [3] proposes a specific network architecture while we propose a regularization term (see, A4).\nMoreover, note that, because VQ-VAE2 has a different data generating process from that of DSAE, it cannot perform some applications that DSAE can perform (e.g., voice conversion without speaker labels).\n\n\n**B6-B7 \"using it is only weakly empirically justified by Alemi et al. - but the main message of that paper is a different one.\"**\nThank you for your clarification.\nFirstly, we acknowledge that \"the main message of that paper is a different one\" (targeting a specific rate via the objective).\nTherefore, we have clarified this point by redrafting the 2nd paragraph of Section 4.\nSecondly, however, we believe that $\\beta$-VAE is a valid baseline.\nIt is because $I(x; z)$-maximizing regularization is a standard approach to alleviate posterior collapse, and $\\beta$-VAE is a simple and effective instance of the regularization (see, the 2nd paragraph of Section 4).\nIn fact, the following sentence, which can be found in Section 5 of Alemi et. al., suggests that $\\beta$-VAE is a simpler and more effective method for alleviating posterior collapse than the prior methods:\n\"This fix is much easier to implement than other solutions that have been proposed in the literature, and comes with a clear theoretical justification.\"\nAlso, note that $\\beta$-VAE has a theoretical justification, which can be found in Section 2 of Alemi et. al, that it can control $I(x; z)$.\nThat is, since the ELBO contains a positive lower bound and a negative upper bound of $I(x; z)$, the MI can be controlled by balancing the two terms using a weighting parameter $\\beta$.\n", "title": "Author Response (3/3)"}, "6rWYhPewfe6": {"type": "rebuttal", "replyto": "qooXFoswvho", "comment": "We thank the reviewer for taking the time to thoroughly read our response and giving us the further feedback to strengthen our manuscript.\nWe will respond to the points separately.\n\n**A1 \"it is also important to clearly state the novel contributions and separate them from what's known and previously reported\"**\nWe agree with you, and have updated the 3rd and 4th paragraph of Section 4 to further clarify the difference between our paper and the previous studies.\n", "title": "Author Response (1/3)"}, "cqKE9-mUNo": {"type": "rebuttal", "replyto": "WIoGXqSMrOU", "comment": "## Part C\n\n### C1 \"Eq. (10) should be an inequality, because I(z;s) is upper bounded on r.h.s.?\"\nThank you for your query.\nNo, Eq (10) is equality because r.h.s. is composed of the upper bound of $I(x; z)$ and the negative upper bound of $I(z; s)$\nThe derivation is given in Appendix F.\n\n### C2 \"How was it determined that \u201calpha=1 works reasonably\u201d, is this based on some control experiments?\"\nThank you for your query.\n\"Alpha=1 works reasonably\" means that it outperformed the baseline methods ($\\beta$-VAE and MI-VAE) in our experiments.\n\n### C3 \"Eq (13). Why this particular mixing in of the KL-term, why not multiply KL(s) with (1-\\gamma) as well?\"\nThank you for your query.\nAs shown in Eq (13), $L_{SSM} + \\gamma I_{CMI-DRT}$ naturally results in the r.h.s..\nAlso, note that, reweighting KL(s) results in regularizing $I(x; s)$.\nSince our interest is regularizing $I(x; z)$ and $I(z; s)$ (see, A1), we did not employ the reweighting of KL(s).\n\n### C4 \"Table 1: ...\"\nThank you for your suggestion.\nWe have incorporated this suggestion into Appendix K1 and K2 (Update 14).\nAlso, we have confirmed that even for large $\\gamma$, there is still reasonable reconstruction performance.\n\n### C5 \"Fig 3a - is the x-axis ELBO or KL?\"\nThank you for your query.\nThe x-axis is set with ELBO because we expect that some may wonder about the relation between ELBO and AoLR as well as the relation between KL(z) and AoLR.\n\n### C6 \"Fig 3, Table 1: ideally report multiple repetitions with error bars.\"\nFor the experiment using speech data, we have incorporated this suggestion into Appendix K1 (Update 15).\nFor the experiment using image data, we are sorry, but we cannot afford to conduct multiple repetitions within the rebuttal period.\n\n### C7 \"For \\gamma=0.6 in appendix K, ...\"\nThank you for your suggestion.\nWe have clarified this point by redrafting the last paragraph of Section 5.3 (Update 16).\n\n\nAgain, thank you for giving us the opportunity to strengthen our manuscript with your valuable comments and queries.\nWe look forward to hearing from you regarding our submission.\n\n- Li et. al., Disentangled sequential autoencoder. ICML, 2018.\n- Razavi et. al., Preventing posterior collapse with delta-VAEs. ICLR, 2019.\n- Zhao et. al., Balancing learning and inference in variational autoencoders. AAAI, 2019.\n- Brock et. al., Large scale GAN training for high fidelity natural image synthesis. ICLR, 2019.\n- Iwasawa et. al., Stabilizing Adversarial Invariance Induction from Divergence Minimization Perspective. IJCAI, 2020.\n- Ganin et. al., Domain-adversarial training of neural networks. JMRL, 2016.\n- He et. al., Lagging inference networks and posterior collapse in variational autoencoders. ICLR, 2019.\n", "title": "Author Response to AnonReviewer5 (4/4) "}, "lQtpn3_q_Bt": {"type": "rebuttal", "replyto": "WIoGXqSMrOU", "comment": "## Part B\n\n### B1 \"Comment on ...\"\nWe thank the reviewer's suggestion and have clarified the following three points;\nhowever, note that, our claim is not that \"Eq. (13, 14) is the best approach\" (see A3) even if it has some merit.\n\n(i) \"all assumptions made ...\".\nAs well as prior studies (e.g., Ganin et. al.), the assumption we made is only that the classifier approximates the true density ratio.\nWe have added the above comment to the last paragraph of Section 3.2 (Update 9).\n\n(ii) \"Are these assumptions justified in practice?\"\nThis point will be addressed in B2.\n\n(iii) \"Would there be alternative ... \"\nOne of the alternative choices and its downside is discussed in the 3rd paragraph of Section 3.2 of the original manuscript.\nAdditionally, the following alternatives can be considered:\nthe second term in Eq. (10), which we approximated with a classifier, can also be approximated with other distances such as maximum mean discrepancy, or it can be minimized via Stein variational gradient (see, Zhao et. al.).\nHowever, a weakness of these methods is that they are difficult to apply efficiently in high dimensions.\nUnfortunately, because the second term treats the random variable $[z, s_1, ..., s_T]$, the dimension size becomes high when $T$ is large.\nWe have clarified this point by redrafting the last paragraph of Section 3.2 (Update 10).\n\n### B2 \"Neural network ...\"\nWe thank the reviewer's suggestion, and have clarified the following two points;\nhowever, again note that, we use the neural network classifier as an instance to regularize Eq. (8) (see, A3).\n\n(i) \"Is the discriminator well calibrated\", and \"How robust is the method\"\nIt has been reported by [1] and Iwasawa et. al. that the classifier is not always calibrated.\nHowever, it is also empirically known that original objectives (in our case, minimizing $D_{\\mathrm{KL}} (q(z, s) || p(z)q(s))$) can be reasonably achieved even if the classifier does not perfectly approximate true density ratio (Ganin et. al.).\nIn addition, various studies (e.g., Iwasawa et. al. and Miyato et. al.) have proposed techniques to improve the robustness of adversarial training.\nCombining these techniques with our method would potentially improve performance.\n\n(ii) \"Is the problem expected to get worse when scaling to ...\".\nAdversarial training has been shown to scale when carefully designed (e.g., Brock et. al.).\nAlso, the dimension size of the speech data used in our experiment is modestly large (200 x 20), which supports the ability of our method to scale.\n\nWe have clarified the above two points by redrafting the last paragraph of Section 3.2 (Update 11).\n\n### B3 \"beta-VAE and ...\"\nThis point has already been discussed in A4.\n\n### B4 \"Report additional ...\"\nWe have already incorporated this suggestion in Update 4 (see, A2);\nhowever, note that, using AoLR and EER falls in line with previous studies in the sequential VAE community (see, A2).\n\nNamely, as expected, CMI-VAE achieved the same level of $I(x; z)$ values and the lower $I(z; s)$ values compared to $\\beta$-VAE and MI-VAE, when $\\gamma$ becomes large.\nThis indicates that CMI-VAE can alleviate the mechanism (c) in A1.\n\n### B5 \"Reporting AoLR ...\"\nWe thank the reviewer's suggestion, and added the experiments to Appendix K2 (Update 12);\nhowever, note that, using AoLR falls in line with previous studies in the sequential VAE community (see, A2).\n\nNamely, we found that even if we use a more powerful non-linear classifier (SVM with RBF kernel), our method performed competitively or better than the baselines.\nHere, note that, we use SVM instead of DNN because the dimension size of $x$ and $z$ is not so large and therefore SVM is a proper baseline as well as easy to optimize.\n\n### B6 \"Alemi et al. 2018 gets ...\"\nThis point has already been clarified in A1 and A2.\nNamely, the reason why we did not perform the evaluation with auto-decoding regime is that our purpose is to learn good global representation.\nWe would like to evaluate whether $z$ is good global representation (measured by EER and AoLR), or whether the decoder uses global information within $z$ (measured by mCAS).\nOn the other hand, the auto-decoding regime evaluates whether a decoder uses $z$ or not.\n\n### B7 \"Alemi et al. 2018 actually ...\"\nWe acknowledge that one of their proposals is \"a modified objective to target a specific rate\";\nhowever, \"$\\beta$-VAE as a solution to PC\" is also one of their proposals.\nAs an evidence of it, the following sentence can be found in Section 5 of Alemi et. al.:\n\"We also confirmed that models with expressive decoders can ignore the latent code, and proposed a simple solution to this problem (namely reducing the KL penalty term to $\\beta$ < 1).\"\nA similar sentence can also be found in Abstract.\nMoreover, He et. al. also employed $\\beta$-VAE as a baseline, which supports that $\\beta$-VAE is a valid baseline to alleviate PC.\nwe have clarified this point by redrafting the 2nd paragraph of Section 2.2 (Update 13).\n", "title": "Author Response to AnonReviewer5 (3/4) "}, "feyUKsV19a": {"type": "rebuttal", "replyto": "WIoGXqSMrOU", "comment": "### A3 Regarding the novelty of Eq. (8)\n\n(i) The reviewer comments that \"Eq. (8) is good, but certainly not novel .. The merit is thus in ... in Eq. (13) and (14)\".\nYou have raised an important point;\nhowever, our novelty is not \"particular derivation and approximations\" of Eq. (13) and (14), but is \"the regularizer Eq. (8)\".\nThat is, as noted in A1, our novelty is to regularize $I(x; z)$ and $I(z; s)$ *at the same time*.\nIt is novel, especially in the context of the sequential VAEs, due to two reasons.\nFirstly, in previous studies of the sequential VAEs, although the regularization of $I(x; z)$ was proposed, the regularization of $I(z; s)$ has been overlooked (see, also, the mechanism (a-c) in A1).\nSecondly, in the studies for separating relevant from irrelevant information (such as [1], which is the reference you suggested), only the regularization of $I(z; s)$ is considered because they did not treat the sequential VAEs and did not have to care about the mechanism (b).\nThen, to further clarify this point, we have added the discussion about the relation between [1] and our paper to the 3rd paragraph of Section 4 (Update 6).\n\n(ii) Also, the reviewer requires to compare Eq. (13, 14) with alternative approaches since \"The merit is thus ... in Eq. (13) and (14)\".\nHowever, as discussed above, we consider that Eq. (13, 14) is one of the instances to regularize Eq. (8), even if Eq. (13, 14) has some merits (this point will be discussed in B1 and B2).\nWe have clarified this point by redrafting the 3rd paragraph of Section 3.2 (Update 7).\n\n\n### A4 Regarding the relation between our paper and [1-3]\nThe reviewer queries that our analysis is a \"recap\" of [1-3].\nWe agree that we have missed these important related works;\nhowever, we believe that our analysis is not the \"recap\" but is novel due to two reasons.\n(i) Firstly, our analysis clarifies the mechanism (a-c) (see, A1).\nWhile the phenomenon of (c), i.e., \"large $I(x; z)$ results in large $I(z; c=s)$\", was previously discussed by [1], the whole mechanism (a-c) has been overlooked in the sequential VAE community.\n(ii) Secondly, by explicitly considering the relationship between the two latent variables $z$ and $s$, our analysis is able to highlight a new problem that was not considered in [1-3].\nFor example, [1] considers the relationship between the latent variable $z$ and the observed nuisance factor $c=s$.\nThen, in [1], the focus is only on removing the redundant information from $z$.\nOn the other hand, our analysis highlights the need to consider removing the redundant information from $s$ at the same time as removing the redundant information from $z$.\nAlthough the former has been overlooked in [1-3] and the previous studies for the sequential VAEs, it is an important issue in applications such as voice conversion (see, the 4th paragraph of Section 1).\n\nAlso, we thank the reviewer's suggestion that \"it would be good to compare against alternative approaches that have the same objective, such as e.g. [1] and [3]\".\nWe acknowledge that the comparison would improve our paper;\nhowever, we believe that our regularization term Eq. (8) is novel (see, A3) and different from the objective of [1] and [3].\nNamely, our regularization term is composed of $I(x; z)$ and $I(z; s=c)$.\nOn the other hand, the regularization term of [1] is composed of only $I(z; c)$ because [1] did not care about the mechanism (b) (see, also, A3).\nAlso, to our understanding, [3] propose a specific network architecture to learn representation.\nTherefore, our proposal is orthogonal to [3] because we propose a regularization term, which is orthogonal to architecture choice (see, A1).\nMoreover, note that, because VQ-VAE2 has a different data generating process from that of DSAE, it cannot perform some applications that DSAE can perform (e.g., voice conversion without speaker labels).\n\nWe have clarified the relation between our paper and [1-3] by redrafting the 3rd paragraph of Section 4 (Update 8).\n", "title": "Author Response to AnonReviewer5 (2/4)"}, "SrW2Am3FAxd": {"type": "rebuttal", "replyto": "WIoGXqSMrOU", "comment": "We thank the reviewer for taking the time to thoroughly read our paper.\nWe are glad to hear that the ingredients for a good paper are there, and have worked hard to incorporate your valuable feedback.\nWe have separated our responses into three parts.\nIn Part A, we respond to major concerns of the reviewer (denoted as A1 to A4).\nIn Part B, we respond to each comments in the \"Improvements / major issues\" paragraph (B1 to B7).\nIn Part C, we respond to each comments in the \"Minor comments\" paragraph (C1 to C7).\n\n## Part A\n\n### A1 Regarding our contribution\nThank you for your suggestion that \"It would probably also help ... summarises the novel contributions clearly\".\nWe agree with you, and we first clarify our contributions here.\n\n(i) Through our information-theoretic analysis, we reveal the potential negative side-effect of MI-maximizing regularization, which has been standard in learning global representation with sequential VAEs as discussed in Section 1, 2.2, and 4.\nThis analysis makes the sequential VAE community aware of the limitation of the regularization, and encourages the community to seek for new regularization approach.\nNamely, our analysis formalises the following mechanism (a-c):\n- (a) Sequential VAEs with a global latent variable $z$ can in principle uncover global representation of data by exploiting its structured data generating process.\n- (b) Previous studies for the sequential VAEs have regularized mutual information $I(x; z)$ to be large in order to alleviate posterior collapse (PC).\n- (c) However, (b) can increase $I(z; s)$ as a side-effect, which contradicts the intention of (a).\n\n(ii) by analyzing the mechanism, we proposed a natural regularization approach that maximizes $I(x; z)$ and minimizes $I(z; s)$ *at the same time* in order to obtain *good global representation*.\n$I(x; z)$ and $I(x; z)$ are robustly shown to work complementary by our experiments using two models (DSAE and PixelCNN-VAE) and two domains (speech and image datasets).\nThis finding would help improve the various sequential VAEs proposed before, which are presented in Section 4.\n\nTo clarify our contribution, we have added the above discussion to the last paragraph of Section 1 (denoted as Update 1).\nAlso, we have revised Section 3.1 to further clarify the mechanism (a-c) (Update 2).\n\n\n### A2 Regarding \"the main problems (denoted as (A) and (B))\"\nThan you for your suggestion that we should clarify the following points.\n\n(i) Firstly, the reviewer suggests that \"It might be worth clearly stating the main problems (denoted as (A) and (B))\", and queries that \"how the paper addresses them\".\nYou have raised an important point.\nWe believe this point has already been clarified in A1.\nThat is, our main problem is not to tackle (A) and (B) independently, but rather learn good representation via regularizing $I(x; z)$ and $I(z; s)$.\nThe \"good representation\" is one that facilitates downstream applications such as controlled generation (e.g., voice conversion) and semi-supervised learning.\nAlso, we do not consider (A) and (B) as independent issues;\nrather, our analysis reveals the relation betweein (A) and (B): (A) becomes problematic as a side-effect of (B) in the sequential VAEs.\n\n(ii) Secondly, the reviewer suggests that \"separately discussion how they have been addressed\".\nWe have incorporated this suggestion.\nNamely, we have redrafted the 3rd paragraph of Section 4 to discuss \"how (A) have been addressed\" (Update 3).\nOn the other hand, \"how (B) have been addressed\" is already discussed in the 2nd paragraph of Section 4 of the original manuscript.\n\n(iii) Thirdly, the reviwer queries that \"it is not entirely clear how well the proposed objective actually addresses (A) and (B) in the experiments.\"\nWe acknowledge that assessing (A) and (B) would improve our paper;\ntherefore, we have reported the metrics suggested in \"Improvements 4\" to Appendix K1 and K2 (Update 4).\nHowever, we believe our contribution is defended with only the existing experiments because our purpose is not to increase $I(x; z)$ and decrease $I(z; s)$, but to obtain *good global representation* via regularizing them (see, A1);\nTherefore, *measuring representation quality* is a direct way.\nMoreover, EER and AoLR are the conventional metrics to assess the quality of global representation, e.g., Li et. al. and Razavi et. al. also use these metrics.\nOn the other hand, large $I(x; z)$ value and small $I(z; s)$ value do not necessarily indicate that $z$ is a good global representation.\n(For example, imagine the situation where $z$ has all the information about $x$ and $s$ has no information about $x$.\nIn this case, although $I(x; z)$ is high and $I(z; s)$ is low, $z$ does not capture only global information.)\nWe have further clarified these points by redrafting the 1st paragraph of Section 5.1 (Update 5).", "title": "Author Response to AnonReviewer5 (1/4)"}, "uzgipdk8bV": {"type": "rebuttal", "replyto": "8ytlnHIEGln", "comment": "We thank the reviewer for taking the time to thoroughly read our paper and giving us the opportunity to strengthen our manuscript with your valuable comments and queries. Below we respond to concerns that the reviewer commented.\n\n**A1 Regarding \"why the authors only compare with $\\beta$-VAE for the speech experiments but not MI-VAE.\"**\nThank you for your query. Because MI-VAE performed worse than $\\beta$-VAE in our experiments of PixelCNN-VAEs, which may be due to the adversarial training in MI-VAE causing optimization difficulties (see, Section 5.3), we expected that a similar tendency would be observed in the experiment using speech data.\n\n**A2 Regarding \"The authors should also compare with such regularization for the speech experiments since it\u2019s shown effective in the previous work\"**\nThank you for your suggestion.\n\n(point 1) Firstly, \"MI-VAE\" used in our experiment is different from the method of Hsu et. al. (2017), i.e., discriminative objective. Also, we did not compare with MI-VAE due to the reason explained in A1.\n\n(point 2) Secondly, we agree that we should have noted that \"The EER reported in Hsu et al. (2017) is much lower than the results in this paper\"; however, we believe that even if our method cannot outperform discriminative objective, our claim, \"regularizing $I(x; z)$ and $I(z; s)$ is complementary\", can be defended. It is because we compared CMI-VAE (regularization of $I(x; z)- I(z; s)$) to $\\beta$-VAE (regularization of $I(x; z)$), and showed that CMI-VAE consistently outperformed $\\beta$-VAE.\n\n(point 3) Thirdly, we chose to extend $\\beta$-VAE to construct the proposed objective function (Eqs. 13 and 14), although the discriminative objective could also be extended to CMI-regularization by the addition of the $I(z; s)$ minimization term as noted in Section 6. It is because we believe that $\\beta$-VAE is the simplest MI-maximization method that requires fewer hyperparameters, widely used in (sequential) VAE community (e.g., [1]). \n\nThen, we have added the discussion about point 2 to the last paragraph in Section 5.2, and added the discussion about point 3 to Section 6.\n\n**A3 Regarding \"it would be informative to show the results of approximating both terms ... can be independently tuned.\"**\nThank you for your suggestion. We agree that the experiments would be informative; however, since we cannot afford to conduct it within the rebuttal period, we have added it as a future work to Section 6. Also, while independent tuning would be informative, we believe that \"forcing alpha in Eq.8 to be 1\" has two merits as noted in Section 3.2 and Appendix D: it not only avoids complicating optimization, but also reveals the relation between our regularization term and conditional mutual information.\n\nAgain, thank you for giving us the opportunity to strengthen our manuscript with your valuable comments and queries.\nWe look forward to hearing from you regarding our submission.\n\n[1] He et. al., Lagging inference networks and posterior collapse in variational autoencoders. ICLR, 2019.\n", "title": "Author Response to AnonReviewer3"}, "V3AU31b2VTz": {"type": "rebuttal", "replyto": "p9ye8IZyHfo", "comment": "We thank the reviewer for taking the time to thoroughly read our paper and giving us the opportunity to strengthen our manuscript with your valuable comments and queries. Below we respond to a concern that the reviewer commented.\n\n**Regarding \"The density-ratio technique ... should be better explained in the paper\"**\nThank you for your suggestion. We have reflected this comment by two ways. Namely, (i) we have added a brief explanation of the density-ratio trick (DRT) (see, Sec.3.2). Also, (ii) we have added a citation [1], which discusses the relationship between DRT and adversarial training and can further facilitate the understanding (see, Sec.3.2).\n\nAgain, thank you for giving us the opportunity to strengthen our manuscript with your valuable comments and queries. We look forward to hearing from you regarding our submission.\n\n[1] Shakir Mohamed and Balaji Lakshminarayanan. Learning in implicit generative models. 2017.", "title": "Author Response to AnonReviewer2"}, "p9ye8IZyHfo": {"type": "review", "replyto": "zfO1MwBFu-", "review": "Summary\nObserving the deficiency of existing MI-based sequential VAEs, where through the learning objective design, the local and global features may become disentangled, the authors propose adding a regularizer to explicitly disentangle local and global features. To address the computation tractability issue of adding the new regularizer, a density-ratio based approximation is adopted and a classifier is trained to approximate the density-ratio term, which during training is learned alternatively with the VAE objective.\nRelation between the proposed method and Conditional MI, beta-VAE, and domain adversarial training is discussed. Then the proposed method is empirically evaluated on two sequential VAE based tasks: speech voice manipulation (DSAE) and image generation (PixelCNN-VAE). The authors designed experiments that show that the proposed approach can improve global representation learning.\n\nQuality\n\n*Pros: \nThe paper is overall of good quality: the context of the problem is well explained with adequate diagrams/plots to aide understanding. The approach is well motivated and the derivation of the approximation method is mostly easy to follow. Experiments are well designed and details are provided.\n\n*Cons:\nThe density-ratio technique to approximate D(q(z, s) || p(z)q(s)) should be better explained in the paper: I had to look into the reference (Sugiyama et al 2012) to understand the derivation in Equation (11).\n\nClarity\nThe paper is clearly written.\n\nOriginality\nThe paper is based on existing work of MI-VAE families of neural networks. Instead of proposing a completely new architecture/method, the authors spot a gap in the current literature, i.e., that local and global feature representations can be disentangled using the current learning objective. The paper addresses exactly this gap.\n\nSignificance\nThe paper and the proposed method should be of some significance to the VAE and domain-adaptation community and inspire future works.", "title": "Good paper, accept", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}