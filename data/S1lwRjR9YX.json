{"paper": {"title": "Stability of Stochastic Gradient Method with Momentum for Strongly Convex Loss Functions", "authors": ["Ali Ramezani-Kebrya", "Ashish Khisti", "and Ben Liang"], "authorids": ["aramezani@ece.utoronto.ca", "akhisti@ece.utoronto.ca", "liang@ece.utoronto.ca"], "summary": "Stochastic gradient method with momentum generalizes.", "abstract": "While momentum-based methods, in conjunction with the stochastic gradient descent, are widely used when training machine learning models, there is little theoretical understanding on the generalization error of such methods. In practice, the momentum parameter is often chosen in a heuristic fashion with little theoretical guidance. In this work, we use the framework of algorithmic stability to provide an upper-bound on the generalization error for the class of strongly convex loss functions, under mild technical assumptions. Our bound decays to zero inversely with the size of the training set, and increases as the momentum parameter is increased. We also develop an upper-bound on the expected true risk,  in terms of the number of training steps, the size of the training set, and the momentum parameter.", "keywords": ["Generalization Error", "Stochastic Gradient Descent", "Uniform Stability"]}, "meta": {"decision": "Reject", "comment": "The paper according to Reviewers needs more work for publication and significantly more clarifications. The Reviewers are not convinced on publishing even after intensive discussion that the AC read in full. The AC recommends further improvements on the paper to address better Reviewer's concerns."}, "review": {"rJxdSh34yV": {"type": "rebuttal", "replyto": "SJet7-5TC7", "comment": "Dear reviewer,\n\nRegarding the comparison with (Jain et al., 2018), we should clarify that only linear regression problem with quadratic loss function has been studied in (Jain et al., 2018), while we consider a general strongly-convex loss function. In addition, our generalization bound is based on uniform stability, which is not the case in (Jain et al., 2018). Hence, we do not find a strong connection between the results of (Jain et al., 2018) and those of our paper. \n\nWe emphasize that the claim that \"for problems with larger condition number, the momentum should approach to one\" is indeed based on *convergence* analysis of GD with momentum. It does not account for *generalization*. In addition, those recommended parameters are not necessarily optimal for SGD. In our view, what mainly matters is extending the results of (Hardt et al., 2016) to SGMM and showing that there exists some mu for which SGMM satisfies uniform stability, i.e., our machine learning model can be trained for multiple epochs and still generalizes. We have verified the trends predicted by our stability bounds using experimental evaluations. Those evaluations are based on common machine learning models leading to a smooth and strongly convex loss function.\n\nBy asymptotic, we mean that the problem structure imposes very large *kappa*. As explained before, the gamma parameter can be tuned by adjusting a weight decay regularization parameter in a typical machine learning model. We used 3.5 merely as an example to show that there exists mathematical problems for which the suggested momentum based on the convergence analysis of GD falls within the interval specified by Theorem 2 in our paper. We do not claim that kappa=3.5 necessarily represents practical problems in machine learning. Please note that even for the original work of  (Hardt et al., 2016), which analyzes the stability of SGD without momentum, there are some conditions on the learning rate in the theorem statements to satisfy the uniform stability, i.e., unlike the convergence analysis, the stability bounds typically involve limitations on the range of hyper-parameters. We further emphasize that our theorem for convergence analysis (Theorem 3) does not have any limitation on mu.\n", "title": "Response to AnonReviewer3 Comments "}, "Skl6ykATA7": {"type": "rebuttal", "replyto": "HkgEmbtaA7", "comment": "Dear reviewer,\n\nThank you for your comments and pointing out the typos.\n\nRegarding Proposition 1, please note that in our proof (Page 2 in the \nsupplementary document of the original submission, which can be accessed \nby clicking \"show revisions\"), we have first shown (as stated in \nLemma 2) that the stability bound holds for the average of ${w_t}$. \nTherefore, we believe that Proposition 1 is correct.\n", "title": "Response to AnonReviewer1 Comments "}, "B1e21iAhA7": {"type": "rebuttal", "replyto": "HJlL1YjoCm", "comment": "Our problem setting involves constrained optimization where we seek the optimal solution within a compact set. This constraint is assumed to be given apriori in the problem definition.  Such setting have been widely considered in the literature. See for example:  (Hardt et al., 2016)[Section 3.4]).  \n\nPlease note that we do not address the unconstrained optimization problem that you mention in your response. Thus we do not need to design the compact set that increases the chance of the compact set containing the optimal solution.\n\nWe hope this clarifies our problem setup and you are convinced by the technical soundness of our work.\n", "title": "Response to AnonReviewer2 Comment"}, "ryemHZssRm": {"type": "rebuttal", "replyto": "HyeCCsdoRm", "comment": "Dear reviewer,\n\nThe supplementary document was submitted along with the original \nsubmission. It can be found by clicking the \"Show revisions\" link below \nthe paper title.\n", "title": "Response to AnonReviewer2 Comment"}, "rJxsFK_iRQ": {"type": "rebuttal", "replyto": "ryeWFpGiCX", "comment": "Dear reviewer,\n\nPlease note that inequalities (A.2) and (A.3) (shown in the proof of  Lemma 1 in the supplementary document) hold for the projected SGMM update (5) because Euclidean projection does not increase the distance  between projected points. We are quite certain that our proof is  correct, since our approach to handle projection is a commonly used  technique in existing work. For example, it is used in (Hardt et al., 2016)[Section 3.4]. ", "title": "Response to AnonReviewer2 Comment"}, "HkxhFKzs07": {"type": "rebuttal", "replyto": "SkglZ4I90Q", "comment": "Dear reviewer, \n\n- To clarify the correctness of our proof, please note that L in the theorem statement and the proof is bounded due to compactness of the parameter space. We have shown that (19) holds for projected SGMM. Before (19), we have not used L-Lipschitz. \n\n- Regarding convergence analysis, please note that our goal is to find a *global* convergence bound not a \"local\" one. We know that classical results show that heavy ball momentum achieves linear convergence rate locally. However, those results are for batch gradient descent not stochastic gradient descent for a general strongly-convex function. ", "title": "Response to AnonReviewer2 Comments "}, "SkewoU49R7": {"type": "rebuttal", "replyto": "SJx-bmHbnm", "comment": "R2C1: We believe that our results are substantial and important. Our analysis involves some subtle but important steps in dealing with the momentum term in the recursion in Section 4. This method was not conceived in prior attempts on this problem. We reproduce the following statement from [Hardt et al., Section 7]: ``One very important technique that we did not discuss is momentum. However, it is not clear that momentum adds stability. It is possible that momentum speeds up training but adversely impacts generalization.'' Our work is the first successful attempt that establishes that SGMM generalizes, for the practically important class of strongly convex loss functions.\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nR2C2: Please note that we first discuss the proofs without projection to keep the notation uncluttered. We then explain how the proofs can be modified to accommodate projection. We believe this approach is technically sound, and it helps the readers to better understand the insights in our proofs. We respectfully request that the reviewer point out any specific issue in our proofs such that we can fix it.\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nR2C3: To the best of our understanding, linear convergence happens under a very stringent condition: $\\Pr\\{\\nabla f_i(x^*)=0\\}=1$, \\ie $x^*$ is a simultaneous minimizer of (almost) all $f_i(x^*)$ [Needell et al. , 2014] . Such a condition would artificially force that the loss function be simultaneously minimized on each training example. In absence of this condition, SGD appears to exhibit similar convergence rate as our paper, albeit under somewhat different assumptions on the loss function.\n\nMoreover, in terms of convergence, we cannot claim that SGMM always outperforms SGM without momentum. For example, in [Kidambi et al. , 2018], the authors show that there exists linear regression problems for which SGM outperforms SGMM in terms of convergence for any learning rate and momentum parameter. \n", "title": "Response to AnonReviewer2 Comments "}, "HJxr0SV90m": {"type": "rebuttal", "replyto": "Skl1MikYnX", "comment": "R1C1: Our analysis involves some subtle but important steps in dealing with the momentum term in the recursion in Section 4. This method was not conceived in prior attempts on this problem. To convince you, we reproduce the following statement from [Hardt et al., Section 7]: ``One very important technique that we did not discuss is momentum. However, it is not clear that momentum adds stability. It is possible that momentum speeds up training but adversely impacts generalization.'' Our work is the first successful attempt that establishes that SGMM generalizes, for the practically important class of strongly convex loss functions.", "title": "Response to AnonReviewer1 Comments"}, "SyenUHNcA7": {"type": "rebuttal", "replyto": "r1lvWTHc2X", "comment": "R3C1: Please note that the theoretically advocated momentum parameters mu = (sqrt(kappa)-1)/(sqrt(kappa)+1) [Nesterov, 1983] or mu = ( (sqrt(kappa)-1)/(sqrt(kappa)+1) )^2 [Polyak,1964] are based on the *convergence* analysis of GD with momentum -- they do not account for *generalization*. Therefore, these values are not necessarily optimal for SGD with momentum (SGMM), in terms of our objective of true risk. In Theorem 2, our focus is to find a bound on stability, i.e., the condition on generalization. Our theorem for convergence analysis (Theorem 3) does not have any limitation on mu.\n\nOur goal in Theorem 2 is to find the tightest possible bound that shows why machine learning models can be trained for multiple epochs of SGMM while their generalization errors are limited. In order to satisfy uniform stability for SGMM (with constant momentum), we need to have a recursion with coeff<1. Even ignoring the third term in the RHS of (12), we still have to assume mu<1/kappa in order to have such a recursion. \n\nWe agree theoretically suggested momentum parameters for GD approach 1 \u2013 1/sqrt(kappa), which grow close to one as kappa grows large. On the other hand, as our concern in this work is on gamma-strongly convex loss functions, where the gamma parameter can be tuned by adjusting a weight decay regularization parameter in a typical machine learning model, it is indeed important and interesting to study the generalization bound when kappa is not too large, i.e., the non-asymptotic regime. When kappa is not too large, the range specified in our theorem captures a typical value of the suggested momentum based on convergence analysis of GD. As an example, if we set kappa = 3.5, then ((sqrt(kappa)-1)/(sqrt(kappa)+1))^2\u22480.1, which is approximately 1/(3*kappa). \n------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nR3C2: In the original submission, we specified the condition mu*(beta+gamma)<<alpha*beta*gamma in the supplementary document. In the revision, we have explicitly provided this condition it in the proposition statement. Please note that this condition is used only to make tractable the optimization of the expected true risk over alpha. In practice, we can still use alpha as specified in Proposition 1. However, it will not necessarily optimize the upper-bound on the expected true risk.\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nR3C3: Please note that although [1]-[3] study first-order methods with noisy (imperfect) gradients, none of these works study generalization of SGD for a strongly convex loss function using algorithmic stability. We note that both [1] and [2] are cited in [3]. In the revision, we have added the following sentence to our introduction: \"First-order methods with noisy gradient are studied in [Kidambi et al. , 2018] and references therein. In [Kidambi et al. , 2018], the authors show that there exists linear regression problems for which SGM outperforms SGMM in terms of convergence.\"\n\nRegarding comparison with [Loizou et al. , 2018], please note that [Loizou et al. , 2018] considers the special case of a convex *quadratic* loss function of a least-squares type, while we consider the general case of strongly convex loss functions. Furthermore, we emphasize that we do not limit our analysis of SGMM to super large batch sizes. Our analysis indeed works even for a batch size of one.\n", "title": "Response to AnonReviewer3 Comments"}, "r1lvWTHc2X": {"type": "review", "replyto": "S1lwRjR9YX", "review": "This paper presents an analysis of generalization error of SGD with multiple passes for strongly convex objectives using the framework of algorithmic stability [Bousquet and Elisseef, 2002] and its recent use to analyze generalization error of SGD based methods [Hardt, Recht and Singer 2016].\n\nThe problem considered by this work is interesting and raises the possibility of understanding generalization related questions of SGD style methods when augmented with momentum, which is common practice in Deep Learning [Sutskever et al. 2013]. That said, there are some concerns about the results as presented in this paper, which I will elaborate below:\n\n- Consider the stability bound admitted by theorem 2: The special case (similar to theorem 3.9 of Hardt et al 2016) when the learning rate alpha = 1/beta (which is the typical learning rate that theory advocates), and setting kappa = beta/gamma where kappa is the condition number of the problem, leads to the following bound on momentum allowed by theorem 2, which is:\n\n(something non-positive) <= mu < 1/(3*kappa). \n\nThis is basically the regime where momentum does not make any difference towards accelerating optimization. Referring to the standard value of momentum for strongly convex functions, we see that the momentum is set as mu = (sqrt(kappa)-1)/(sqrt(kappa)+1) [Nesterov, 1983], or, mu = ( (sqrt(kappa)-1)/(sqrt(kappa)+1) )^2  [Polyak,1964]. Upon simplification of this standard momentum values, we see that mu \\approx 1 - 1/sqrt(kappa) which grows close to one as kappa grows large. On the other hand, the momentum values admitted by the paper for their bound is super tiny (which gets to zero as the condition number kappa grows large). This essentially implies there is not much about momentum that is captured by the bound of theorem 2 since there is no characterization of the provided bound for theoretically advocated and practically used parameters for momentum.\n\n- In proposition 1, there is no quantitative description of what \"sufficiently small\" mu (momentum parameter) is - this statement is imprecise. As mentioned in the previous point, sufficiently small mu really is not descriptive of momentum parameters employed in practice (mu in practice typically is >= 0.9). For strongly convex objectives, this should be closer to 1- (1/sqrt(kappa)). Sufficiently small mu parameter essentially does not yield quantitatively different behaviors compared to standard SGD. \n\n\nIn summary, while this paper attempts to make progress on an interesting question, but falls short and doesn't really capture the behavior of these methods that is even mildly reflective of practice (even in terms of the parameter regimes admitted by the bounds proven in the theorems).\n\n- This paper does not perform a thorough literature survey of published results. Furthermore, this paper does not present a precise treatment of assumptions (and implications) amongst other works cited in the paper (see for e.g. [4] below). \n\n[1] Polyak (1987) presents (generalization) behavior of Heavy Ball momentum with noisy (inexact) gradients.\n[2] Several efforts in Signal Processing literature do consider the similar setting as one considered by this paper, which is that of Heavy Ball (called accelerated LMS) method with noisy gradients: refer to Proakis (1974), Roy and Shynk (1990), Sharma et al. (1998). \n[3] Kidambi et al (2018) estimate the \"optimization\" power (which is a part of characterization of generalization error [Bach and Moulines 2011], since this dominates at the start of optimization) of HB method with Stochastic Gradients and prove that HB+stochastic gradients does not offer any speedup over vanilla SGD.\n[4] Loizou and Richtarik provide an analysis of stochastic heavy ball with super large batch sizes (so they end up showing accelerated rates) under similar assumptions as considered by this paper, such as assuming the function is smooth and strongly convex. However, the paper dismisses the work of Loizou and Richtarik to be working with a different set of assumptions - this is not really true.", "title": "Interesting question and direction", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "Skl1MikYnX": {"type": "review", "replyto": "S1lwRjR9YX", "review": "This paper studies the algorithmic stability of SGD with momentum and provides an upper-bound on true risk through convergence analysis.\nThis bound clarifies dependencies of convergence speed on the size of dataset and the momentum parameter.\n\nThe presentation is easy to follow and technically sounds good.\nSGD with momentum is heavily used for learning linear models and deep neural networks, hence to analyze its convergence behavior is quite important.\nThis paper achieves this goal well by extending a previous result on vanilla SGD in a straightforward manner, although it is not technically difficult.\n", "title": "Review", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "SJx-bmHbnm": {"type": "review", "replyto": "S1lwRjR9YX", "review": "Comments: \n\nThe author(s) provide stability and generalization bounds for SGD with momentum for strongly convex, smooth, and Lipschitz losses. \n\nThis paper basically follows and extends the results from (Hardt, Recht, and Singer, 2016). Section 2 is quite identical but without mentioning the overlap from Section 2 in (Hardt et al, 2016). The analysis closely follows the approach from there. \n\nThe proof of Theorem 2 has some issues. The set of assumptions (smooth, Lipschitz and strongly convex) is not valid on the whole set R^d, for example quadratic function. In this case, your Lipschitz constant L would be arbitrarily large and could be damaged your theoretical result. To consider projected step is true, but the proof without projection (and then explaining in the end) should have troubles. \n\nFrom the theoretical results, it is not clear that momentum parameter affects positively or negatively. In Theorem 3, what is the advantage of this convergence compared to SGD? It seems that it is not better than SGD. Moreover, if \\mu = 0 and \\gamma > 0, it seems not able to recover the linear convergence to neighborhood of SGD. Please also notice that, in this situation, L also could be large. \n\nThe topic could be interesting but the contributions are very incremental. At the current state, I do not support the publications of this paper. \n", "title": "Stability of Stochastic Gradient Method with Momentum for Strongly Convex Loss Functions", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}