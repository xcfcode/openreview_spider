{"paper": {"title": "On the Need for Topology-Aware Generative Models for Manifold-Based Defenses", "authors": ["Uyeong Jang", "Susmit Jha", "Somesh Jha"], "authorids": ["wjang@cs.wisc.edu", "susmit.jha@sri.com", "jha@cs.wisc.edu"], "summary": "", "abstract": "ML algorithms or models, especially deep neural networks (DNNs), have shown significant promise in several areas. However, recently researchers have demonstrated that ML algorithms, especially DNNs, are vulnerable to adversarial examples (slightly perturbed samples that cause mis-classification). Existence of adversarial examples has hindered deployment of ML algorithms in safety-critical sectors, such as security. Several defenses for adversarial examples exist in the literature. One of the important classes of defenses are manifold-based defenses, where a sample is \"pulled back\" into the data manifold before classifying. These defenses rely on the manifold assumption (data lie in a manifold of lower dimension than the input space). These defenses use a generative model to approximate the input distribution. This paper asks the following question: do the generative models used in manifold-based defenses need to be topology-aware? Our paper suggests the answer is yes. We provide theoretical and empirical evidence to support our claim.", "keywords": ["Manifold-based Defense", "Robust Learning", "Adversarial Attacks"]}, "meta": {"decision": "Accept (Poster)", "comment": "This paper studies the role of topology in designing adversarial defenses. Specifically , the authors study defense strategies that rely on the assumption that data lies on a low-dimensional manifold, and show theoretical and empirical evidence that such defenses need to build a topological understanding of the data.\n\nReviewers were initially positive, but had some concerns pertaining to clarity and limited experimental setup. After a productive rebuttal phase, now reviewers are mostly in favor of acceptance, thanks to the improved readibility and clarity. Despite the small-scale experimental validation, ultimately both reviewers and AC conclude this paper is worthy of publication.  "}, "review": {"Skg5fxnRYr": {"type": "review", "replyto": "r1lF_CEYwS", "review": "This paper argues that defenses against adversarial attacks need to be stronger than they currently are. Defenses that use generative models assume that there exists a manifold of data that is modeled by a trained generative model that can be used to project any out-of-manifold data unto the manifold. However, this work argues that if the generative model does not model the topology of the manifold, it can still be fooled by an adversarial example. They argue that a generative model needs to be at least aware of the number of connected components of the data-generating manifold. If the number of connected components does not match, based on theorem 2, Corollary 1 argues that a generative model can generate an adversarial example that does not exist in the data-generating manifold.\n\nPros:\n- To the extent I checked, proofs are correct.\n- The experimental results support this result on 2D toy manifolds. They show how a prior defense based on generative-models (INC) fails on the toy problems and show how a modification to INC can improve it.\n\nCons:\n- In their experiments, they use the number of classes as an approximation to the number of connected components (Appendix E) and train class-conditional generative models. Some of these details are better to be put in the main text.\n- There are no experiments beyond toy examples on high-dimensional problems and datasets. It should not be too difficult to have some preliminary results using the proposed extension of INC on MNIST or CIFAR10.\n\nAfter rebuttal:\nI have raised my score after authors improved to quality of the text. Even though this work does not have empirical results on high-dimensional datasets such as MNIST or CIFAR10, it has a nice theoretical contribution useful for finding stronger defenses against adversarial examples.", "title": "Official Blind Review #2", "rating": "8: Accept", "confidence": 3}, "BJbpU5hoS": {"type": "rebuttal", "replyto": "r1lF_CEYwS", "comment": "We found the following minor typo after posting the rebuttal, and it is now corrected.\n - The loss function is corrected from \"likelihood\" to \"negative log-likelihood\".\n - The title of Figure 7a is corrected from \"Isotropic Gaussian\" to \"Mixture of 2 Gaussians\".", "title": "Minor changes made after rebuttal"}, "BylhlU9hjr": {"type": "rebuttal", "replyto": "SkxkP9InoS", "comment": "Thank you for another response.\nThe following challenges that we encountered come across our mind.\n\n - Our code was originally designed for 2-D data, and it required a few more implementations for high dimensional data, so there have been major changes in the code to incorporate the change in the architecture. For example, we implemented checkerboard masking (by permuting dimensions before passing data into coupling layers) as it is not explicitly supported by the TensorFlow-probability library.\n\n - As the loss function of training is defined with negative log-likelihood, when the model encounters a training batch that is very unlikely to be generated by the model being trained, the loss blows up to infinity value (np.inf in Python Numpy library) and fails to compute the gradient for next training. This happened from time to time, crashing the training during the convergence. After numerous trials and errors, we found a parameter setting that reduces the number of these mishaps, so now the training process at least decreases the model loss.\n\n - Applying class-aware training to real-world data, e.g. MNIST, was another challenge. For example, from the new discussion in Appendix D.6, we know that the alignment of Gaussian distribution matters, and it is desirable to find the center of Gaussians that,\n  1. Reflects the \u201clocation\u201d of each data-generating manifold corresponding to each label.\n  2. Each center should be far enough so that superlevel sets of Gaussian are separated in the latent vector space.\nWe first computed the center of each cluster (data points with the same label) in the training set, to reflect the location of each data-generating manifold, then we took the elementary basis of $R^784$ (784 is the dimension of MNIST dataset) that is closest to the center. By taking elementary basis elements we can ensure the minimum distance is bounded by some number so that superlevel sets of Gaussian are separated with a proper choice of the standard deviation of Gaussian distributions.\n", "title": "Thanks for your response"}, "BkxjO615FH": {"type": "review", "replyto": "r1lF_CEYwS", "review": "I. Summary of the Paper\n\nThis paper studies robustness to adversarial examples from the\nperspective of having 'topology-aware' generative models. Next\nto some experiments on data sets with a manifold structure, the\nmain contribution of the paper is a tandem of theorems that state\nthe conditions under which models can recover the topology---or\nthe number of connected components---of a data set correctly,\nthereby making them more robust to adversarial examples.\n\nII. Summary of the Review\n\nThis paper provides a novel perspective on adversarial examples through\nthe lens of Riemannian Geometry and topology. I appreciate novel\nresearch that employs topology-based methods, but at present, I cannot\nfully endorse accepting the paper. Specifically, I see the following\nissues:\n\n- Missing clarity: while the appendix is very comprehensive, which\n  I appreciate, the main text could be improved; some statements appear\n  redundant, while others need to be re-formulated to build intuition\n\n- This paper appears to span both theory and applications. I appreciate\n  this attempt, knowing full well that this is no easy feat to\n  accomplish. However, the main theoretical result on the number of\n  connected components only applies to mixtures of Gaussian\n  distributions, but the purported scope of the paper is the analysis of\n  manifold-based defences in general. I would expect a more in-depth\n  discussion of the limitations of the theorem. Can we expect this to\n  generalise? Moreover, 'topology' is reduced to 'connected components'\n  in this paper. While this is perfectly adequate in the sense of\n  connected components being a particular concept from topology, I would\n  expect this to be clarified much earlier in the paper. In addition,\n  connected components are a very basic and coarse concept, so I am\n  wondering to what extent it is sufficient to describe models purely\n  based on that information.\n\n- As a sort of corollary to the previous point, the experiments could be\n  improved. I like the idea of employing known data sets with a simple\n  manifold structure, but the setup is somewhat preliminary; I would\n  prefer to see an analysis of border cases or limit cases in which the\n  theorem _almost_ applies (or not); plus, a more in-depth analysis of\n  stochastic effects during training: do _all_ models end up being\n  robust if their number of connected components is sufficiently large?\n  Is there a dependency between the number of connected components and\n  vulnerabilities---are models with a very small number of connected\n  components more vulnerable than models with a very larger number of\n  connected components? The present experimental section is lacking this\n  depth.\n\n- The same statements apply to the INC example. I found this super\n  instructive, but it is only _one_ case on _one_ manifold---I would\n  like to see more details here; maybe some of the experiments in the\n  appendix could be moved to the front? I have some suggestions for\n  shortening the paper (see below).\n\nDespite these issues, I think this paper can be a strong contribution if\nproperly revised; since I am positive that at least some of these\nsuggestions could be performed within a revision cycle, I want to be\nupfront and state that I will definitely consider raising my score,\nprovided that my concerns are addressed appropriately!\n\nI have to state that I am _not_ an expert in adversarial examples, but\nan expert in topology-based methods; I consider this paper to belong to\nthe latter field given its theoretical contributions about 'recovering'\nthe correct density distribution.\n\nIII. Clarity\n\nThe paper provides an extensive background to Riemannian geometry, which\nI appreciated as a reference. Nevertheless, there are improvements to\nthe main text that I would suggest:\n\n- Please consider changing the title to 'On the need...'\n\n- The manifold assumption is that data lie _on_ a manifold or _close to_\n  a manifold whose intrinsic dimension is much lower than that of the\n  ambient space. This is not stated in sufficient precision in the\n  paper; please correct the usage on p. 1 and p. 2\n\n- In terms of notation, why use $p_M$ to denote the density on the whole\n  of $\\mathds{R}^n$? I would expect $p_M$ to refer to the density on $M$\n  rather than the density of the whole space.\n\n- If $M$ is a disjoint union of manifolds, please consider using\n  a '\\cupdot' operator to make this more clear.\n\n- If the pairwise manifolds are disjoint, how can the resulting data\n  distribution still contain any ambiguities? I find this hard to\n  harmonise with the statement in Section 3.4 about the existence of\n  a classifier that separates the manifolds. Please clarify the meaning\n  behind the term 'ambiguities' here.\n\n- The '(R0)' requirement definition and the discussion in Section 3.2\n  strike me as needlessly complex. Would it be possible to shorten this\n  or move some content to the appendix? I think it would be sufficient\n  to have Eq. 1 and mention how it could be solved.\n\n- Section 3.3 could be shortened as well, if I am not mistaken; while it\n  is good to know how such models look, the 'change of variable formula'\n  is not used directly any more in the paper; I think it might be easier\n  to write down a generic form of the density for each model.\n\n- The salient points of Section 3.4 seem to be the projection point;\n  maybe this could also be shortened somewhat in the interest of having\n  more space for experiments. The relevant information of this section\n  was to learn how projections work for different models, but it would\n  be sufficient to keep Eq. 3 and discuss Eq. 4 in the appendix\n\n- The 'topological differences' mentioned in Section 4 could be\n  clarified: the paper talks about differences in connected components.\n\n- The $\\lambda$-density set appears to be a superlevel set, if I am not\n  mistaken: the level set would be defined for a single threshold only,\n  while this paper introduces the pre-image of an interval.\n\n- I would expect the pre-image to be defined as $p^{-1}$, not $p_{-1}$;\n  the latter strikes me as somewhat non-standard usage\n\n- The statements preceding Definition 1 require some more intuition;\n  what is the purpose of these assumptions?\n\n- The notation for the Euclidean balls should be briefly introduced\n  before Definition 1. I recognise this as a standard notation, but\n  since this is the first appearance of the symbol, it should be\n  mentioned at least briefly.\n\n- Definition 1 could also be phrased more intuitively; additional\n  sentence behind each definition would be useful, such as:\n  $\\delta_\\lambda$ is the largest $\\delta$ such that the full\n  superlevel set is contained in a ball of radius $\\delta_\\lambda$.\n\n  Figure 1 is already helpful in that regard; it should ideally precede\n  the definition and/or be made larger to be more illustrative\n\n- Maybe the results of Theorem 2 could already be stated earlier; it\n  could probably be explained reasonably well when describing the number\n  of connected components as a sort of 'baseline' topological complexity\n  that a model has to satisfy.\n\n  On a more abstract level, could it also be summarised as 'the\n  inclusion of prior knowledge is a necessary condition for robustness'?\n\n- I would not state that the main goals of the experiments are to\n  'check the correctness of Theorem 2'---the proofs should be\n  responsible for this! I would rather say that the main goals are to\n  provide empirical evidence for the *relevance* or *applicability* of\n  the Theorem.\n\n- The paragraph on 'Latent vector distributions' contains the most\n  relevant information, viz. the knowledge of what the paper considers\n  to be a 'topology-aware' and 'topology-ignorant' model; this should be\n  highlighted more; maybe the figures could be extended to contain\n  information about $n_X$?\n\nOverall, I like the idea of having one overarching question in a paper\nthat is subsequently answered or discussed under different aspects. I\nvery much commend the authors of the paper for choosing this sort of\nwriting style!\n\nIV. Experimental setup\n\nAs mentioned above, the experiments require more depth. I would propose\nadding more repetitions of the training process for different data sets\nand analysing the impact of the 'parameters' used in the theorems.\n\nIn particular, the 'INC' experiments show great promise for multiple\nrepetitions. Why not choose more data sets and more staring positions\nand visualise the trajectories of _multiple_ draws, as shown for\na single draw in Figure 4 a,b,c?\n\nAlso, please consider moving the additional experiments from the\nappendix to the main paper.\n\nMore compelling examples would also be helpful. Why not generate data\nsets consisting of more than two manifolds? At present, the largest\nissue I see in this section is that the conceptual 'leap of faith'\nbetween the theory and the applications is simply too large. Would it\nnot be possible to perform the same experiments on a simple digits data\nset, say MNIST?\n\nV. Minor issues\n\nThe paper is well-written overall. There are only a few typos and minor\nstyle issues that I would recommend fixing:\n\n- please check the usage of quotes; it should be ``pulled back'', not ''pulled back'' in LaTeX\n\n- please check the usage of citations; if '\\citet' is used, citations\n  can be used as nouns directly (for example: 'in Pennec (1999)' instead\n  of 'in (Pennec, 1999)'.\n\n- etc.. --> etc.\n- it approximates posterior distribution --> it approximates a posterior distribution\n- for compound distribution --> for a compound distribution\n- a relatively simpler distribution --> a simpler distribution\n- near manifold --> near a/the manifold\n- we simply the minimum --> we denote (?) the minimum\n- satisfies the followings --> satisfies the following properties\n- number of connected component --> number of connected components\n- Experimental result --> Experimental results\n\nVI. Update after the rebuttal\n\nThe authors managed to address the majority of my comments. Overall, I still would like to see a more detailed/in-depth experimental setup, but I realise that this not directly possible within the timeframe allotted during the rebuttal period. I am thus raising my score.", "title": "Official Blind Review #1", "rating": "6: Weak Accept", "confidence": 4}, "B1gZIRbhsr": {"type": "rebuttal", "replyto": "BkxjO615FH", "comment": "We highly appreciate your detailed feedback and all your suggestions.\n\n**Issues pointed out in the summary**\nWe see that the issues mentioned in this section are truly valuable comments as they inspire lots of possible future works.\n - For the issue about the clarity, we followed the suggestion items appears in \u201cIII. Clarity\u201d\n - While Gaussian distributions are very common choices for latent vector distribution, we agree that the theorem can be generalized to a more broad family of distributions. We consider this generalization as the main theme of our future work.\n\n**Clarity**\nThank you for all of the thoughtful suggestions to improve the clarity of the work.\nWe checked the items one by one and applied the following changes for each item.\n - We first changed the title to \"On the Need For Topology-Aware Generative Models for Manifold-based Defenses\".\n - We clarified the manifold assumption (in p. 2) as suggested in the comment.\n - We exchanged all p and p_M as p_M is a more proper notation for density defined only on M.\n - \"\\cupdot\" operator is now used to denote a disjoint union of manifolds.\n - The statement containing the term 'ambiguities' was removed as it is misleading and redundant.\n - The requirement (R0) was moved to the appendix.\n - \"Change of variable formula\" was moved to the appendix once, but now in section 5.1 to describe how training loss is estimated.\n - Both \"INC optimization formulae\" (eq.3 & eq.4 in the previous version) are moved to the appendix.\n - In the first paragraph of section 4, now we clarify that we specifically discuss the number of connected components.\n - The term \u201clevel set\u201d is replaced by \u201csuperlevel set\u201d.\n - The preimage notation $p_{-1}$ was a typo, so corrected to $p^{-1}.\n - We introduced the notation for the Euclidean ball, before the notation is used.\n - Additional sentences were added to describe each radius.\n - Figure 1 was moved to the position near the Definition 1.\n - We agree that the correctness of Theorem 2 is clear from the proof. We now express the goal of the 1st experiment as \u201cempirical support for the applicability of Theorem 2\u201d\n - We extended the figure 3 to show the superlevel set components of the latent vector distribution.\n\n**Experimental setup**\nWe moved the additional experiments from the appendix to the main paper, as a visual comparison of decision boundaries can be illustrative to show the effect of our training method.\n\nWe prioritized the experiment on high dimensional data (e.g. MNIST), to show the applicability of our method in a more practical domain. We spent the majority of the revision period conducting experiments for the MNIST dataset. However, we are unable to obtain convincing results in the time frame provided.\n\nWe used our own code base to implement the realNVP generative model for MNIST dataset for the following reasons.\nWe wanted to re-use the code for INC projection without dealing with technical difficulties stemming from using other implementations.\nThere is no realNVP implementation (for MNIST) that standardizes data for preprocessing. This standardization is useful for us in choosing the centers of Gaussian distributions (when constructing the mixture of Gaussian for latent vector distribution) for class-aware training, as the dataset is scaled adaptively by its own standard deviation.\nHowever, after all the experiments, it turned out that the generative model we trained is not good enough to be used (in terms of the quality of images that it generates) for INC defense.\n\nTraining a generative model for high dimensional data is a challenging topic by itself, and we lack experience in this field. We will place top priority on implementing our idea for higher dimensional data, to support the wide applicability of our work.\n\nDue to the major time loss made in the MNIST experiment, we are not able to make all the other useful suggestions on experiments. However, for the question \u201cDo all models end up being robust if their number of connected components is sufficiently large?\u201d, we already knew that the answer is \u201cno\u201d in general. Training a generative model is influenced by choices of other hyperparameters, and we added one section describing the case that \u201cthe alignment of Gaussian matters\u201d. We also provided a hypothetical explanation (of the reason) by interpreting the reversible generative model as a dynamical system moving the latent vector distribution to the target distribution.\n\n**Minor issues**\nWe appreciate your kindness in telling us about those typos and style issues. Now, all issues mentioned are corrected.\n", "title": "Thank you for your valuable feedback!"}, "HJeA-Cb3iH": {"type": "rebuttal", "replyto": "Skg5fxnRYr", "comment": "We appreciate your review and all the suggestions.\n\n**Notational Changes**\nIn case you read the revised version, we made the following notational changes for the clarity of the paper.\n - We exchanged all p and p_M, as p_M is a more proper notation for density defined only on M.\n - \"\\cupdot\" operator is now used to denote a disjoint union of manifolds.\n - The term \u201clevel set\u201d is corrected to a more proper term \u201csuperlevel set\u201d.\n - The preimage notation $p_{-1}$ in previous version was a typo, so we corrected it to $p^{-1}.\n\n**Major changes**\n - We mostly re-structured the paper, so that we can move details about training class-conditional generative model and an additional experiments.\n - Appendix D.6 was added to discuss the limitation of topological information, suggesting that more detailed information about data-generating manifold may be exploited to train a better model.\n\n**Changes reflecting the comments**\n - We re-structured the paper based on your feedback. Specifically, we have moved details regarding training of the class-conditional generative models to the main text. Your feedback also suggested we discuss in detail how one could implement INC for class-conditional generative models. However, we decided to leave this discussion in the appendix to create space for experiments that required to be moved from the appendix to the body of the paper.\n\nYour feedback suggested we expand our experiments are to include results from high dimensional models such as MNIST. We spent the majority of the revision period conducting experiments for the same. However, we are unable to obtain convincing results in the time frame provided.\n\nWe used our own code base to implement the realNVP generative model for MNIST dataset for the following reasons.\nWe wanted to re-use the code for INC projection without dealing with technical difficulties stemming from using other implementations.\nThere is no realNVP implementation (for MNIST) that standardizes data for preprocessing. This standardization is useful for us in choosing the centers of Gaussian distributions (when constructing the mixture of Gaussian for latent vector distribution) for class-aware training, as the dataset is scaled adaptively by its own standard deviation.\nHowever, after all the experiments, it turned out that the generative model we trained is not good enough to be used (in terms of the quality of images that it generates) for INC defense.\n\nTraining a generative model for high dimensional data is a challenging topic by itself, and we lack experience in this field. We will place top priority on implementing our idea for higher dimensional data, to support the wide applicability of our work.\n", "title": "Thank you for your valuable feedback! "}, "BkxWR5ZioB": {"type": "rebuttal", "replyto": "HJe4ZU5t9r", "comment": "Thank you for your time and effort spent on the feedback.\nAlso, thank you for mentioning two related work regarding defense strategies based on denoising adversarial effects. We will add a discussion to these papers in our related work section.\n\nWe want to reiterate that the main theme of our work is \"The need of topology-awareness of a generative model when a generative model is exploited as a part of defense\" rather than \"The effectiveness of denoising as a defense mechanism\". Both [A] and [B] don't seem to have applications of a generative model, but we enjoyed reading both [A] and [B].\n\nFor the question \"Why denoising is not enough to pull the data back to the data manifold?\", we believe that denoising should be an effective way to implement the projection to manifold. Assuming that denoising is done with a proper choice of parameters, it ideally removes the noise and pulls the data back to the data generating manifold. However, before the work of [C], there have been trials (e.g. [D], [E], [F]) and errors (e.g. [G], [H], [C]), regarding denoising images in pixel space, that cast doubt on the research question of \"Effectiveness of denoising as a defense mechanism\".\n\nFocusing on the topic of \"Effectiveness of denoising as a defense mechanism\", there are more themes to discuss. Before further discussions on both of [A] and [B], we summarize a related work [C]. In [C], an intensive case study was performed to test their attack that circumvents obfuscated gradients that are the basis of most defense mechanisms. Especially, they introduced Backward Pass Differentiable Approximation (BPDA) to circumvent the part, of the defense mechanism, that obfuscates gradients by replacing the part by differentiable approximation for the backward pass of the algorithm. While Defense-GAN is also supposed to be vulnerable against [C], as it must also obfuscate gradients, [C] reported a failure of attacking Defense-GAN. This motivated us to focus on approaches based on generative models than any other approaches including denoising.\n\nThe work of [A] is an interesting approach to defend against a universal adversarial perturbation, even though it does not show its performance against an adversary who attacks each data point differently. However, assuming a white-box adversary, this can also be considered as an input transformation, so it is very likely to suffer performance drop via differentiable approximation of denoising mechanism.\n\nThe work of [B] is very impressive and attacking it would be an interesting challenge. However, we are a bit reluctant to relate this to the manifold assumption yet, due to the lack of knowledge about how the image of data manifold would look like in the intermediary feature space. Since they used adversarial training for both the baseline models and their feature denoising models, the approach of [C] will not be a direct threat to their model as the author of [C] admitted that adversarial training does not seem to cause obfuscated gradients. However, the benefit by introducing feature denoising blocks may disappear after the method of [C] is applied.\n\nReference:\n[A] Defensive Denoising Methods Against Adversarial Attack\n[B] Feature Denoising for Improving Adversarial Robustness\n[C] Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\n[D] Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks\n[E] MagNet: a Two-Pronged Defense Against Adversarial Examples\n[F] Countering Adversarial Images Using Input Transformations\n[G] Bypassing Feature Squeezing by Increasing Adversary Strength\n[H] MagNet and \"Efficient Defenses Against Adversarial Attacks\" are Not Robust to Adversarial Examples\n", "title": "Thank you for your valuable feedback!"}, "HJe4ZU5t9r": {"type": "review", "replyto": "r1lF_CEYwS", "review": "The paper tries to answer the following question:\nIn adversarial defense training do manifold based defenses need to know the structure of the underlying data manifold?\nThe question is quite rhetoric (the answer is most probably yes), nevertheless, the paper provides a theoretical and empirical answer.\n\nThe paper reads well and it is interesting to read. Nevertheless, I have a very basic question regarding the usefulness of the methods that the paper studies and the topic of adversarial defenses. I have worked on the topic for some years and in the beginning, I found it quite interesting, until I realized that, at least for images, audio, 3d meshes, all adversarial attacks can be very easily addressed with simple denoising mechanisms (for images even a non-local means filter or even a Gaussian filter eliminated all the adversarial attacks I have tried). There are some recent papers that demonstrate this [A] or recently feature denoising [B]. Why denoising is not enough to pull the data back to the data manifold (e.g., general low-rank data denoising or general denoising suitable for the data under investigation)?  \n\nI really want a discussion about that before I make a final decision.\n\n[A] Defensive denoising methods against adversarial attack\n[B] Feature Denoising for Improving Adversarial Robustness", "title": "Official Blind Review #3", "rating": "3: Weak Reject", "confidence": 2}}}