{"paper": {"title": "Mode Regularized Generative Adversarial Networks", "authors": ["Tong Che", "Yanran Li", "Athul Jacob", "Yoshua Bengio", "Wenjie Li"], "authorids": ["tong.che@umontreal.ca", "csyli@comp.polyu.edu.hk", "ap.jacob@umontreal.ca", "yoshua.bengio@umontreal.ca", "cswjli@comp.polyu.edu.hk"], "summary": "", "abstract": "Although Generative Adversarial Networks achieve state-of-the-art results on a\nvariety of generative tasks, they are regarded as highly unstable and prone to miss\nmodes. We argue that these bad behaviors of GANs are due to the very particular\nfunctional shape of the trained discriminators in high dimensional spaces, which\ncan easily make training stuck or push probability mass in the wrong direction,\ntowards that of higher concentration than that of the data generating distribution.\nWe introduce several ways of regularizing the objective, which can dramatically\nstabilize the training of GAN models. We also show that our regularizers can help\nthe fair distribution of probability mass across the modes of the data generating\ndistribution during the early phases of training, thus providing a unified solution\nto the missing modes problem.", "keywords": ["Deep learning", "Unsupervised Learning"]}, "meta": {"decision": "Accept (Poster)", "comment": "This paper presents some intuitions about why GAN training is difficult, and proposes a somewhat remedy that seems to help. \n \n Pros\n  - a detailed explanation of the motivation\n  - side experiments to demonstrate the properties of the new method\n \n Cons\n  - There are already several closely-related approaches, namely VAEGAN, with similar motivations and procedures. This paper argues that their method is conceptually distinct from the VAEGAN, but I and other reviewers found the arguments underdeveloped unconvincing.\n  - Most of the evaluations are qualitative.\n \n The search space of reasonable modifications to the GAN objective is so large that either a more principled or systematic (as in, do more comparison experiments) exploration of the space is necessary. \n\nGiven the importance of the topic, the PCs still believe this paper should be accepted, but we encourage the authors to further revise their paper to address the remaining outstanding issues."}, "review": {"BJa_DNdIl": {"type": "rebuttal", "replyto": "HJKkY35le", "comment": "Dear reviewers and readers,\n\nThanks for your constructive and thoughtful reviews and comments. We've updated our submission paper and added experiments in the appendix sections. Please kindly refer to our newest version. \n\nThanks again.", "title": "Update the submission paper"}, "SJfnlnQNx": {"type": "rebuttal", "replyto": "rJtxviX4e", "comment": "From what I understand, you are using plain autoencoder meaning that p(z|x) is just a delta function (degenerate gaussian). To be honest, I don't see how this gives a regularization property which is missing (for some unknown reason) for a KL-penalized gaussian p(z|x). Probabilistic formalism aside, the KL-penalty encourages certain smoothness of the latent space and I personally feel that this is not an undesirable effect.\n\nI would like to stress that I'm not claiming that AE and VAE is the same thing. Instead, I'm saying that changing VAE to AE in the existing work without theoretically and empirically justifying this single modification is not sufficient to call the resulting model a superior invention. I would also want to clarify that I'm not stating that the aforementioned modification is useless but rather I'm trying to encourage the authors to fill the missing gap and properly prove the significance of the contribution.\n\nIf the evaluation reveals that the both approaches perform similarly, I would suggest reframing the paper as an analysis of the family of related methods.", "title": "Comment"}, "rJtxviX4e": {"type": "rebuttal", "replyto": "HkgiRw7Ve", "comment": "Thanks again for comments\n\nHere VAE targets means the sum of the prior loss and auto-encoder loss, which is the optimization target for VAEs as in the original VAE paper (Kingma and Welling, 2013). The reason why this VAE target cannot be used as regularizer is that it imposes probabilistic assumptions  to posterior distribution p(z|x) as pointed above. However, in our model, if G(z), z~p_prior is a good generative model, one can always expect that there can be an encoder E, such that x and G(E(x)) is close. Mathematically our model does not require p(z|x) has a Gaussian shape. This is why our additional loss can be used as a regularizer. \n\nAs I said, the autoencoder used in our model is a plain auto-encoder. It is different from a variational autoencoder. We do not need any variational approximations to make the model work. ", "title": "reply"}, "HkgiRw7Ve": {"type": "rebuttal", "replyto": "rygJ8vX4g", "comment": "Thanks for your answer! The following statement is not clear to me: \"What\u2019s more, the VAE targets in the VAEGAN are not used as regularizers. By regularizers, we mean that the term will control model variance but probably introduce biases\". What do you mean by \"VAE targets\"? In which sense could one you use those targets as regularizers?", "title": "Clarification"}, "rygJ8vX4g": {"type": "rebuttal", "replyto": "r1-E8UX4x", "comment": "Thanks for your thoughtful comments!\n\nIn fact, this model is different from VAEGAN, just like VAEs are different from plain autoencoders. VAE used in VAEGAN has to satisfy some probabilistic assumptions. For example, VAEs need also to train a network to approximate the variance of the posterior distribution q(z|x). Also, the approximate posterior distribution q(z|x) has to be assumed as a factorized Gaussian distribution in their case. In an arbitrary GAN architecture, where these assumptions are not assumed, you cannot combine VAEs to that setting. What\u2019s more, the VAE targets in the VAEGAN are not used as regularizers. By regularizers, we mean that the term will control model variance but probably introduce biases. \n\nSo we believe that these two models are different. But we also admit that there is important similarity in terms of target for optimization. We plan to add more analysis of these differences and similarities to our next version of paper. \n", "title": "Differences."}, "rkTrkvXNe": {"type": "rebuttal", "replyto": "HyEXhrQVx", "comment": "Thanks for your immediate and always constructive comments!\n\nWe made this claim based on the samples they\u2019ve provided in their papers. Unfortunately they didn\u2019t provide many samples. So we agree that this claim alone might be questionable in terms of number of evidences. In hope to link the differences between these two models and the differences in the performance, we will carry out more quantitative study and update the paper as soon as possible.\n\nWe agree that we should compare our model and theirs in terms of missing modes. We\u2019re trying to run their official code and integrate our evaluation in. ", "title": "Reply for constructive comment."}, "r1-E8UX4x": {"type": "rebuttal", "replyto": "BJMXcOs7l", "comment": "Please read around equation 9 of VAEGAN (https://arxiv.org/pdf/1512.09300v2.pdf). They indeed weight the loss from VAE and the loss from GAN as well. VAEGANs can also be combined with different GAN variants.\n\nYour argument that VAEGAN is a VAE with GAN loss, while MRGAN is a GAN with an autoencoder is nothing more than nomenclature. Both VAEGAN and proposed model are training decoders. It's wrong to say that in your case GANs are the generative model, while in VAEGAN's case, VAEs are the generative model. In both case, the neural network which represents p(x | z) (i.e. the decoder) is the generative model.\n\nMoreover, if the difference between VAEGAN and proposed model is just conceptual, perhaps the paper should be written along the lines of explaining and analyzing VAEGAN, rather than claiming to have discovered a new model/architecture.\n\n", "title": "Striking similarity of proposed model to VAEGAN (Larsen et al.)"}, "HyEXhrQVx": {"type": "rebuttal", "replyto": "r15NBE7Eg", "comment": "Thanks for your answers! \n\nIn my opinion, the most crucial part of the comparison (VAEGAN vs the proposed method) is not visual inspection of samples but rather extensive missing mode analysis as it is the main selling point the present paper.\n\nI guess, what I'm trying to say in the second comment is that I don't see why VAEGAN would produce blurry samples (something that the authors claim in the sentence: \"The samples from VAEGAN and DCGAN are unsatisfactory due to insufficient sharpness\"). The architectural difference between VAEGAN and the proposed method seems minor (both approaches have GAN as a part of the pipeline) and I'm not convinced that this difference makes the proposed method superior to the work of Larsen et al. (especially given the fact that the authors did not conduct any direct comparison at all).\n\nTo summarize my concerns: I would suggest the authors conduct a direct empirical comparison between their work and Larsen et al to prove that the introduced differences are crucial for obtaining superior performance. In my opinion, in its current form the paper downplays the existing work without supporting the claims (about VAEGAN) with experimental results.", "title": "More comments"}, "r15NBE7Eg": {"type": "rebuttal", "replyto": "Bybg2pf4x", "comment": "Thanks for the comment. We didn\u2019t find the repository you\u2019ve provided (we\u2019ve did a Google search \u2018VAEGAN\u2019\u2019 and we missed the code link in the original paper). Thank you. And the official code page didn\u2019t provide more samples than they reported. So, we will run it as fast as possible and add more VAEGAN samples in our paper soon.\n\nWe\u2019re not sure what did you mean by \u201cMoreover, the authors explain lower quality of the VAEGAN samples by the fact that Larsen et al. use only hidden space of D (and no other pre-trained model) to obtain the reconstruction loss...\u201d We guessed that you\u2019re saying in theory our L2-reconstruction should lead to blurrer samples and it seems contradict our conclusion in the paper. It is well known that VAE by L2 loss tend to generate blurry images, and using hidden space of D tend to generate sharper images. But for our case, L2 loss is enough because the generative model is GAN, the weight on the L2 loss is very small, so we can generate sharp images even without using any advanced distances. ", "title": "Replies for comments"}, "Bybg2pf4x": {"type": "rebuttal", "replyto": "r1TuK3GVx", "comment": "Thanks for the answers!\n\n1. There is an official open-sourced implementation of VAEGAN (http://github.com/andersbll/autoencoding_beyond_pixels) and the link is provided in the original paper. The authors could use either this one or the unofficial repo mentioned above to conduct the comparison. Given that VAEGAN has a striking similarity to the proposed method, leaving it out of the comparison seems suspicious.\n\n2. The authors admit they did not run the code for VAEGAN. In this case, I don't think, few samples from the original paper are enough to perform a reasonable evaluation of the prior work (e.g. \"The samples from VAEGAN and DCGAN are unsatisfactory due to insufficient sharpness\"). Moreover, the authors explain lower quality of the VAEGAN samples by the fact that Larsen et al. use only hidden space of D (and no other pre-trained model) to obtain the reconstruction loss, but at the same time, in the present paper, only L2-reconstruction in the pixel space is performed (Figure 8). Several existing papers (including Dosovitskiy and Brox [1]) show that L2 leads to blurry images.", "title": "Comments"}, "r1TuK3GVx": {"type": "rebuttal", "replyto": "rkeSiZRQx", "comment": "Thanks for your comment.\n\n1. As there is no official open-sourced implementation of Larsen et al., and the unofficial implementation (https://github.com/anitan0925/vaegan) seems produce poorer results in terms of sample quality, we can not build up fair comparison on ours and theirs. But it's a good idea to try your suggestion if reliable implementation once available.\n\n2. We sincerely apologize for our carelessness. Since there is no satisfying implementation of VAEGAN, the samples were directly extracted from their paper via a screenshot tool, and there might be some quality loss due to zooming. After your suggestions, we have found out the way to directly extract the image from their compiled PDF file. Now we have updated our paper. Also, we notified our reader to reference to the original papers if they have questions about sample quality. \n\nThe perceptual similarity measure is a good choice for models to generate samples that are more natural looking. However, we think it is still insufficient, which is consistent with the work of Dosivitskiy and Brox [1]. They additionally use a loss from image data space, and suggest a real image prior is important to generate sharper images. Similar ideas and extra model improvements are done in PPGN. For example, they use Activation Maximization to synthesize image-related priors and features into generated images to encourage the quality of images. Furthermore, their samplers are also contributing to the generation quality. \n\nThanks again for your valuable comments. \n\n[1] Generating Images with Perceptual Similarity Metrics based on Deep Networks. https://arxiv.org/pdf/1602.02644.pdf", "title": "perceptual similarity measure alone is not sufficient"}, "rkeSiZRQx": {"type": "rebuttal", "replyto": "BJMXcOs7l", "comment": "1. Did you conduct a comparison between your work and Larsen et al. in terms of missing modes? Is there any difference except for conceptual?\n\n2. On page 8, you mention that samples from VAEGAN are insufficiently sharp. Larsen et al. are using perceptual similarity measure known to produce high-quality images (e.g. http://www.evolvingai.org/ppgn). Also, the samples from the original VAEGAN paper look significantly sharper than the ones you report in your paper. How would you explain this difference?", "title": "More questions"}, "BJMXcOs7l": {"type": "rebuttal", "replyto": "H1oV0u_Xx", "comment": "Thanks for your comment.\n\nThere is indeed a similarity on the objective we are optimizing comparing with theirs. \nHowever, there are several important differences:\n\n1. The main difference is due to the motivations which are different: They are trying to merge the VAE and GAN frameworks, so for example the noise in h-space is regulated by the VAE KL(q(z|x)||p(z)) whereas we don't have this penalty, we are just trying to visit the neighborhood of missed modes so as to rebalance the set of examples on which the generator gets feedback, to account for the fact that the examples from missing modes will come rarely but count a lot in the mismatch to the data distribution.\n\n2. From a theoretical point of view, VAE objectives (including VAEGAN) assumes that the conditional distribution q(z|x) is factorized distribution. This assumption usually does not hold in the context of GANs. So it may happen that the VAE objective and GAN objective they are trying to optimize conflict with each other. \n\n3. The optimization target we are using is conceptually different. In VAEGAN, the generative model is in fact the VAE, the GAN discriminator is only employed to provide more accurate measure than pixel-wise similarity. So the VAE objective is not reweighted in their work. However, in our model, the GAN model is the only generative model. The encoder is only employed to penalize missing modes. The encoder losses we use are often multiplied by a very small coefficient. This makes our technique possible to combine with other GAN training techniques, such as DCGAN, improved GAN, energy-based GAN and Unrolled GAN. \n\nThanks again for your careful reading.", "title": "Differences with VAEGAN."}, "H1oV0u_Xx": {"type": "review", "replyto": "HJKkY35le", "review": "What do the authors think is the main difference between this work and Larsen et al? Specifically, both the geometric regularizer (autoencoding cost in Larsen et al) and the mode regularizer (Discriminating based on samples from p(z) and q(z|x) in Larsen et al) have been proposed in the context of VAEs in Larsen et al and I feel the way they are used is essentially the same as this paper.Summary:\n\nThis paper proposes several regularization objective such as \"geometric regularizer\" and \"mode regularizer\" to stabilize the training of GAN models. Specifically, these regularizes are proposed to alleviate the mode-missing behaviors of GANs.\n\nReview:\n\nI think this is an interesting paper that discusses the mode-missing behavior of GANs and proposes new evaluation metric to evaluate this behavior. However, the core ideas of this paper are not very innovative to me. Specifically, there has been a lot of papers that combine GAN with an autoencoder and the settings of this paper is very similar to the other papers such as Larsen et al. As I pointed out in my pre-review comments, in the Larsen et al. both the geometric regularizer and model regularizer has been proposed in the context of VAEs and the way they are used is essentially the same as this paper. I understand the argument of the authors that the VAEGAN is a VAE that is regularized by GAN and in this paper the main generative model is a GAN that is regularized by an autoencoder, but at the end of the day, both the models are combining the autoencoder and GAN in a pretty much same way, and to me the resulting model is not very different. I also understand the other argument of the authors that Larsen et al is using VAE while this paper is using an autoencoder, but I am still not convinced how this paper outperforms the VAEGAN by just removing the KL term of the VAE. I do like that this paper looks at the autoencoder objective as a way to alleviate the missing mode problem of GANs, but I think that alone does not have enough originality to carry the paper.\n\nAs pointed out in the public comments by other people, I also suggest that the authors do an extensive comparison of this work and Larsen et al. in terms of missing mode, sample quality and quantitative performances such as inception score.", "title": "pre-review question", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "SkMk-sH4g": {"type": "review", "replyto": "HJKkY35le", "review": "What do the authors think is the main difference between this work and Larsen et al? Specifically, both the geometric regularizer (autoencoding cost in Larsen et al) and the mode regularizer (Discriminating based on samples from p(z) and q(z|x) in Larsen et al) have been proposed in the context of VAEs in Larsen et al and I feel the way they are used is essentially the same as this paper.Summary:\n\nThis paper proposes several regularization objective such as \"geometric regularizer\" and \"mode regularizer\" to stabilize the training of GAN models. Specifically, these regularizes are proposed to alleviate the mode-missing behaviors of GANs.\n\nReview:\n\nI think this is an interesting paper that discusses the mode-missing behavior of GANs and proposes new evaluation metric to evaluate this behavior. However, the core ideas of this paper are not very innovative to me. Specifically, there has been a lot of papers that combine GAN with an autoencoder and the settings of this paper is very similar to the other papers such as Larsen et al. As I pointed out in my pre-review comments, in the Larsen et al. both the geometric regularizer and model regularizer has been proposed in the context of VAEs and the way they are used is essentially the same as this paper. I understand the argument of the authors that the VAEGAN is a VAE that is regularized by GAN and in this paper the main generative model is a GAN that is regularized by an autoencoder, but at the end of the day, both the models are combining the autoencoder and GAN in a pretty much same way, and to me the resulting model is not very different. I also understand the other argument of the authors that Larsen et al is using VAE while this paper is using an autoencoder, but I am still not convinced how this paper outperforms the VAEGAN by just removing the KL term of the VAE. I do like that this paper looks at the autoencoder objective as a way to alleviate the missing mode problem of GANs, but I think that alone does not have enough originality to carry the paper.\n\nAs pointed out in the public comments by other people, I also suggest that the authors do an extensive comparison of this work and Larsen et al. in terms of missing mode, sample quality and quantitative performances such as inception score.", "title": "pre-review question", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "HJ_OO4SXg": {"type": "rebuttal", "replyto": "Sy4lRrWXx", "comment": "Thanks for your comment. We've added more details in our latest version, especially, the architecture details are added to Appendix. For the second question, the maximization target in Eqn.(1) is chosen to fight the gradient vanishing problem. Hence, we're maximizing log(D(G(z)) instead of minimizing log(1-D(G(z))). Please kindly refer to the original DCGAN paper (Radford et al., 2015) for more detailed discussion on this problem. ", "title": "Details Added"}, "B1cMSErQe": {"type": "rebuttal", "replyto": "H1M6pdCMl", "comment": "Thanks for your comment! In our latest version, we have added in the Appendix the pseudo code for MDGAN that you've suggested. We hope it's clearer now for better understanding of our proposed techniques. Please check it in the Appendix. Thanks a lot.", "title": "Pseudo Code added in Appendix"}, "S1SHE4Sme": {"type": "rebuttal", "replyto": "SJyXUQ8bx", "comment": "Thanks for your comment! In our latest version, we have added an synthetic experiment similar as that you've suggested, which also qualitatively demonstrated how the proposed techniques alleviate the missing mode problem. Please check it in the Appendix. Thanks a lot.", "title": "Experiments added in Appendix"}, "ryd4mVBXe": {"type": "rebuttal", "replyto": "Hy3dyvVWe", "comment": "Thanks for your proof-reading. We're sorry for this careless mistake and have fixed it in the latest version. Thanks again.", "title": "fixed."}, "Sy4lRrWXx": {"type": "rebuttal", "replyto": "HJKkY35le", "comment": "1. Could there be more details on each experiment (could be in Appendix), so that the results can be reproduced? In particular, it is not mentioned what exactly the \"encoder\" is.\n\n2. I think the generator should minimize log(1-D(G(z))) instead of log(D(G(z))). Or, if Eqn.(1) is meant to be the maximization target, then you may need to redefine the distance measure d().", "title": "More experiments details"}, "H1M6pdCMl": {"type": "review", "replyto": "HJKkY35le", "review": "How is the model trained? Section 3.3 refers to a \"manifold step\" and a \"diffusion step\" but only describes them informally. Do the steps consist of one step of gradient descent, or perhaps something else?This paper does a good job of clearly articulating a problem in contemporary training of GANs, coming up with an intuitive solution via regularizers in addition to optimizing only the discriminator score, and conducting clever experiments to show that the regularizers have the intended effect. \n\nThere are recent related and improved GAN variants (ALI, VAEGAN, potentially others), which are included in qualitative comparisons, but not quantitative. It would be interesting to see whether these other types of modified GANs already make some progress in addressing the missing modes problem. If code is available for those methods, the paper could be strengthened a lot by running the mode-missing benchmarks on them (even if it turns out that a \"competing\" method can get a better result in some cases).\n\nThe experiments on digits and faces are good for validating the proposed regularizers. However, if the authors can show better results on CIFAR-10, ImageNet, MS-COCO or some other more diverse and challenging dataset, I would be more convinced of the value of the proposed method. \n\n", "title": "Training pseudocode", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "Skkn6YbNx": {"type": "review", "replyto": "HJKkY35le", "review": "How is the model trained? Section 3.3 refers to a \"manifold step\" and a \"diffusion step\" but only describes them informally. Do the steps consist of one step of gradient descent, or perhaps something else?This paper does a good job of clearly articulating a problem in contemporary training of GANs, coming up with an intuitive solution via regularizers in addition to optimizing only the discriminator score, and conducting clever experiments to show that the regularizers have the intended effect. \n\nThere are recent related and improved GAN variants (ALI, VAEGAN, potentially others), which are included in qualitative comparisons, but not quantitative. It would be interesting to see whether these other types of modified GANs already make some progress in addressing the missing modes problem. If code is available for those methods, the paper could be strengthened a lot by running the mode-missing benchmarks on them (even if it turns out that a \"competing\" method can get a better result in some cases).\n\nThe experiments on digits and faces are good for validating the proposed regularizers. However, if the authors can show better results on CIFAR-10, ImageNet, MS-COCO or some other more diverse and challenging dataset, I would be more convinced of the value of the proposed method. \n\n", "title": "Training pseudocode", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "SJyXUQ8bx": {"type": "rebuttal", "replyto": "HJKkY35le", "comment": "Nice paper. It would be interesting to conduct some synthetic experiments to qualitatively demonstrate how the proposed techniques alleviate the missing mode problem. For example, Fig 3, 4 in \"Generative Adversarial Parallelization\" look nice to me.", "title": "Synthetic Experiments on missing mode"}, "Hy3dyvVWe": {"type": "rebuttal", "replyto": "HJKkY35le", "comment": "Very interesting work.\n\nIn equation (3), p(y) refers to label distribution of the training data. However, in the original paper (Salimans et al. 2016), p(y) means label distribution of the generated images, which contradicts with p*(y) in equation (4). \n", "title": "Is this a typo?"}}}