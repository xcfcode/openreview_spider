{"paper": {"title": "Overparameterisation and worst-case generalisation: friend or foe?", "authors": ["Aditya Krishna Menon", "Ankit Singh Rawat", "Sanjiv Kumar"], "authorids": ["~Aditya_Krishna_Menon1", "~Ankit_Singh_Rawat1", "~Sanjiv_Kumar1"], "summary": "Overparameterised models' worst-subgroup performance can be improved via post-hoc processing.", "abstract": "Overparameterised neural networks have demonstrated the remarkable ability to perfectly fit training samples, while still generalising to unseen test samples. However, several recent works have revealed that such models' good average performance does not always translate to good worst-case performance: in particular, they may perform poorly on subgroups that are under-represented in the training set. In this paper, we show that in certain settings, overparameterised models' performance on under-represented subgroups may be improved via post-hoc processing. Specifically, such models' bias can be restricted to their classification layers, and manifest as structured prediction shifts for rare subgroups. We detail two post-hoc correction techniques to mitigate this bias, which operate purely on the outputs of standard model training. We empirically verify that with such post-hoc correction, overparameterisation can improve average and worst-case performance.", "keywords": ["overparameterisation", "worst-case generalisation"]}, "meta": {"decision": "Accept (Poster)", "comment": "This paper studies how to improve the worst-case subgroup error in overparameterized models using two simple post-hoc processing techniques. All reviewers were positive about the paper, though R5 questioned the novelty of the paper which built heavily on a few previous papers (in particular, it builds heavily on Sagawa et al. 2020a,b). The AC is satisfied with the authors`' response clarifying the novelty. Given that this topic is quite timely and of interest to the ICLR community, and that this paper presented a clean investigation on it, the AC recommends acceptance."}, "review": {"PUGFzGK_Yvu": {"type": "review", "replyto": "jphnJNOwe36", "review": "This paper studies how to improve the worst-case subgroup error in overparameterized models using two simple post-hoc processing techniques: (1) learning a new linear classification layer of a network, or (2) learning new per-group threshold on the logits. The efficacy of these techniques is evaluated on three synthetic datasets.\n\nPros:\n- The paper studies a timely topic--generalization in overparameterized models-- with some applications to fairness.\n- The algorithms presented are very simple and avoid the overhead of more complicated algorithms like DRO or subsampling strategies.\n- In the experiments presented, both the thresholding method and the \"learn a new classification layer\" method significantly improve worst-case group error over ERM and are competitive with DRO.\n- The paper is well-written and pleasant to read.\n\nCons:\n- The experimental evaluation is somewhat limited, focusing on three synthetic datasets and two models (ResNet/Logistic Regression). It remains an open question how well the presented technique work more generally both on different model families and on \"real\" distributions.\n\nMinor:\n- There appears to be a discrepancy between the text and the main results table, Table 1. The text says \"For example, on celebA, THR reduces the worst-subgroup error from 56.94% to 31.11%\", but the table shows THR gets a worst-subgroup error of 12.10. What's going on there?\n\n==============\n\nUpdate after rebuttal:\nThank you for clarifying the numbers in Table 1 should match the main text. I enjoyed this paper, and I'm keeping my score unchanged.", "title": "Nice study of simple methods for improving worst-case subgroup error in overparameterized models", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "WUBxVRNnR2e": {"type": "rebuttal", "replyto": "XFTo9ZrMlR0", "comment": "Thanks for the detailed feedback and encouraging comments!\n\n*# That being said, it feels the study/paper builds on a few earlier studies heavily, and I am not fully convinced that there is enough new findings in the present paper to warrant publication in ICLR.*\n\nWe reiterate that the novelty of the present work is in showing that :\n\n(1) overparameterised models\u2019 bias on rare subgroups can be in the form of a structured shift in the classification scores, thus deepening the understanding of their behaviour;\n\n(2) this bias can be mitigated via post-hoc modification, thus illustrating that standard training of these models may already capture useful information on rare subgroups.\n\nMore broadly, one of our main messages is that the overparameterised setting is not too detached from standard learning with subgroup fairness considerations. As the reviewer notes, this is a timely problem, and so we believe that progress in this regard is of interest. We hope that our study can help guide further explorations in this new field.\n\n*# The findings presented in Figure 4 is interesting (mainly the fact that the overparametrization seem to be improving the worst-group performance with threshold tuning). It would be interesting to see more investigation/discussion of what could be the underlying reason.*\n\nThis is one of our central points: the classification layer is biased against rare subgroups. However, increasing model complexity also allows for better modelling (i.e., learned representations) of such samples. This is why, with suitable tuning, one can achieve better performance than in underparameterised settings.\n\nNote also that Sagawa et al. \u201820b already demonstrated that another technique -- subsampling -- can similarly show improvements on worst subgroup performance as model complexity increases. Compared to this, we show that the learned representations from standard training may themselves be sufficient to improve worst subgroup performance.\n\nWe have fixed all typos, and updated Figure 2 to have clearer separation from the legend, and use colourblind-friendly colours.", "title": "Response to R3"}, "roDanqj9l3S": {"type": "rebuttal", "replyto": "PUGFzGK_Yvu", "comment": "Thanks for the detailed feedback and encouraging comments!\n\n*# The experimental evaluation is somewhat limited, focusing on three synthetic datasets and two models (ResNet/Logistic Regression). It remains an open question how well the presented technique work more generally both on different model families and on \"real\" distributions.*\n\nPlease note that these datasets were extensively used in prior work. Per comments to R4, we have added results on more datasets and with more complex group specifications.\n\n*# There appears to be a discrepancy between the text and the main results table, Table 1. The text says \"For example, on celebA, THR reduces the worst-subgroup error from 56.94% to 31.11%\", but the table shows THR gets a worst-subgroup error of 12.10. What's going on there?*\n\nThanks for spotting this: this was a typo, which we have fixed.", "title": "Response to R2"}, "pKkzkE4e3DU": {"type": "rebuttal", "replyto": "wk3b5CrwFh", "comment": "Thanks for the detailed feedback and encouraging comments!\n\n*# The scope of the work seems largely limited to the set-up from Sagawa a, b. Given that all three datasets are simplified/synthetic (only one attribute, max. 4 subgroups), it would have been great to see how this paper's analysis applied to more complex settings.*\n\nTo show the applicability of our findings in more complex settings, we have added results on:\n1) CelebA with a larger (64) number of subgroups in Appendix A.1 (see details below).\n2) a modified version of the MNIST dataset in Appendix A.3, comprising 10 labels and 20 total subgroups. This data is based on the setup of [Goel et al., 2020], and comprises a mixture of standard MNIST and a \u201ccorrupted\u201d version with zig-zag images.\n\nIn both settings, we find that one can improve on the worst-subgroup error of ERM using the learned representations.\n\n*# It is not immediately clear why we would not expect classifier retraining/threshold correction (which as the author notes, are standard techniques) to work for the overparameterized setting? ... Could the authors better explain why overparameterization reduces our expectations on the effectiveness of these post-hoc procedures?*\n\nAs noted in the \u201cScope and contributions\u201d section (pg 2), the overparameterised setting can defeat techniques that might otherwise work in classical settings, e.g., standard distributionally robust optimisation (c.f. Sagawa et al. \u201820a). Thus, while our proposed idea of decoupling the learned representation and classifier is intuitive in hindsight, its success is not a-priori guaranteed. \n\nIn particular, the efficacy of such a technique is unclear given prior work, which established that the predictions of standard training in overparameterised settings leads to systematically biased predictions. These studies do not establish whether or not this bias is solely a function of the classification layer, or in fact pervades the learned representation too.\n\n*# The requirement of knowing the groups a priori seems rather significant. While one of their main cited works (Sagawa a) seems to have touched on group attribute mis-specification, this was not explored here -- how does having imprecise knowledge of the groups effect performance when using threshold correction or classifier retraining?*\n\nWe have included in Appendix A.1 results with the setting of imperfectly specified groups, per Sagawa et al. \u201820a, Appendix B. Specifically, we consider A = Wearing Lipstick x Eyeglasses x Smiling x Double Chin x Oval Face, which yields 64 subgroups of Y x A. In this setting, that threshold adjustment based on the subgroup frequencies can similarly improve the worst-subgroup error: this setting yields 16.67% worst-subgroup error, which is a modest increase compared to the 12.10% when using the exact subgroups.\n\n*# I have trouble fully understanding Figure 2 without a sense of what \"insufficient\" or poor representations would look like in a tSNE visualization.*\n\nIn a \u201cpoor\u201d representation, samples from the same class may not be clustered together: in particular, rare subgroups from one class may be closer to dominant samples from another class. Of course, this visualisation by itself does not establish the sufficiency of learning with the representations -- it is meant to provide some intuition for why the post-hoc correction techniques of the subsequent section can work.\n\n*# Does the nature of the attribute (land vs water, or hair color) have any effect on the observed poor worst-group performance, or are the results are mainly due to the fact that some groups are rarer than others? For example, would the authors expect similar results if y=male,female and A=blond,dark for celebA?*\n\nWe thank the reviewer for this very interesting suggestion. We have included in Appendix A.2 results when swapping the role of Y and A on CelebA. We find that there is an improvement in the baseline performance: the worst-subgroup error goes from 56.94% to 13.67%. Nonetheless, threshold adjustment can further reduce the worst-subgroup error.\n\nIn general, we expect that the choice of target Y and spurious attribute A plays an important role in final performance. Indeed, if the target variable is spuriously correlated with many other features in the training set, this could hamper performance. Thus, the problem is not purely one of certain subgroups being rare in the training set.\n\n*# Did the authors visualize the embeddings of models trained with DRO, to see whether there is any improvement in the learned representations ability to distinguish subgroups?*\n\nWe have included in Appendix B a plot of the embeddings learned under DRO. We find the separation is visually similar to what is seen under standard ERM. Note however that the slightly improved classification performance under DRO indicates that in the full representation space, there is greater inherent separability of the subgroups.", "title": "Response to R4"}, "XFTo9ZrMlR0": {"type": "review", "replyto": "jphnJNOwe36", "review": "This paper is concerned with potential improvements to the worst-case\n(mainly minority class/group) generalizations in over-parametrized\nneural networks through post-hoc corrections. The authors demonstrate\nthe problem and the suggested corrections (that were used in previous\nliterature) on one artificial classification task as well as two\nimage classification tasks. The paper shows that post-hoc corrections\nmay improve the worst-subgroup scores similar to an earlier\nstate-of-the-art system that modifies the learning objective.\n\nThis topic is interesting. The paper is in general written well, and\ndemonstrates the problem convincingly. The post-hoc fix solution\nsuggested also seem to be performing reasonably well on the problems /\ndata sets used in the study.\n\nThat being said, it feels the study/paper builds on a few earlier\nstudies heavily, and I am not fully convinced that there is enough new\nfindings in the present paper to warrant publication in ICLR.\n\nI also have a few minor notes/suggestions:\n\n- The findings presented in Figure 4 is interesting (mainly the fact\n  that the overparametrization seem to be improving the worst-group\n  performance with threshold tuning). It would be interesting to see\n  more investigation/discussion of what could be the underlying\n  reason.\n\n- Page 2 (middle): \"also common the fairness literature\" ->   \"also common in the fairness literature\" \n- Figure 2 is not very readable. If increasing size/scale is not an\n  option due to limited space, taking legend out the figures may also\n  improve it. Colorblind friendly colors may also be a good idea.\n- There are case (normalization) issues in the references:\n  \"ml\", \"t-sne\" (not exhaustive, a through check is\n  recommended).\n", "title": "A demonstration of a few methods for post-hoc improvements for bias in overparametrized models. Interesting, but not sure if there is enough new information.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "wk3b5CrwFh": {"type": "review", "replyto": "jphnJNOwe36", "review": "Summary:\nThe paper builds upon prior work that shows that overparameterized networks learned by ERM can have poor worst-case performance over pre-defined groups. Specifically, the paper demonstrates that this result is not necessarily due to overparameterized learning poor representations for rare subgroups, but rather mis-calibration in the classification layer that can be addressed with two simple correct techniques: thresholding and re-training the classification layer. They show improvements over ERM in worst-case subgroup error.  \n\nStrengths:  \n1. The paper is very well-written and easy to follow.\n2. The paper provides a better understanding of worst-case generalization in overparamaterized models by isolating the issue to the classification layer, which can help machine learning practitioners better understanding how they can address the issue of poor worst-group performance. \n\n\nWeaknesses:  \n1. The scope of the work seems largely limited to the set-up from Sagawa a, b. Given that all three datasets are simplified/synthetic (only one attribute, max. 4 subgroups), it would have been great to see how this paper's analysis applied to more complex settings.   \n2. It is not immediately clear why we would not expect classifier retraining/threshold correction (which as the author notes, are standard techniques) to work for the overparameterized setting? The richness of learned representations is well known, so in some sense the findings are not too surprising, especially given the simple (e.g. binary label) settings that make post-hoc corrections less complex. Could the authors better explain why overparameterization reduces our expectations on the effectiveness of these post-hoc procedures? \n3. The requirement of knowing the groups a priori seems rather significant. While one of their main cited works (Sagawa a) seems to have touched on group attribute mis-specification, this was not explored here -- how does having imprecise knowledge of the groups effect performance when using threshold correction or classifier retraining? \n4. I have trouble fully understanding Figure 2 without a sense of what \"insufficient\" or poor representations would look like in a tSNE visualization.  \n\n\nRecommendation:  \nI recommend acceptance. While I remain concerned about the limited scope of the experiments, I believe the paper adds valuable insights to the overall important topic of robustness / worst-case generalization.  \n\nQuestions:\n1. Does the nature of the attribute (land vs water, or hair color) have any effect on the observed poor worst-group performance, or are the results are mainly due to the fact that some groups are rarer than others? For example, would the authors expect similar results if y=male,female and A=blond,dark for celebA?   \n2. Did the authors visualize the embeddings of models trained with DRO, to see whether there is any improvement in the learned representations ability to distinguish subgroups? ", "title": "Well-written paper, although a bit limited in overall contributions", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}}