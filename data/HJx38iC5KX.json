{"paper": {"title": "Domain Generalization via Invariant Representation under Domain-Class Dependency", "authors": ["Kei Akuzawa", "Yusuke Iwasawa", "Yutaka Matsuo"], "authorids": ["akuzawa-kei@weblab.t.u-tokyo.ac.jp", "iwasawa@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "summary": "Address the trade-off caused by the dependency of classes on domains in domain generalization", "abstract": "Learning domain-invariant representation is a dominant approach for domain generalization, where we need to build a classifier that is robust toward domain shifts induced by change of users, acoustic or lighting conditions, etc. However, prior domain-invariance-based methods overlooked the underlying dependency of classes (target variable) on source domains during optimization, which causes the trade-off between classification accuracy and domain-invariance, and often interferes with the domain generalization performance. This study first provides the notion of domain generalization under domain-class dependency and elaborates on the importance of considering the dependency by expanding the analysis of Xie et al. (2017). We then propose a method, invariant feature learning under optimal classifier constrains (IFLOC), which explicitly considers the dependency and maintains accuracy while improving domain-invariance. Specifically, the proposed method regularizes the representation so that it has as much domain information as the class labels, unlike prior methods that remove all domain information. Empirical validations show the superior performance of IFLOC to baseline methods, supporting the importance of the domain-class dependency in domain generalization and the efficacy of the proposed method for overcoming the issue.", "keywords": ["domain generalization", "adversarial learning", "invariant feature learning"]}, "meta": {"decision": "Reject", "comment": "This paper proposes a new solution to the problem of domain generalization where the label distribution may differ across domains. The authors argue that prior work which ignores this observation suffers from an accuracy-vs-invariance trade-off while their work does not. \n\nThe main contribution of the work is to 1) consider the case of different label distributions across domains and 2) to propose a regularizer extension to Xie 2017 to handle this. \n\nThere was disagreement between the reviewers on whether or not this contribution is significant enough to warrant publication. Two reviewers expressed concern of whether 1) naturally occurring data sources suffer substantially from this label distribution mismatch and 2) whether label distribution mismatch in practice results in significant performance loss for existing domain generalization techniques. Based on the experiments and discussions available now the answer to the above two points remains unclear. These key questions should be clarified and further justified before publication."}, "review": {"HyxnMJwKT7": {"type": "rebuttal", "replyto": "SJg4xkvKaQ", "comment": "\n### Reply to \u201cit is desirable to compare with the missing references in experiments\u201d\n\nThank you for introducing two important works.\nThese works greatly help us re-consider the novelty of our work.\n\nHowever, currently, we do not plan to conduct comparative experiments with them for two reasons.\nFirstly, both Wang+2014 and Long+2018 address domain adaptation, so their methods are not directly applicable to our setting (domain generalization).\nSecondly, as we discussed in reply to comment 1, p(y|x, d) \\neq p(y|x) is not a sufficient condition for p(y|d) \\neq p(y), and this paper addresses the trade-off problem caused by the latter.\nMore specifically, we acknowledge that comparing our method with methods invented for addressing p(y|x, d) \\neq p(y|x) is very interesting research direction, but is out of scope of this paper, given our three contributions: the novel problem setting (domain generalization under domain-class dependency); the theoretical analysis which derives the novel approach to address the problem (to regularize latent representation so that H(d|y)=H(d|h) holds); and to confirm the efficacy of the proposed approach with the novel algorithm (IFLOC).\n\n\nBelow are the detailed comments to each paper.\n\nWang+2014: They consider domain adaptation under a general case where both the support and the model (p(y|x)) change across domains. They proposed to transform both X and Y by a location-scale shift to achieve transfer between domains. Our paper differs from theirs in that we focus on domain generalization (while they focus on domain adaptation), we focus on p(y|d) \\neq p(y) (they focus on p(y|x, d) \\neq p(y|x)), we focus on classification (they focus on regression), and we use DNN to extract latent features (they use location-scale shift to transform target data into source data).\n\nLong+2018: They address two issues in domain adaptation: (1) when data distributions embody complex multimode structures, adversarial domain adaptation may fall into mode collapse; (2) adversarial adaptation of a particular layer is not sufficient to bridge the domain shifts. To address these issues, they proposed to conditioning domain discriminator on the middle layer and output layer of the classifier. Our paper differs from theirs in that we focus on domain generalization (while they focus on domain adaptation), we focus on p(y|d) \\neq p(y) (they do not mention the type of distributional shift), and we avoid removing all domain information from latent features.\n(Also, please note that the NIPS version of the paper is unavailable now.)", "title": "Response to Reviewer 3 [3/4]"}, "ryg7wJvK67": {"type": "rebuttal", "replyto": "HyxnMJwKT7", "comment": "\n### Reply to \u201cIt is also suggested to conduct the analysis of why the datasets satisfy the assumption of the dependence of class and domains\u201d\n\nWe agree that \u201cthe analysis of why the datasets satisfy the assumption of the dependence of class and domains\u201d would improve the paper, and some analysis is already done in the paper.\nSo we would very appreciate if you could specify what kind of analysis would improve the paper more.\nBelow are the analyses we already did in the paper.\n\n1. BMNISTR is the synthetic dataset which we created by modifying MNISTR. As noted in Sec.5.1., BMNISTRs have several types of domain-class dependency, and the reason for each type is noted in Sec.5.1. Also, the performances of IFLOC in each dependency type are discussed in the 1st-paragraph in Sec.5.4.\n\n2. PACS has the dependency probably because samples in some <domain, class> pairs are difficult to obtain, as noted in Sec.5.1. The reasons why some <domain, class> pairs become difficult to obtain is discussed in Sec.1 (data characteristics and data-collection errors).\n\n3. WISDM has the dependency due to the reason discussed in Sec.1.\n\n\nAlso, we have added the below discussion regarding the datasets.\n\n1. We have added the table of the concrete sample sizes for each <domain, class> pair in PACS and WISDM dataset to Appendix.\n\n2. The reason why WISDM has the dependency was already noted in Sec.1, but we have added it to Sec.5.1 again.\n\n3. We have provided the concrete example of domain-class dependency in PACS as follows:\n```\n(Sec.5.1, para.2) For example, p(y = person|d = Phot) is much higher than p(y = person|d = Sketch), which indicates that photos of person are easier to obtain than those of animals, but sketches of persons are more difficult to obtain than those of animals in the wild.\n```\n\n4. We have cited Zhang+2013 to support the fact that that domain-class dependency often happens in real-world dataset as follows:\n```\n(Sec.1, para.4) Unfortunately, domain-class dependency is common in real-world datasets as shown in Zhang et al. (2013).\n```\n\n### References\n\nKun Zhang, Bernhard Scholkopf, Krikamol Muandet, Zhikun Wang, \u201cDomain Adaptation under Target and Conditional Shift\u201d, ICML2013\nXuezhi Wang, Jeff Schneider, \u201cFlexible Transfer Learning under Support and Model Shift\u201d, NIPS2014\nMingsheng Long, Zhangjie Cao, Jianmin Wang, Michael I. Jordan, \u201cConditional Adversarial Domain Adaptation\u201d, NIPS2018\nYa Li, Mingming Gong, Xinmei Tian, Tongliang Liu, Dacheng Tao, \u201cDomain Generalization via Conditional Invariant Representations\u201d, AAAI2018\n", "title": "Response to Reviewer 3 [4/4]"}, "SJg4xkvKaQ": {"type": "rebuttal", "replyto": "Hkei6C8FpX", "comment": "\nBased on the above discussion (Response to Reviewer 3 [1/4]), we have updated the paper. Below are the details.\n\n1. To make it clear that our purpose is improving {\\em domain generalization performance}, we have changed the title of the paper to \u201ddomain generalization via invariant representation under domain-class dependency.\u201d\n\n2. To make it clear that domain generalization differs from domain adaptation, We have added the following sentences:\n```\n(Sec.2, para.2) Domain generalization has been attracting considerable attention in recent years (Blanchard et al. (2011); Muandet et al. (2013); Shankar et al. (2018)). Note that it is different from domain adaptation in that we cannot obtain input and label data from the target domain(s).\n(Sec.2, para.5) In domain adaptation, Zhang et al. (2013); Gong et al. (2016) address the situation where p(y) changes across source and target domains by estimating p(y) change using unlabeled target data. However, this approach is not applicable (or necessary) to domain generalization because our problem setting is different from theirs in that we are agnostic on target domain and aim to care about p(y) change within source domains instead.\n```\n\n3. To make it clear that conditional probability shift (p(y|x, d) \\neq p(y|x)) and domain-class dependency (p(y|d) \\neq p(y)) are different problems, and the latter is the root cause of the trade-off problem, we have added the following sentences:\n```\n(Sec.1, para.3) We define domain-class dependency as the situation where domain and class labels are statistically dependent due to some common latent factor (z) of y and d (Figure 1-right).\n(Sec.1, para.3) Domain-class dependency might be similar to the situation where p(y|x) and p(x) change across domains due to the causal structure y \u2192 x (Zhang et al. (2013); Gong et al. (2016) in domain adaptation and Li et al. (2018c) in domain generalization), which we call conditional probability shift. However, the shift does not cause the trade-off as long as y and d are independent (Figure 1-left), so it is necessary to focus on the relationship between y and d.\n(Sec.2, para.5) There are several kinds of distributional shifts other than domain-class dependency, such as conditional probability shift. Although the distinction between that shift and domain-class dependency is important, it has been received less attention. For example, Li et al. (2018c) claimed that conditional probability shift might harm the performance of domain-invariance-based methods, but our analysis in Sec.4.1.1 suggests that the root cause of the performance degradation is not it but domain-class dependency.\n```\n\n4. To show why conditional probability shift does not cause the trade-off problem and why domain-class dependency is important, we added the following sentence:\n```\n(Sec.4.1.1, the last para.) It is worth noting that although Li et al. (2018c) claimed that conditional probability shift (the causal structure y \u2192 x) could harm the domain generalization performance of invariance-based methods, this analysis suggests that it does not harm DAN as long as domain and class are independent. It can be confirmed by considering Eq.7 and Eq.10; even when the shift occurs, i.e., H(y|x, d) < H(y|x) holds and then H(y|h, d) \u2264 H(y|h) holds, it does not conflict with H(d|h) = H(d|y) = H(d) as long as H(d|y) = H(d) holds. In other words, we only need to infer latent variable h that satisfies the causal structure y \u2192 h \u2192 x to avoid the trade-off. Although Gong et al. (2016) showed a similar result in domain adaptation context, it has been overlooked in domain generalization.\n```", "title": "Response to Reviewer 3 [2/4]"}, "Hkei6C8FpX": {"type": "rebuttal", "replyto": "SylAH62FhQ", "comment": "Thank you for your critical feedback.\nWe hope to clarify and address your concerns and questions.\nWe respond in detail to each comment below.\n\n\n### Reply to \u201cit is desirable to discuss the difference between these two problems\u201d\n\nIn our understanding, your main concern is the novelty of our problem setting, i.e., \u201cis domain generalization under domain-class dependency (p(y|d) \\neq p(y)) is different from domain adaptation under p(y|x_S) \\neq p(y|x_T) ?\u201d\nWe acknowledge that we lack the discussion about the difference between these two (though they are indeed considerably different problems), so we have added the below discussion to the paper and emphasized the novelty of our problem setting.\n\nFirstly, the paper addresses {\\em domain generalization}, not domain adaptation, as noted in abstract, Sec.1, etc.\nThese two have different assumptions and purposes.\nConcretely, domain adaptation methods require either labeled or unlabeled data from the target domain at training time.\nIn contrast, domain generalization methods do not require any data from target domains during training but instead, require labeled data from several source domains.\nThen the methods collectively exploit them so that the trained system can handle new domains without any adaptation step.\n\nDue to the difference, domain adaptation methods are not always applicable to domain generalization.\nFor example, Wang+2014, which you suggested for us, transform unlabeled target data so that they can correct distributional shift, but in domain generalization, target data are unavailable.\nAlso, please note that we care about the shifts within source domains, because domain generalization methods are agnostic on the target domain.\nSo we think p(y|x_S) \\neq p(y|x_T) should be rewritten as p(y|x, d) \\neq p(y|x) (we call it conditional probability shift) in domain generalization, so that clarify we focus on the shift within source domains (not between S and T).\n\nSecondly, conditional probability shift (p(y|x, d) \\neq p(y|x)), which is often caused by the causal structure y -> x, is not a sufficient condition for p(y|d) \\neq p(y).\nWhile conditional probability shift was previously addressed by Li+2018 in domain generalization context, domain-class dependency has been overlooked.\nThe relation between these two problems is illustrated in Figure 1 in our updated paper.\n\nThirdly and most importantly, in domain generalization, conditional probability shift does not cause the trade-off problem as long as the domain-class dependency does not exist.\nIn other words, p(y|x, d) \\neq p(y|x) is not a root cause of the trade-off problem, but domain-class dependency is, so it is essential to consider and address domain-class dependency problem.\nAgain the relation between these two problems is illustrated in Figure 1 in our updated paper.\n", "title": "Response to Reviewer 3 [1/4]"}, "HkxHep8Y67": {"type": "rebuttal", "replyto": "SkeHjnHch7", "comment": "Thank you for your positive review.\nWe really appreciate the remarks that our \u201cidea is well motivated\u201d and \u201cexperiments are extensive and supportive\u201d.\n\n### Reply to \u201cto discuss its application to other domain adaptation/generalization methods and to show its effectiveness on another method in the experiments\u201d would improve the paper.\n\nThank you for the suggestion. As you pointed out, the regularization term is motivated by analyzing DAN. So we acknowledge that its application to other domain adaptation/generalization methods is not trivial and discussing it would improve the paper. One possible direction is to modify conditional VAE (Louizos+2015) or CrossGrad (Shankar+2018) to make H(d|h) = H(d|y) holds and to use it in domain generalization. These methods have clear and tractable data generating process but assume the independence of y and d, so we hope we can somehow modify it to H(d|h) = H(d|y) holds. However, we unfortunately might not have time to develop concrete methods and conduct experiments, so we have added the above discussion to the paper.\n\n### References\n\nChristos Louizos, Kevin Swersky, Yujia Li, Max Welling, and Richard S. Zemel. The variational fair autoencoder. ICLR2016\nShiv Shankar, Vihari Piratla, Soumen Chakrabarti, Siddhartha Chaudhuri, Preethi Jyothi, and Sunita Sarawagi. Generalizing across domains via cross-gradient training. ICLR2018\n", "title": "Response to Reviewer 1"}, "ByeXo2UY6m": {"type": "rebuttal", "replyto": "H1lur28F6m", "comment": "\n### Reply to comment 2.\n\n#### About Figure3-(b):\nWe acknowledge that we lack the explanation on it, so we investigated and considered the reasons as below.\n\n(1) Firstly, we do not intend to claim that \"IFLOC and IFLOC-Abl always outperform DAN when \u03b3 becomes strong\", but we just observed that IFLOC and IFLOC-Abl tends to outperform DAN when \u03b3 = 10, i.e., the regularizer becomes strong, in Figure 2-(a, b) and 3-(a, b).\nWe provided one possible explanation of this observation that \"the regularizers of IFLOC and IFLOC-Abl is KLD and thus bounded by 0, in contrast to that of DAN that can increase to infinity and destabilize the traininig\".\nHowever, since the regularization terms of IFLOC-Abl and DAN are intended to achive the same equilibrium and they do not have clear superiority or inferiority in theory, we do not intend to exclude the possibility that DAN outperforms IFLOC-Abl on a certain hyperparameter (and of course to show the superiority of IFLOC-Abl over DAN is not the main purpose of the paper).\n\n(2) Secondly, we acknowledge that \"the classification accuracy of IFLOC-abl method decreases a lot when \u03b3 is taken from 0.1 to 1\".\nHowever, the range of the accuracy reduction is roughly the same with those in <DAN, \u03b3 changes from 1 to 10, Figure 3-(a)> and (2) <DAN, \u03b3 changes from 1 to 10, Figure 3-(a)>.\nThis suggests that the range of accuracy reduction you concern is not so exceptional for the two domain-invariance-based methods in the WISDM experiment.\n\n\nBased on the above discussions, we modified the paper to clarity that \"IFLOC and IFLOC-Abl tends to but not always outperform DAN when \u03b3 becomes strong\" as follows:\n```\nThe training of IFLOC tends to be more stable than that of DAN when the regularizer becomes strong. Figures 2-(a,b) and 3-(a,b) show that IFLOC and IFLOC-Abl could achieve higher Y-Acc than DAN when \u03b3 = 1 or 10, i.e., the regularization is strong, except for IFLOC-Abl with \u03b3=1 in Figure 3-(b).\nThis tendency might be because the regularizer of IFLOC is KLD and thus bounded by 0, in contrast to that of DAN that can increase to infinity and destabilize the traininig.\n```\n\n\n#### About Figure3-(c):\nWe agree that this should be explained, and we already explained it to some extent as follows:\n```\n(Sec. 5.4, 2nd para.) That high D-Acc might be because the validation accuracy achieved the highest value before the domain-invariance matured. (Recall that the more the representation becomes invariant, the lower the accurary becomes under the trade-off).\n```\nSo we would appreciate if you could specify what kind of analysis would improve the paper more.\n\n\n### Reply to comment 3.\n\nWe agree that \u201canalysis on domain-class dependency of each dataset\u201d is important, and some analysis is already done in the paper.\nSo we would very appreciate if you could specify what kind of analysis would improve the paper more.\nBelow are the analyses we already did in the paper.\n\n1. BMNISTR is the synthetic dataset which we created by modifying MNISTR. As noted in Sec.5.1, BMNISTRs have several types of domain-class dependency, and the reason for the each type is noted in Sec.5.1. Also, the performances of IFLOC on each dependency type are discussued in the 1st-paragraph in Sec.5.4.\n\n2. PACS has the dependency probably because samples in some <domain, class> pairs are difficult to obtain, as noted in Sec.5.1. The reasons why some <domain, class> pairs become difficult to obtain is discussed in Sec.1 (data characteristics and data-collection errors).\n\n3. WISDM has the dependency due to the reason discussed in Sec.1.\n\n\nAlso, we have added the below discussion regarding the datasets.\n\n1. We have added the table of the concrete sample sizes for each <domain, class> pair in PACS and WISDM dataset to Appendix.\n\n2. The reason why WISDM has the dependency was already noted in Sec.1, but we have added it to Sec.5.1 again.\n\n3. We have provided the concrete example of domain-class dependency in PACS as follows:\n```\n(Sec.5.1, para.2) For example, p(y = person|d = Phot) is much higher than p(y = person|d = Sketch), which indicates that photos of person are easier to obtain than those of animals, but sketches of persons are more difficult to obtain than those of animals in the wild.\n```\n\n4. We have cited Zhang+2013 to support the fact that that domain-class dependency often happens in real-world dataset as follows:\n```\n(Sec.1, para.4) Unfortunately, domain-class dependency is common in real-world datasets as shown in Zhang et al. (2013).\n```", "title": "Response to Reviewer 2 [2/2]"}, "H1lur28F6m": {"type": "rebuttal", "replyto": "SygAAIO3n7", "comment": "Thank you for your critical feedback.\nWe hope to clarify and address your concerns and questions.\nWe respond in detail to each comment below.\n\n\n### Reply to comment 1\n\nRegarding this comment, we would very much appreciate if you could give us more details so that we could exactly address your concerns and improve the paper.\nFor example, we would like to know (1) why you think \"the paper does not support the innovation point enough\" and (2) which parts of \"the explanation is too simple\" and why simple is a weak point.\n\nHere, we would like to clarify three innovation points of the paper we think.\n(1) We elaborate on the trade-off problem under domain-class dependency, both theoretically (Sec.4.1.1) and experimentally (1st-paragraph of Sec.5.4), for the first time in domain generalization context.\nHere, note that domain generalization is different from domain adaptation in that we cannot obtain input and label data from target domain(s), but has been attracting considerable attention in recent years.\n(2) We propose to maximize domain-invariance within a range that does not interfere with classification accuracy and provide the theoretical analysis which derives the novel approach (i.e., to regularize latent representation so that H(d|y)=H(d|h) holds) to address the aforementioned problem in Sec.4.1.2.\n(3) We confirm the efficacy of the proposed approch with the novel algorighm (IFLOC) in Sec.5.4.\n\n\nMoreover, we have added the below contents to the updated paper in order to clarify the inovation points.\n\n1. To make it clear that domain generalization differs from domain adaptation, we have added the following sentence:\n```\n(Sec.2, para.2)  Domain generalization has been attracting considerable attention in recent years (Blanchard et al. (2011); Muandet et al. (2013); Shankar et al. (2018)). Note that it is different from domain adaptation in that we cannot obtain input and label data from target domain(s).\n```\n\n2. To make it clear that domain-class dependency (p(y|d) \\neq p(y)) is a novel and important problem setting in domain generalization, we compare it with conditional probability shift (p(y|x) and p(x) change across domains) and showed that domain-class dependency is a root cause of the trade-off problem:\n```\n(Sec.1, para.3) Domain-class dependency might be similar to the situation where p(y|x) and p(x) change across domains due to the causal structure y \u2192 x (Zhang et al. (2013); Gong et al. (2016) in domain adaptation and Li et al. (2018c) in domain generalization), which we call conditional probability shift. However, the shift does not cause the trade-off as long as y and d are independent (Figure 1-left), so it is necessary to focus on the relationship between y and d.\n(Sec.2, para.5) There are several kinds of distributional shifts other than domain-class dependency, such as conditional probability shift. Although the distinction between that shift and domain-class dependency is important, it has been received less attention. For example, Li et al. (2018c) claimed that conditional probability shift might harm the performance of domain-invariance-based methods, but our analysis in Sec.4.1.1 suggests that the root cause of the performance degradation is not it but domain-class dependency.\n```", "title": "Response to Reviewer 2 [1/2]"}, "SygAAIO3n7": {"type": "review", "replyto": "HJx38iC5KX", "review": "In this paper, the author(s) propose a method, invariant feature learning under optimal classifier constrains (IFLOC), which maintains accuracy while improving domain-invariance. Here is a list of suggestions that will help the author(s) to improve this paper.\n1.The paper explains the necessity and effectiveness of the method from the theoretical and experimental aspects, but the paper does not support the innovation point enough, and the explanation is too simple.\n2.In this paper, Figure3-(b) shows that the classification accuracy of IFLOC-abl method decreases a lot when \u03b3 is taken to 0. Figure3-(c) shows that the domain invariance of IFLOC-abl method becomes significantly worse when \u03b3 is 10. The author(s) should explain the reasons in detail.\n3. The lack of analysis on domain-class dependency of each dataset makes the analysis of experimental results weak.\n", "title": "This paper lacks sufficient novelty", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "SkeHjnHch7": {"type": "review", "replyto": "HJx38iC5KX", "review": "This paper proposed to address domain generalization under inter-dependence of domains and classes. It motivates a new regularization term by analyzing an existing work, DAN. It shows that this term can improve the generalization performance when the classes and domains are not independent. Experiments are extensive and supportive. \n\nI do not have many comments about this paper. It was a joy to read. The proposed idea is well motivated. It is simple and seems like effective. Experiments are extensive. \n\nWhile the regularization term is motivated by analyzing DAN, it would be nice to discuss its application to other domain adaptation/generalization methods. What is even better is to show its effectiveness on another method in the experiments.", "title": "Simple and effective idea, good experiment design", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "SylAH62FhQ": {"type": "review", "replyto": "HJx38iC5KX", "review": "The paper proposed a problem that most prior methods overlooked the underlying dependency of classes on domains, namely p (y|d) \\= p(y).   Figure 1 is used to illustrate this issue. \n\nIf the conditional probability of source domain and target domain is not equal (i.e., p(y|x_S) \\= p(y|x_T)  ), the optimal invariance can lead the same generalization problem.   Unfortunately, a lot of works has been done [1,2] in matching domain classifier or conditional probability.  It is desirable to discuss the difference between these two problems and compared with the missing references in experiments. \n\nIt is also suggested to conduct the analysis of why the datasets satisfy the assumption of the dependence of class and domains. \n\nReference:\n[1] Flexible Transfer Learning under Support and Model Shift, NIPS 2014.\n[2]Conditional Adversarial Domain Adaptation, NIPS 2018", "title": "The proposed problem seems similar to traditional conditional distribution matching problem. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}