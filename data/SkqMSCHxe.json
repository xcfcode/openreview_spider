{"paper": {"title": "PREDICTION OF POTENTIAL HUMAN INTENTION USING SUPERVISED COMPETITIVE LEARNING", "authors": ["Masayoshi Ishikawa", "Mariko Okude", "Takehisa Nishida & Kazuo Muto"], "authorids": ["masayoshi.ishikawa.gv@hitachi.com", "mariko.okude.uh@hitachi.com", "takehisa.nishida.cu@hitachi.com", "kazuo.muto.ny@hitachi.com"], "summary": "", "abstract": "We propose a learning method to quantify human intention. Generally, a human being will imagine several potential actions for a given scene, but only one of these actions will subsequently be taken. This makes it difficult to quantify human intentions.\nTo solve this problem, we apply competitive learning to human behavior prediction as supervised learning. In our approach, competitive learning generates several outputs that are then associated with several potential situations imagined by a human. We applied the proposed method to human driving behavior and extracted three potential driving patterns. Results showed a squared error is reduced to 1/25 that of a conventional method . We also found that competitive learning can distinguish valid data from disturbance data in order to train a model.", "keywords": ["Computer vision", "Deep learning", "Supervised Learning", "Applications"]}, "meta": {"decision": "Reject", "comment": "The authors present a prediction framework that involves multiple 'competitive' RNNs, and they claim that they are predicting human intention. It is unclear if this method, which seems quite ad-hoc, is any different from a simple ensemble approach, and it is unclear that the model is predicting human intention. The experiments do not adequately demonstrate either."}, "review": {"Bkki4UCQg": {"type": "rebuttal", "replyto": "ryQCpbqmx", "comment": "- After 6 steps is right. We predict state at time t+6 when we observe state at time t. We mention this in section 4.\n\n- Predicting steps relate with prediction error. Generally, long prediction steps increase prediction error. We didn't mention this in our paper.\n\n- Switching competitive layers are shown at top-left of Figure 8 (train) and Figure 9 (test). We use other color for each competitive layers and switching color means switching competitive layers. In Figure 8, we use three competitive layers and assign green, blue and purple line for first, second and third competitive layers respectably. And we can see that purple line is dominant when speed is decreasing or deceleration. Also blue line is dominant when speed is increasing or acceleration. Therefore, we consider we can extract other driver's style such that deceleration mode by purple line and acceleration mode by blue line.  We mention this in section 4.2.", "title": "Answer"}, "ryQCpbqmx": {"type": "review", "replyto": "SkqMSCHxe", "review": "- In Figures 6 and 7, what do predictions correspond to? Is it the prediction 3 seconds after the last observed state, or the prediction right after the last state? In other words, after 6 or 1 steps?\n\n- How do predictions degrade when predicting more steps, say 1, 6, 12, 24?\n\n- In Figure 7, how much switching occurs between competitive layers? Is it sticking to the same layer for a couple steps, few seconds or for the whole sequence to adapt to a particular driver's style?Authors propose a competitive learning architecture that learn different RNN predictors independently, akin to a committee of experts which are chosen with a hard switch at run-time. This work is applied to the task of predictive different driving behaviors from human drivers, and combines behaviors at test time, often switching behaviors within seconds. Prediction loss is lower than the similar but non-competitive architecture used as a baseline.\nIt is not very clear how to interpret the results, what is the real impact of the model. If behaviors switch very often, can this really be seen as choosing the best driving mode for a given situation? Maybe the motivation needs to be rephrased a little to be more convincing?\nThe competitive approach presented is interesting but not really novel, thus the impact of this paper for a conference such as ICLR may be limited.", "title": "Details", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "BJGLxHeEg": {"type": "review", "replyto": "SkqMSCHxe", "review": "- In Figures 6 and 7, what do predictions correspond to? Is it the prediction 3 seconds after the last observed state, or the prediction right after the last state? In other words, after 6 or 1 steps?\n\n- How do predictions degrade when predicting more steps, say 1, 6, 12, 24?\n\n- In Figure 7, how much switching occurs between competitive layers? Is it sticking to the same layer for a couple steps, few seconds or for the whole sequence to adapt to a particular driver's style?Authors propose a competitive learning architecture that learn different RNN predictors independently, akin to a committee of experts which are chosen with a hard switch at run-time. This work is applied to the task of predictive different driving behaviors from human drivers, and combines behaviors at test time, often switching behaviors within seconds. Prediction loss is lower than the similar but non-competitive architecture used as a baseline.\nIt is not very clear how to interpret the results, what is the real impact of the model. If behaviors switch very often, can this really be seen as choosing the best driving mode for a given situation? Maybe the motivation needs to be rephrased a little to be more convincing?\nThe competitive approach presented is interesting but not really novel, thus the impact of this paper for a conference such as ICLR may be limited.", "title": "Details", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}