{"paper": {"title": "Deep Neural Networks and the Tree of Life", "authors": ["Yan Wang", "Kun He", "John E. Hopcroft", "Yu Sun"], "authorids": ["yanwang@hust.edu.cn", "brooklet60@hust.edu.cn", "jeh@cs.cornell.edu", "ys646@cornell.edu"], "summary": "Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks", "abstract": "In Evolutionary Biology, species close in the tree of evolution are identified by similar visual features. In computer vision, deep neural networks perform image classification by learning to identify similar visual features. This leads to an interesting question: is it possible to leverage the advantage of deep networks to construct a tree of life? In this paper, we make the first attempt at building the phylogenetic tree diagram by leveraging the high-level features learned by deep neural networks. Our method is based on the intuition that if two species share similar features, then their cross activations in the softmax layer should be high. Based on the deep representation of convolutional neural networks trained for image classification, we build a tree of life for species in the image categories of ImageNet. Further, for species not in the ImageNet categories that are visually similar to some category, the cosine similarity of their activation vectors in the same layer should be high. By applying the inner product similarity of the activation vectors at the last fully connected layer for different species, we can roughly build their tree of life. Our work provides a new perspective to the deep representation and sheds light on possible novel applications of deep representation to other areas like Bioinformatics.\n", "keywords": ["Deep learning", "Computer vision", "Applications"]}, "meta": {"decision": "Reject", "comment": "The reviewers agree that the paper provides a creative idea of using Computer Vision in Biology by building \"the tree of life\". However, they also agree that the paper in its current form is not ready for publication due to limited novelty and unclear impact/application. The authors did not post a rebuttal to address the concerns. The AC agrees with the reviewers', and encourages the authors to improve their manuscript as per reviewers' suggestions, and submit to a future conference."}, "review": {"r1_vW2HVx": {"type": "rebuttal", "replyto": "r17RD2oxe", "comment": "I think the idea is interesting, but is that something useful to construct the tree based on visual features? \n\nMoreover, in the paper, you mentioned that, it is based on the conjecture that,\n\"if images of two training categories share some similar features, then their cross activations in the softmax layer should be high\".\n\nTo me , this is something like the Neural style transfer, \nhttps://arxiv.org/abs/1508.06576\nIt is calculating the correlations between features.\n\nThen what is the real application for this ?", "title": "Is this something useful for biologist ? or for computer vision researcher ?"}, "HyEuBvMNx": {"type": "rebuttal", "replyto": "BkLWp70zx", "comment": "Thank you for your comments and questions.We agree that \"tree of life\", semantic hierarchy and visual hierarchy are different concepts. We agree with your summarize that we have created a visual hierarchy evaluated on a hierarchy. We do no claim that we are building a \"tree of life\" and should make that very clear.The works that you mentioned are relevant and we will cite and compare them. The paper by Deng et. al focuses image classification; more specifically, your referred section attempts to make classification results more reasonable when placed in an existing hierarchy. They do not attempt the task of generating a new visual hierarchy. The paper by Griffin and Perona al also explores the problem from a classification perspective, while their hierarchy of classifiers can be viewed as analogous to our hierarchy of images. We will also point these out. The paper by Marsza\u0142ek and Schmid should be an interesting baseline for our method, and we hope to conduct this experiment soon.", "title": "feedback"}, "r1PIHPMNx": {"type": "rebuttal", "replyto": "rkXjqEqQl", "comment": "Our methods creates a particular taxonomy, which may contain information on ancestry. Yes, many complex phenomena factor into the determination of ancestry, which is even difficult for biologists. We do not claim that we have recovered the ancestry relationship.We are claiming that the features learned by the current generation of networks are capable of learning a very reasonable hierarchy. Yes, previous feature extractors are also fitting for this task, but we did not experiment with them simply because we wanted to use modern models.", "title": "feedback"}, "rkXjqEqQl": {"type": "review", "replyto": "r17RD2oxe", "review": "I don't have any clarification questions so I'm left with big picture stuff:\n\nDon't biologists primarily want a tree of life hierarchy based on actual ancestry? Is the proposed work supposed to approximate that? Because visual similarity seems like a poor proxy. You have phenomena such as convergent evolution ( https://en.wikipedia.org/wiki/Convergent_evolution ) that will fool a visual classifier. Or maybe ancestry isn't the only way to organize the tree of life. But in that case, it probably shouldn't be a tree, right? Probably more of a graph. A tree makes sense only with ancestry.\n\nCouldn't you do this with any previous (including non-deep) visual feature + classifier? Won't the next generation of better deep networks provide yet another arrangement? Won't human perceptual ratings provide yet another? How would this actually be used?I like this paper in that it is a creative application of computer vision to Biology. Or, at least, that would be a good narrative but I'm not confident biologists would actually care about the \"Tree of Life\" built from this method. There's not really any biology in this paper, either in methodology or evaluation. It boils down to a hierarchical clustering of visual categories with ground truth assumed to be the WordNet hierarchy (which may or may not be the biological ground truth inheritance relationships between species, if that is even possible to define -- it probably isn't for dog species which interbreed and it definitely isn't for vehicles) or the actual biological inheritance tree or what humans would do in the same task. If we're just worried about visual relationships and not inheritance relationships then a graph is the right structure, not a tree. A tree is needlessly lossy and imposes weird relationships (e.g. ImageNet has a photo of a \"toy rabbit\" and by tree distance it is maximally distant from \"rabbit\" because the toy is in the devices top level hierarchy and the real rabbit is in the animal branch. Are those two images really as semantically unrelated as is possible?). Our visual world is not a hierarchy. Our biological world can reasonably be defined as one. One could define the task of trying to recover the biological inheritance tree from visual inputs, although we know that would be tough to do because of situations like convergent evolution. Still, one could evaluate how well various visual features can recover the hierarchical relationship of biological organisms. This paper doesn't quite do that. And even if it did, it would still feel like a bit of a solution in search of a problem. The paper says that this type of exercise can help us understand deep features, but I'm not sure sure how much it reveals. I guess it's a fair question to ask if a particular feature produces meaningful class-to-class distances, but it's not clear that the biological tree of life or the wordnet hierarchy is the right ground truth for that (I'd argue it's not).\n\nFinally, the paper mentions human baselines in a few places but I'm not really seeing it. \"Experiments show that the proposed method using deep representation is very competitive to human beings in building the tree of life based on the visual similarity of the species.\" and then later \"The reconstructed quality is as good as what human beings could reconstruct based on the visual similarity.\" That's the extent of the experiment? A qualitative result and the declaration that it's as good as humans could do? ", "title": "Pre-review concerns", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rkVScXzEl": {"type": "review", "replyto": "r17RD2oxe", "review": "I don't have any clarification questions so I'm left with big picture stuff:\n\nDon't biologists primarily want a tree of life hierarchy based on actual ancestry? Is the proposed work supposed to approximate that? Because visual similarity seems like a poor proxy. You have phenomena such as convergent evolution ( https://en.wikipedia.org/wiki/Convergent_evolution ) that will fool a visual classifier. Or maybe ancestry isn't the only way to organize the tree of life. But in that case, it probably shouldn't be a tree, right? Probably more of a graph. A tree makes sense only with ancestry.\n\nCouldn't you do this with any previous (including non-deep) visual feature + classifier? Won't the next generation of better deep networks provide yet another arrangement? Won't human perceptual ratings provide yet another? How would this actually be used?I like this paper in that it is a creative application of computer vision to Biology. Or, at least, that would be a good narrative but I'm not confident biologists would actually care about the \"Tree of Life\" built from this method. There's not really any biology in this paper, either in methodology or evaluation. It boils down to a hierarchical clustering of visual categories with ground truth assumed to be the WordNet hierarchy (which may or may not be the biological ground truth inheritance relationships between species, if that is even possible to define -- it probably isn't for dog species which interbreed and it definitely isn't for vehicles) or the actual biological inheritance tree or what humans would do in the same task. If we're just worried about visual relationships and not inheritance relationships then a graph is the right structure, not a tree. A tree is needlessly lossy and imposes weird relationships (e.g. ImageNet has a photo of a \"toy rabbit\" and by tree distance it is maximally distant from \"rabbit\" because the toy is in the devices top level hierarchy and the real rabbit is in the animal branch. Are those two images really as semantically unrelated as is possible?). Our visual world is not a hierarchy. Our biological world can reasonably be defined as one. One could define the task of trying to recover the biological inheritance tree from visual inputs, although we know that would be tough to do because of situations like convergent evolution. Still, one could evaluate how well various visual features can recover the hierarchical relationship of biological organisms. This paper doesn't quite do that. And even if it did, it would still feel like a bit of a solution in search of a problem. The paper says that this type of exercise can help us understand deep features, but I'm not sure sure how much it reveals. I guess it's a fair question to ask if a particular feature produces meaningful class-to-class distances, but it's not clear that the biological tree of life or the wordnet hierarchy is the right ground truth for that (I'd argue it's not).\n\nFinally, the paper mentions human baselines in a few places but I'm not really seeing it. \"Experiments show that the proposed method using deep representation is very competitive to human beings in building the tree of life based on the visual similarity of the species.\" and then later \"The reconstructed quality is as good as what human beings could reconstruct based on the visual similarity.\" That's the extent of the experiment? A qualitative result and the declaration that it's as good as humans could do? ", "title": "Pre-review concerns", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "BkLWp70zx": {"type": "review", "replyto": "r17RD2oxe", "review": "Would you please comment on the similarities and differences between \u201ctree of life,\u201d \u201csemantic hierarchy\u201d and \u201cvisual similarity hierarchy\u201d? It appears that the algorithm is claimed to be learning a \u201ctree of life\u201d but in practice is just building a \u201cvisual hierarchy\u201d evaluated with a \u201csemantic hierarchy\u201d (i.e., WordNet).\n\nWould you please also place this work in the context of computer vision literature on constructing visual hierarchies: for example, (1) the findings of Section 6 of \u201cWhat Does Classifying More Than 10,000 Image Categories Tell Us?\u201d Deng et al. ECCV 2010 about the relationship between classification confusion and the WordNet hierarchy,  as well as works such as (2) Griffin, G., Perona, P.: Learning and using taxonomies for fast visual categorization. In: CVPR 2008, or (3) \u201cConstructing category hierarchies for visual recognition\u201d M Marsza\u0142ek, C Schmid - European Conference on Computer Vision, 2008, etc. The paper presents a simple method for constructing a visual hierarchy of ImageNet classes based on a CNN trained on discriminate between the classes. It investigates two metrics for measuring inter-class similarity: (1) softmax probability outputs, i.e., the class confusion matrix, and (2) L2 distance between fc7 features, along with three methods for constructing the hierarchy given the distance matrix: (1) approximation central point, (2) minimal spanning tree, and (3) multidimensional scaling of Borg&Groenen 2005.\n\nThere are two claimed contributions: (1) Constructs a biology evolutionary tree, and (2) Gives insight into the representations produced by deep networks. \n\nRegarding (1), while the motivation of the work is grounded in biology, in practice the method is based only on visual similarity. The constructed trees thus can\u2019t be expected to reflect the evolutionary hierarchy, and in fact there are no quantitative experiments that demonstrate that they do. \n\nRegarding (2), the technical depth of the exploration is not sufficient for ICLR. I\u2019m not sure what we can conclude from the paper beyond the fact that CNNs are able to group categories together based on visual similarities, and deeper networks are able to do this better than more shallow networks (Fig 2).\n\nIn summary, this paper is unfortunately not ready for publication at this time. ", "title": "Types of hierarchy", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "HkptTW8Vl": {"type": "review", "replyto": "r17RD2oxe", "review": "Would you please comment on the similarities and differences between \u201ctree of life,\u201d \u201csemantic hierarchy\u201d and \u201cvisual similarity hierarchy\u201d? It appears that the algorithm is claimed to be learning a \u201ctree of life\u201d but in practice is just building a \u201cvisual hierarchy\u201d evaluated with a \u201csemantic hierarchy\u201d (i.e., WordNet).\n\nWould you please also place this work in the context of computer vision literature on constructing visual hierarchies: for example, (1) the findings of Section 6 of \u201cWhat Does Classifying More Than 10,000 Image Categories Tell Us?\u201d Deng et al. ECCV 2010 about the relationship between classification confusion and the WordNet hierarchy,  as well as works such as (2) Griffin, G., Perona, P.: Learning and using taxonomies for fast visual categorization. In: CVPR 2008, or (3) \u201cConstructing category hierarchies for visual recognition\u201d M Marsza\u0142ek, C Schmid - European Conference on Computer Vision, 2008, etc. The paper presents a simple method for constructing a visual hierarchy of ImageNet classes based on a CNN trained on discriminate between the classes. It investigates two metrics for measuring inter-class similarity: (1) softmax probability outputs, i.e., the class confusion matrix, and (2) L2 distance between fc7 features, along with three methods for constructing the hierarchy given the distance matrix: (1) approximation central point, (2) minimal spanning tree, and (3) multidimensional scaling of Borg&Groenen 2005.\n\nThere are two claimed contributions: (1) Constructs a biology evolutionary tree, and (2) Gives insight into the representations produced by deep networks. \n\nRegarding (1), while the motivation of the work is grounded in biology, in practice the method is based only on visual similarity. The constructed trees thus can\u2019t be expected to reflect the evolutionary hierarchy, and in fact there are no quantitative experiments that demonstrate that they do. \n\nRegarding (2), the technical depth of the exploration is not sufficient for ICLR. I\u2019m not sure what we can conclude from the paper beyond the fact that CNNs are able to group categories together based on visual similarities, and deeper networks are able to do this better than more shallow networks (Fig 2).\n\nIn summary, this paper is unfortunately not ready for publication at this time. ", "title": "Types of hierarchy", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}}