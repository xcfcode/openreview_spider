{"paper": {"title": "Sequence generation with a physiologically plausible model of handwriting and Recurrent Mixture Density Networks", "authors": ["Daniel Berio", "Memo Akten", "Frederic Fol Leymarie", "Mick Grierson", "R\u00e9jean Plamondon"], "authorids": ["d.berio@gold.ac.uk", "m.akten@ac.uk", "ffl@gold.ac.uk", "m.grierson@gold.ac.uk", "rejean.plamondon@polymtl.ca"], "summary": "To explore the feasibility and potential benefits of using a physiological plausible model of handwriting as a feature representation for sequence generation with recurrent mixture density networks", "abstract": "The purpose of this study is to explore the feasibility and potential benefits of using a physiological plausible model of handwriting as a feature representation for sequence generation with recurrent mixture density networks. We build on recent results in handwriting prediction developed by Graves (2013), and we focus on generating sequences that possess the statistical and dynamic qualities of handwriting and calligraphic art forms. Rather than model raw sequence data, we first preprocess and reconstruct the input training data with a concise representation given by a motor plan (in the form of a coarse sequence of `ballistic' targets) and corresponding dynamic parameters (which define the velocity and curvature of the pen-tip trajectory). This representation provides a number of advantages, such as enabling the system to learn from very few examples by introducing artificial variability in the training data, and mixing of visual and dynamic qualities learned from different datasets.", "keywords": ["Deep learning", "Supervised Learning", "Applications"]}, "meta": {"decision": "Reject", "comment": "The paper presents a system, namely a recurrent model for handwriting generation. However it doesn't make a clear case for what contribution is being made, or convincing experimental comparisons. The reviews, while short, provide consistent suggestions and directions for how this work could be improved and reworked."}, "review": {"BJqGXDKNl": {"type": "rebuttal", "replyto": "B1nnYzUQl", "comment": "Hi; thank you for the comment: can you please indicate which paper(s) or work you are thinking of when talking of skeleton data? very hard to provide a clear reply otherwise.\n", "title": "Please indicate your reference(s)"}, "r1jS_2dme": {"type": "rebuttal", "replyto": "Hkc_Yz87l", "comment": "We did only train on 1/10th of the IAM database, however our interests with the augmentation is specifically for small datasets (as small as a single training example) which we do test and report under the \"one shot learning\" section.\n\n\nWe propose that one of the advantages of the Sigma-Lognormal intermediate representation is that it allows to augment a dataset by introducing variability in the the parameters of the movement model. This results in variations of the trajectories that are similar to the ones that can be seen in multiple instances of writing by one or more authors, and would be difficult to achieve by simply scaling the input dataset or perturbing the raw trajectory data-points.\n\n\nWhile a network will learn a sparse representation of the (online) data internally, we do not have much control on what this representation this will be, on its behaviour, on on how to control it. By using the Sigma-Lognormal model we abstract the complexity of motor execution, using a well studied human movement model, and thus simplify the task of the network to a motor-planning one.  We propose The Sigma-Lognormal representation results in a network output that is controllable and more easily manipulable (e.g in an interactive setting) than raw sequence data or than a latent representation learned by the network.\n\n\n It could be argued that a similar advantages would be given by parameterising the data as splines or Bezier curves, but the Sigma-Lognormal model provides the additional benefit of capturing the movement dynamics (velocity/acceleration) of the input data in a physiologically plausible manner. ", "title": "Intermediate representation"}, "rybe_3umg": {"type": "rebuttal", "replyto": "B1nnYzUQl", "comment": "To the best of our knowledge, RNN/LSTMs are amongst the state of the art for handwriting prediction  (though it's difficult to quantify), but our research is specifically targeted at testing the Sigma-Lognormal representation and any advantages it may give over a dense representation.", "title": "Sequence prediction"}, "SJn3D2dmx": {"type": "rebuttal", "replyto": "HkRpFMUXg", "comment": "Hello, first of all thanks for the feedback!\nMaybe this should be made more clear/emphasised in the paper, but we are using the online version of the IAM dataset, so the training data is generated by preprocessing the raw (online, time ordered point sequence) data and reconstructing Sigma-Lognormal parameters.\n", "title": "Offline/online"}, "Hkc_Yz87l": {"type": "review", "replyto": "r1S083cgx", "review": "I wonder whether the intermediate representation (developed by Plamondon et al.) is useful in this context of a fully trained sequence generation model. Couldn't the model pick up the necessary transformations itself?\n\nYou do mention that the new representation allows to do data augmentation, but the experiments suggest that this was not fully exploited, as training is performed on 1/10th of the images only.\nThe paper presents a method for sequence generation with a known method applied to feature extracted from another existing method. The paper is heavily oriented towards to chosen technologies and lacks in literature on sequence generation. In principle, rich literature on motion prediction for various applications could be relevant here. Recent models exist for sequence prediction (from primed inputs) for various applications, e.g. for skeleton data. These models learn complex motion w/o any pre-processing. \n\nEvaluation is a big concern. There is no quantitative evaluation. There is no comparision with other methods.\n\nI still wonder whether the intermediate representation (developed by Plamondon et al.) is useful in this context of a fully trained sequence generation model and whether the model could pick up the necessary transformations itself. This should be evaluated.\n\nDetails:\n\nThere are several typos and word omissions, which can be found by carefully rereading the paper.\n\nAt the beginning of section 3, it is still unclear what the application is. Prediction of dynamic parameters? What for? Section 3 should give a better motivation of the work.\n\nConcerning the following paragraph\n\n\"While such methods are superior for handwriting analysis and biometric purposes, we opt for a less precise method (Berio & Leymarie, 2015) that is less sensitive to sampling quality and is aimed at generating virtual target sequences that remain perceptually similar to the original trace. \n\"\nThis method has not been explained. A paper should be self-contained.\n\nThe authors mentioned that the \"V2V-model is conditioned on (...)\"; but not enough details are given. \n\nGenerally speaking, more efforts could be made to make the paper more self-contained.\n", "title": "Intermediate representation", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "rJpkoyG4g": {"type": "review", "replyto": "r1S083cgx", "review": "I wonder whether the intermediate representation (developed by Plamondon et al.) is useful in this context of a fully trained sequence generation model. Couldn't the model pick up the necessary transformations itself?\n\nYou do mention that the new representation allows to do data augmentation, but the experiments suggest that this was not fully exploited, as training is performed on 1/10th of the images only.\nThe paper presents a method for sequence generation with a known method applied to feature extracted from another existing method. The paper is heavily oriented towards to chosen technologies and lacks in literature on sequence generation. In principle, rich literature on motion prediction for various applications could be relevant here. Recent models exist for sequence prediction (from primed inputs) for various applications, e.g. for skeleton data. These models learn complex motion w/o any pre-processing. \n\nEvaluation is a big concern. There is no quantitative evaluation. There is no comparision with other methods.\n\nI still wonder whether the intermediate representation (developed by Plamondon et al.) is useful in this context of a fully trained sequence generation model and whether the model could pick up the necessary transformations itself. This should be evaluated.\n\nDetails:\n\nThere are several typos and word omissions, which can be found by carefully rereading the paper.\n\nAt the beginning of section 3, it is still unclear what the application is. Prediction of dynamic parameters? What for? Section 3 should give a better motivation of the work.\n\nConcerning the following paragraph\n\n\"While such methods are superior for handwriting analysis and biometric purposes, we opt for a less precise method (Berio & Leymarie, 2015) that is less sensitive to sampling quality and is aimed at generating virtual target sequences that remain perceptually similar to the original trace. \n\"\nThis method has not been explained. A paper should be self-contained.\n\nThe authors mentioned that the \"V2V-model is conditioned on (...)\"; but not enough details are given. \n\nGenerally speaking, more efforts could be made to make the paper more self-contained.\n", "title": "Intermediate representation", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}}