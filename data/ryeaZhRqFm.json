{"paper": {"title": "Link Prediction in Hypergraphs using Graph Convolutional Networks", "authors": ["Naganand Yadati", "Vikram Nitin", "Madhav Nimishakavi", "Prateek Yadav", "Anand Louis", "Partha Talukdar"], "authorids": ["y.naganand@gmail.com", "vikramnitin9@gmail.com", "madhav@iisc.ac.in", "prateekyadav@iisc.ac.in", "anandl@iisc.ac.in", "ppt@iisc.ac.in"], "summary": "We propose Neural Hyperlink Predictor (NHP). NHP adapts graph convolutional networks for link prediction in hypergraphs", "abstract": "Link prediction in simple graphs is a fundamental problem in which new links between nodes are predicted based on the observed structure of the graph. However, in many real-world applications, there is a need to model relationships among nodes which go beyond pairwise associations. For example, in a chemical reaction, relationship among the reactants and products is inherently higher-order. Additionally, there is need to represent the direction from reactants to products. Hypergraphs provide a natural way to represent such complex higher-order relationships. Even though Graph Convolutional Networks (GCN) have recently emerged as a powerful deep learning-based approach for link prediction over simple graphs, their suitability for link prediction in hypergraphs is unexplored -- we fill this gap in this paper and propose Neural Hyperlink Predictor (NHP). NHP adapts GCNs for link prediction in hypergraphs. We propose two variants of NHP --NHP-U and NHP-D -- for link prediction over undirected and directed hypergraphs, respectively. To the best of our knowledge, NHP-D is the first method for link prediction over directed hypergraphs. Through extensive experiments on multiple real-world datasets, we show NHP's effectiveness.", "keywords": ["Graph convolution", "hypergraph", "hyperlink prediction"]}, "meta": {"decision": "Reject", "comment": "The paper describes  a method for the link prediction problem in both directed and undirected hypergraphs.  While the problem discussed in the paper is clearly importnant and interesting, all reviewers agree that the novelty of the proposed approach is somewhat limited given the prior art."}, "review": {"r1xLwJqHJ4": {"type": "rebuttal", "replyto": "B1xcPUDSyV", "comment": "Thanks for the response. \n\nOn the novelty of our work:\nWe reiterate that the main novelty / contribution of our work is to explore\n1) an unexplored problem (link prediction in directed hypergraphs) \n2) an underexplored problem (link prediction in undirected hypergraphs) and to propose the first neural-network-based method for the problem \n\nWe have proposed a unified framework for the two important and interesting problems and our proposed solution is conceptually simple, yet effective.\n\n\n\nOn including the extra term L_d for CMM + MLP:\nThe baseline we have compared against is plain CMM + MLP (sequential). CMM uses the expectation-maximisation (EM) algorithm to optimise its objective function to predict hyperlinks. Since CMM is not solved by the conventional gradient descent-based methods, using the term L_d jointly with EM is a non-trivial problem in itself (it is not as straightforward as adding an extra term to the loss function).\n\n\n\nOn sampling candidate papers:\nAs motivated in section 3, in the case of multi-author collaborations of academic/technical papers, hyperlinks have cardinalities less than a small number, as papers seldom have more than 6 authors. We looked at the distribution of the number of authors of actual (positive) papers and sampled an equal number of negative (fake) papers from the distribution. This means that although there are a large number of potential fake papers, we can make do with a vastly reduced number because of our sampling strategy. \n\nA related work [1] also has sampled an equal number of negative links for all datasets in its experiments. \n[1] Link Prediction Based on Graph Neural Networks, Muhan Zhang and Yixin Chen, NeurIPS 2018", "title": "Our clarifications"}, "rJxYm2KHk4": {"type": "rebuttal", "replyto": "HJlSr0o80Q", "comment": "Thanks for the response. We reiterate that the main novelty / contribution of our work is to explore \n1) an unexplored problem (link prediction in directed hypergraphs)\n2) an underexplored problem (link prediction in undirected hypergraphs) and to propose the first neural-network-based method for the problem\n\nWe have proposed a unified framework for the two important and interesting problems and our proposed solution is conceptually simple, yet effective.", "title": "On the novelty of our work"}, "rklrbi_4Rm": {"type": "rebuttal", "replyto": "ryeaZhRqFm", "comment": "We thank the reviewers for their reviews. Below, we have summarised the revisions made to our paper in the rebuttal period. The majority of the revisions have been in the experiments (section numbers 5, 6 and 7).\n\n- In section 5, we have added descriptions and results of a couple of baselines (node2vec, and GCN on star expansion) as suggested by reviewer 3.\n\n- In section 6, we have added descriptions and results of three baselines (node2vec + MLP, CMM + MLP, and GCN on star expansion + MLP) as suggested by reviewers 2  and 3.\n\n- We have added a new section (section 7) to compare our strategy of positive unlabeled learning and negative sampling uniformly at random as suggested by reviewer 1.\n\n\n\nWe have corrected all typos, and cited missing references as suggested by the reviewers. The revisions can be compared using the compare revisions option on the revisions page.", "title": "Summary of revisions"}, "B1xL2zM4pX": {"type": "rebuttal", "replyto": "S1xMYoWc2Q", "comment": "Thanks for the review\n\nOn the novelty of our work:\nLink prediction in undirected hypergraphs is an underexplored problem and that in directed hypergraphs is an unexplored problem. Our main contribution is a unified framework for both the settings and our proposed solution is conceptually simple, yet effective. We believe the problem settings are important and interesting (as noted by the other reviewers too), and that this paper will inspire further research in this direction.\n\n\n\nOn the discussion of results for directed hyperlink prediction:\nBoth NHP-D (joint) and NHP-D (sequential) perform similarly. To appreciate the results, we have added three baselines as suggested by reviewers 2 and 3. We request the reviewer to see below for a sample of the updated results and the paper for all updated results.\n\n---------------------------------------------------------------------------------------------------------------------------------\n                         dataset\t\t\t\t  \tiAF692\t         iHN637\t          iAF1260b          iJO1366\n---------------------------------------------------------------------------------------------------------------------------------\nnode2vec + MLP\t\t\t                      255 +/- 5\t         237 +/- 5\t  838 +/- 13\t   902 +/- 11\n---------------------------------------------------------------------------------------------------------------------------------\nCMM + MLP    \t\t\t                     253 +/- 9\t        241 +/- 11\t  757 +/- 26\t   848 +/- 21\n---------------------------------------------------------------------------------------------------------------------------------\nGCN on star expansion + MLP\t             242 +/- 5\t        241 +/- 10\t   786 +/- 13\t   852 +/- 11\n---------------------------------------------------------------------------------------------------------------------------------\n\nNHP-D (sequential)\t\t\t             263 +/- 7\t       221 +/- 10\t  867 +/- 31\t   954 +/- 29\n\nNHP-D (joint)\t\t\t\t            262 +/- 8\t        236 +/- 8\t  869 +/- 13\t   944 +/- 20\n\n---------------------------------------------------------------------------------------------------------------------------------\n\n\n\nOn variance in the results:\nWe observed variances of AUC values to be in the third decimal places (i.e., very close to zero). We have reported variances in the number of hyperlinks recovered in all experiments. These are much more interpretable/statistically significant. \n\n\n\nOn 10 trials:\nWe report the mean values over 10 different splits of train and test. \n\n\n\nOn random features:\nThe feature initialisations are random for metabolic network experiments as we do not have any available features to exploit. We believe the neighbourhood feature aggregation of GCN causes useful node embeddings to be learnt during training.\nWe also observe that NHP is competitive with a node2vec baseline (suggested by reviewer 3) which is a featureless approach. \n\n\n\nOn creation of fake papers:\nIn these experiments, authors correspond to nodes in the (primal) graph, while papers correspond to hyperlinks, i.e., sets of authors. So in this context, fake papers are the same as fake author lists and hence cannot be attached to existing (true) papers. The set of candidate edges is the set of true papers union the set of fake papers.", "title": "Our response to major comments of AnonReviewer1"}, "BJenCQzNaX": {"type": "rebuttal", "replyto": "r1x10QuUhm", "comment": "Thanks for the review. \n\nOn the novelty of our work:\nLink prediction in undirected hypergraphs is an underexplored problem and that in directed hypergraphs is an unexplored problem. Our main contribution is a unified framework for both the settings and our proposed solution is conceptually simple, yet effective. We believe the problem settings are important and interesting (as noted by the other reviewers too), and that this paper will inspire further research in this direction.\n\n\n\nOn adding an extra term to CMM as a baseline for directed hyperlink experiments:\nFollowing the reviewer\u2019s suggestion, we have added CMM + MLP as a baseline. We have also compared NHP against node2vec + MLP and star expansion + MLP as suggested by reviewer #3. We report below the number of reactions recovered in the directed hypergraph experiments. \n\n---------------------------------------------------------------------------------------------------------------------------------\n                            dataset\t\t\t\tiAF692\t         iHN637\t          iAF1260b          iJO1366\n---------------------------------------------------------------------------------------------------------------------------------\nnode2vec + MLP\t\t\t                      255 +/- 5\t         237 +/- 5\t  838 +/- 13\t   902 +/- 11\n---------------------------------------------------------------------------------------------------------------------------------\nCMM + MLP    \t\t\t                     253 +/- 9\t        241 +/- 11\t  757 +/- 26\t   848 +/- 21\n---------------------------------------------------------------------------------------------------------------------------------\nGCN on star expansion + MLP\t             242 +/- 5\t        241 +/- 10\t   786 +/- 13\t   852 +/- 11\n---------------------------------------------------------------------------------------------------------------------------------\n\nNHP-D (sequential)\t\t\t             263 +/- 7\t       221 +/- 10\t  867 +/- 31\t   954 +/- 29\n\nNHP-D (joint)\t\t\t\t            262 +/- 8\t        236 +/- 8\t  869 +/- 13\t   944 +/- 20\n\n---------------------------------------------------------------------------------------------------------------------------------\nWe request the reviewer to see the updated paper for AUC numbers. We have also observed that NHP-U outperforms all its baselines in the undirected experiments and the results have been updated in our paper.\n\n\n\nOn candidate papers in coauthorship networks such as cora:\nThe standard cora dataset has 2708 papers. We sampled an equal number of fake papers at random to get the 5416 candidate papers for cora. We request the reviewer to see the appendix for more details.\n\n\n\nOn comparison with Lugo-Martinez and Radivojac, 2017:\nWe had difficulty reproducing the results, given that the code was not available and the authors did not respond to our request emails, and the method as described in the paper is rather vague about the details.", "title": "Our response to AnonReviewer2"}, "SJxfTVfNpQ": {"type": "rebuttal", "replyto": "HJxLFwebh7", "comment": "Thanks for the review. \n\nOn the novelty of our work:\nLink prediction in undirected hypergraphs is an underexplored problem and that in directed hypergraphs is an unexplored problem. Our main contribution is a unified framework for both the settings and our proposed solution is conceptually simple, yet effective. We believe the problem settings are important and interesting (as noted by the other reviewers too), and that this paper will inspire further research in this direction.\n\n\n\nOn comparison with PinSage [Ying et al. KDD 2018]:\nPinSage has been designed to work on the bipartite graph of Pinterest. The Pinterest graph can be seen as the star expansion of a hypergraph with pins (hypernodes) on one side of the partition and boards (hyperlinks) on the other side. Following the reviewer\u2019s suggestion, we have compared NHP against star expansion below.\n\n\n\nOn comparison with node2vec:\nFollowing the reviewer\u2019s suggestion, we have compared NHP against node2vec. Node2vec has been shown to be superior to DeepWalk and LINE in [Grover et al. KDD 2016] and hence we have compared only against it. We have also compared NHP against CMM+MLP as suggested by reviewer #2. We report only the number of reactions recovered in the undirected hypergraph experiments.\n\n-----------------------------------------------------------------------------------------------------------------------------------\ndataset\t\t\t\t  \t       iAF692\t           iHN637\t               iAF1260b\t              iJO1366\n-----------------------------------------------------------------------------------------------------------------------------------\nnode2vec \t\t\t\t     299 +/- 10\t          303 +/- 4\t     1100 +/- 13\t          1221 +/- 21\n-----------------------------------------------------------------------------------------------------------------------------------\nGCN on star expansion\t            174 +/- 5\t         219 +/- 12\t      649 +/- 10\t           568 +/- 18\n-----------------------------------------------------------------------------------------------------------------------------------\nNHP-U (ours)\t\t\t            313 +/- 6\t          360 +/- 5\t     1258 +/- 9\t           1381 +/- 9\n-----------------------------------------------------------------------------------------------------------------------------------\n\nWe request the reviewer to see the updated paper for AUC numbers. We have updated the results for all the other datasets and experiments and we request the reviewer to see the paper.\n\nFrom the table above, we can see that the star expansion of a hypergraph is less effective because there are no direct connections between chemical reactions (because the graph is bipartite). Clique expansion, on the other hand, connects two chemical reactions if they share a chemical substance and hence can exploit the relationships much better.\n\n\n\nOn the size of the datasets used:\nOur work was motivated by the task of predicting reactions, for which we used datasets already available in the literature (given by Zhang et. al, AAAI 2018). Regarding the co-authorship datasets used, we had to filter the large datasets already available to ensure that meaningful hyperlinks were obtained which led to some reduction in size. We request the reviewer to take a look at the appendix for the exact details.\n\n\n\nOn simultaneous learning of node and edge embeddings:\nNHP, our proposed method, learns node embeddings in the dual hypergraph which is the same as learning hyperlink embeddings in the primal.  While PinSage works on the Pinterest bipartite graph (star expansion) and hence involves simultaneous learning of node/edge embeddings, NHP works on the clique expansion and learns node embeddings of the dual.", "title": "Our response to AnonReviewer3"}, "r1xcxV_4R7": {"type": "rebuttal", "replyto": "B1xL2zM4pX", "comment": "On comparisons with random negative sampling:\nBelow, we have compared our strategy of positive-unlabeled learning against uniform random negative sampling.  \n-------------------------------------------------------------------------------------------------------------------------\n                  dataset                           iAF692        iHN637           iAF1260b          iJO1366\n-------------------------------------------------------------------------------------------------------------------------\nrandom negative sampling        236 +/- 32     415 +/- 47     967 +/- 125     1074 +/- 168\n-------------------------------------------------------------------------------------------------------------------------\npositive-unlabeled learning         313 +/- 6     360 +/- 5        1258 +/- 9         1381 +/- 9\n-------------------------------------------------------------------------------------------------------------------------\n\nAs can be seen from the table, the standard deviations of random negative sampling are on the higher side. This is expected as the particular choice made for negative samples decides the decision boundary for the binary classifier.\n\nWe request the reviewer to see the updated paper for AUC numbers and a discussion around these results in the updated section 7 of our paper. \n\n\n\nOn adding Recall@$\\Delta E$ in tables:\nWe have added recall@$\\Delta E$ of NHP for all datasets in both undirected and directed hypergraph experiments in our updated paper. We have retained the raw hyperlinks recovered as they contain standard deviations in addition to mean values.\n\n\n\nOn the arXiv submission 1809.09401:\nThe submission uses the clique expansion to approximate the hypergraph which is similar to our work. We have cited the submission in our updated paper. However, it does not use the dual hypergraph idea nor any negative sampling technique. \n\n\n\nOn connecting experimental results and dataset sizes/densities:\nWe cannot draw general conclusions connecting results and dataset sizes/densities. In general we observe that NHP outperforms the baselines because the graph convolutional network is tailor-made for semi-supervised learning with small amounts of labeled data (10% in our experiments).\n", "title": "Our response to minor comments of AnonReviewer1"}, "S1xMYoWc2Q": {"type": "review", "replyto": "ryeaZhRqFm", "review": "[Relevance] Is this paper relevant to the ICLR audience? yes\n\n[Significance] Are the results significant? somewhat\n\n[Novelty] Are the problems or approaches novel? rather incremental\n\n[Soundness] Is the paper technically sound? yes\n\n[Evaluation] Are claims well-supported by theoretical analysis or experimental results? marginal\n\n[Clarity] Is the paper well-organized and clearly written? okay\n\nConfidence: 2/5\n\nSeen submission posted elsewhere: No\n\nDetailed comments:\n\nIn this work, the authors propose an approach to the (hyper-) link prediction problem in both directed and undirected hypergraphs. The approach first applies an existing dual transformation to the hypergraph such that the link prediction problem (in the primal) becomes a node classification problem in the dual. They then use GCNs to classify the (dual) nodes. Experimentally, the proposed approach marginally outperforms existing approaches.\n\n=== Major comments\n\nI found the novelty of the proposed approach rather limited. The proposed approach essentially just concatenates three existing strategies (dual reformulation from Scheinerman and Ullman, GCNs from Kipf and Welling, and negative sampling which is common in many communities, e.g., Han and Chen, but many others, as well). I believe the contribution for link prediction in directed hypergraphs is a more novel contribution, however, I had difficulty following that discussion.\n\nIt is difficult to interpret the experimental results. Tables 3 and 6 do not include a measure of variance. Thus, it is not clear if any of the results are statistically significant. It is also not clear whether the \u201c10 trials\u201d mentioned in the figure captions correspond to a 10-fold cross-validation scheme or something else. It is unclear to me what the random feature matrix for the metabolic network is supposed to me or do. It is also unclear to me why \u201cfake papers\u201d are needed for the citation networks; it is clear that \u201cfake author lists\u201d are needed for negative sampling, but it seems they could be attached to existing papers. Similarly, it is unclear how the set of candidate edges (\\mathcal{E}) was chosen.\n\nI appreciate that the authors made the code available. I did not run it, but I did have a look, and I believe it could be adapted by others without an unreasonable amount of work.\n\n=== Minor comments\n\nThis work is very similar to the arXiv submission 1809.09401. To the best of my knowledge, though, that work has not yet been published in a peer-reviewed venue, so I do not consider it a problem that it is not cited here.\n\nAccording to Tables 1 and 2, iAF692 and iHN637 datasets are smaller than the other datasets except DBLP; those two are also less dense than DBLP. According to Table 3, NHP-U seems noticeably better than SHC and CMM on the, while does not appear very significant in the other cases. Is there some relationship between NHP\u2019s performance and the size/density of the graph? or is there some other explanation for this behavior?\n\nRelated to the above point, Table 3 shows that the performance on the undirected versions for those two datasets is better than on the other two metabolic networks, while Table 6 shows the opposite for the directed versions. Is there some explanation for this? For example, are there qualitative differences in the size of the hypernodes?\n\nThe described strategy for negative sampling seems as though it selects \u201ceasy\u201d negative samples, in the sense that they are far away from observed positives; thus, they are also likely far away from any sort of decision boundary. How does the performance change if more \u201cdifficult\u201d (or just uniformly random) negative samples are chosen?\n\nI believe Recall@100 (or Precision@100, or @$\\Delta E$, etc.) is a more meaningful value to report in Tables 4 and 7, rather than the raw number of edges. That is, it would be more helpful to report something so that numbers across datasets are at least somewhat comparable.\n\n=== Typos, etc.\n\nIn Equation (4), the \u201ck\u201d index in d_{ijk} is in {1,2}, but in the text, it is in {0,1}.\n\n\u201ctable 2\u201d -> \u201cTable 2\u201d, and many other similar examples throughout the paper.\n\n\u201chigher-order etc.\u201d -> \u201chigher-order, etc.\u201d\n\u201cGCN based\u201d -> \u201cGCN-based\u201d, and similar in several places in the paper\n\u201ca incomplete\u201d -> \u201can incomplete\u201d\n", "title": "Interesting problem, but incremental contribution", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "r1x10QuUhm": {"type": "review", "replyto": "ryeaZhRqFm", "review": "This paper proposed Neural Hyperlink Predictor (NHP) to perform link prediction based on graph convolutional network (GCN). Following prior work, the hyperlink prediction is perform in the dual hypergraph, where each node represents a hyperlink in the primal hypergraph. The original problem is then equivalent to a simple node classification problem. To deal with directed hyperlink, a separate term is added to distinguish heads from tails.\n\nThe problem of link prediction in hypergraph is important and interesting, especially in the chemistry domain. However from the technical point of view, this work is somewhat incremental since prior work has done link prediction using GCN (Zhang and Chen, 2018). The idea of performing hyperlink prediction in the dual hypergraph is not new, either (Lugo-Martinez and Radivojac, 2017). As for the directed hypergraph setting, it seems to be a straightforward extension once one knows how to do in the undirected setting (adding an extra term to classify head/tail).\n\nIn terms of experiments, given the similarity between Lugo-Martinez and Radivojac, 2017 and NHP (both operates in the dual hypergraph), it would be better if the former could also be used as a baseline, as least in the undirected setting.\n\nIt is reasonable to have a subset of links as candidate reactions in the metoboli network datasets. For CORA and DBLP, it is not clear where the \u2018actual papers\u2019 and \u2018candidate papers\u2019 come from. For example in CORA there are 1072 authors; yet there are only 5416 candidate papers.\n\nIt seems the joint learning of NHP-D does not improve the accuracy in the directed setting as claimed in Sec. 5.2. Besides, there is no baseline in the directed setting. It is difficult to appreciate the performance in Sec. 6. One thing one can do is to use previous methods in the undirected setting, e.g., CMM, with the extra term L_d in Eq. (4).\n\nMinor comments:\nTypo: \nP5: atleast -> at least\nP5: What is GCN 2?\nSec. 5: \u2018p = 32 in 1\u2019 and \u2018shown in 2\u2019\n\nMissing references on link prediction and/or deep learning:\nDiscriminative relational topic models. PAMI 2014.\nRelational deep learning: A deep latent variable model for link prediction. AAAI 2017\nNeural relational topic models for scientific article analysis. CIKM 2018.", "title": "Interesting and important problem; technical contribution is limited given existing work.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "HJxLFwebh7": {"type": "review", "replyto": "ryeaZhRqFm", "review": "This paper proposed to use graph convolutional neural networks for link prediction. The authors proposed to use the dual graph to simultaneously learn node and edge embeddings. The label of the edges (positive or negative) are used as supervised signal for training the GCNs. Experiments on a few small data set prove the effectiveness of the proposed approaches.\n\nStrength:\n- important problem\n\nWeakness:\n- the novelty of the proposed method is very marginal\n- the experiments are quite weak\n\nDetails:\n- the novelty of the proposed method seems to be very marginal, which simply applies the GCN for link prediction. The existing GCN based method for recommendation shares similar ideas (e.g., Yin et al. 2018, PinSage), though dual hypergraph is not used. But the essential idea is very similar. \n- the data sets used in the experiments are too small\n- the node embedding based methods should be compared for link prediction, e.g., DeepWalk, LINE, and node2vec.\n", "title": "Novelty of the proposed method is very marginal", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}}