{"paper": {"title": "How Important is a Neuron", "authors": ["Kedar Dhamdhere", "Mukund Sundararajan", "Qiqi Yan"], "authorids": ["kedar@google.com", "mukunds@google.com", "qiqiyan@google.com"], "summary": "", "abstract": "The problem of attributing a deep network\u2019s prediction to its input/base features is\nwell-studied (cf. Simonyan et al. (2013)). We introduce the notion of conductance\nto extend the notion of attribution to understanding the importance of hidden units.\nInformally, the conductance of a hidden unit of a deep network is the flow of attribution\nvia this hidden unit. We can use conductance to understand the importance of\na hidden unit to the prediction for a specific input, or over a set of inputs. We justify\nconductance in multiple ways via a qualitative comparison with other methods,\nvia some axiomatic results, and via an empirical evaluation based on a feature\nselection task. The empirical evaluations are done using the Inception network\nover ImageNet data, and a convolutinal network over text data. In both cases, we\ndemonstrate the effectiveness of conductance in identifying interesting insights\nabout the internal workings of these networks.", "keywords": ["attribution", "saliency", "influence"]}, "meta": {"decision": "Accept (Poster)", "comment": "This paper proposes a new measure to quantify the contribution of an individual neuron within a deep neural network. Interpretability and better understanding of the inner workings of neural networks are important questions, and all reviewers agree that this work is contributing an interesting approach and results."}, "review": {"Hye5Y6SQR7": {"type": "rebuttal", "replyto": "BkxH95gchQ", "comment": "We thank the reviewer for their review. The reviewer notes the need to emphasize how and why to use this approach. In the new revision, we have added a discussion section to make a case for this. We will publish the code to compute conductance after the blind-review phase.\n\nThe reviewer also mentioned that the paper doesn\u2019t compare directly against various attribution methods. For this, we refer the reviewer to our response for the comment by anonymous.\n", "title": "Response to reviewer 1"}, "SJeVPpHQA7": {"type": "rebuttal", "replyto": "HJxwToa927", "comment": "We thank the reviewer for a detailed review. We agree with the reviewer that a uniqueness result based on the axioms is desirable, but we don\u2019t have it. While we\u2019re able to show that the paths at the input and at the hidden layer must be coupled (i.e. non-oblivious), we just don\u2019t understand the space of non-oblivious methods that well. Mathematically, we don\u2019t have a handle on how the path at the hidden layer can vary as the network below the hidden layer is changed. Partition consistency is the only axiom about the network below the hidden layer, but it is not applicable to all networks. We probably need another axiom to prove uniqueness.\n\nAnother key observation made by the reviewer is the interpretability vs importance of neurons. While those are not the same, we demonstrate that conductance can give us some insights about the network (Sections 5.1 and 6.1).\n", "title": "Response to reviewer 2"}, "SyxMr6SmRQ": {"type": "rebuttal", "replyto": "BkeBNXOJT7", "comment": "We thank the reviewer for a detailed review. We have implemented the suggestions for improving clarity. \n\nRegarding our use of \u2018axioms\u2019: We follow the economics literature in using axioms as normative concepts, i.e., to denote desirable properties that a neuron importance methods.  And not the use in the mathematical literature, which is to denote statements that are self-evidently true. We have clarified this in the submission.\n", "title": "Response to reviewer 3"}, "r1eKZaBmAX": {"type": "rebuttal", "replyto": "H1xmAiWo6Q", "comment": "We thank the anonymous commentator and reviewer #3 for the critiques about benchmarks.\nWe respond to the two types of issues with our comparisons:\n\n(a) Comparing against other methods: We chose our benchmarks to be published techniques of neuron importance. In this sense, we certainly make no effort to cherry pick. However, we do agree with the observation that methods such as LRP, DeepLift, DeepShap could be used as measures of neuron importance, though they have not been proposed for this purpose.\n\nTo partially address this, we performed a new theoretical analysis of DeepShap/LRP (see Appendix 8.2 and Section  4.1.) . We find that the importance measures from these methods have an intuitively undesirable dependence on the \u201cimplementation\u201d of the network. That is,  you can vary the network architecture in a way that neuron computes the very same function, but the feature importance changes. \n\n(b) Evaluating on different tasks: First, we should point out that we do have a quantitative analysis on *both the text task and the image one. (see sections 5.2 and 6.2).  We also have qualitative insights on both tasks (Sections 5.1 and 6.1). It is also true that sections 6.1 and 6.2 are not quite the same task. But this was mostly to make a quantitative eval of feature selection possible. Finally, note that we picked two large-scale, practically applied networks. Not MNIST and not some toy task.\n\nThat said, we do agree with Reviewer #3 that the empirical evaluations are not strong proof of generality. Hopefully our theoretical arguments compensate for this. As we all know, there is no natural ground truth for judging attribution or neuron importance. So almost every empirical evaluation of attribution has some issue. But all in all, we do agree there is room for more empirical evaluation.\n", "title": "Clarification on baselines"}, "BkeBNXOJT7": {"type": "review", "replyto": "SylKoo0cKm", "review": "This paper presents a new method to measure the importance of hidden neurons in deep neural networks. The method integrates notions of activation value, input influence to a neuron and neuron influence to the network's output. They provide results confirming that this measure is able to identify neurons that are important for specific tasks.\n\nQuality\n\nThe experiments are well designed to verify their hypothesis, although there could be more to make sure those results are not particular to the few selected problems. Nevertheless, the results are consistent across those experiments.\n\nClarity\n\nThe text is well written in general, but the structure could be improved. The introduction contains too much related work, which should be divided in another section. Section 2 contains mostly high level explanations of the work, which should be integrated in the introduction, and thus before the related work section, to improve readability. See minor comments for more specific suggestions.\n\nIt is difficult to understand the goal of Section 4.2. Section 2 states that section 4.2 proves that a \"path method\" must be used in order to satisfy the axioms, but why such axioms are important is not stressed enough. Also, it is not clear why those are called axioms since they are not use to build anything else. It seems to me that those are rather \"desirable properties\" than axioms.\n\nOriginality\n\nA important number of related works are cited and compared with the current work. Although the proposed measure is close to what is proposed by Datta et al., this paper makes the distinction clear and benchmarks its results properly against it.\n\nSignificance\n\nThere is an increasing need to interpretability of deep neural networks as they get more and more applied to real-world problems. Measures as the one proposed in this paper are a very important building block towards this.\n\nConclusion\n\nFor its original importance measure and the proper experiment benchmarks, I believe this paper should be accepted. There is however many minor issues that should be fixed for the camera-ready version. Although the recommended length is 8 pages, the strict limit is 10, so I would recommended to use a bit of the remaining extra space to conclude the paper properly with a discussion on the results and their consequences, as well as a conclusion to wrap up the paper.\n\n***\n\nMinor Comments\n\nIntroduction:\n- The term flow is never defined precisely, we need to infer it based on the definition of conductance and attribution.\n- First paragraph would be more clear with simple word explanation rather than maths. Also, second sentence is not a complete sentence\n- Work on image indicators of importance could be compared better with current work. Indicators can be seen as a measure of importance.\n- This sentence is not clear: \"[...]; the nature of correlations in the two models may differ\".\n\nSection 2:\n- Last paragraph of section 2 can be true for any well-performing importance measure. The statements should be put in perspective with others.\n\nSection 3:\n- Section 3 should be introduced by explaining the goal of the section otherwise it breaks the flow of reading.\n- The role of the baseline x' should be better explained when it is presented (first paragraph of section 3).\n- The interchangeable use of the term \"conductance of neuron j\" for equations 2 and 3 is confusing. Different terms should be use, even if the context makes it possible to infer which one is being referred to.\n- Remark 1 seems trivial, but the selection of baseline x' seems less trivial. Some explanations should be devoted to it.\n- Second paragraph of remark 1 is not clear. Why couldn't we take another layer's neuron as the neuron of interest, bounding the conductance measure on one layer as the input and the output of the model? If we make the input to be a neuron y rather than the true input x, we could take another neuron z in a subsequent layer to be the neuron of interest, resulting in conductance measure Cond^z_i(y).\n\nSection 4:\n- List of importance measure at beginning of Section 4 should probably have citations.\n- Backward reference to section 3 seems to be a mistake, should it be subsection 4.2?\n- Each of the justifications to get around the issue of distinguishing strange model behavior from bad feature importance technique should be explained briefly in paragraph before section 4.1.\n\nSubsection 4.1:\n- I do not understand the problem explained in fourth paragraph of section 4.1. g(f(1 - epsilon)) = 0, why would it be 1- epsilon?\n- Problem explained in fifth Paragraph of section is not clear unless what the influence of the unit is clearly stated. Is it simply dg/df? \n- A short explanation of what is tested in section 6 should be given at last paragraph of section 4.1. Although the results are favorable to the conductance metric, it is not clear how they precisely confirm the problem of incorrect signs presented in the caricature examples.\n\nSubsection 4.2:\n- As said in the my main comments, I am not convinced by the use of the term Axiom. They are not use as building blocks, and are rather used as desirable properties for which the authors prove that only \"path methods\" can satisfy.\n- Footnote 2 on page 5 it difficult to read.\n- Although the proof does not seem to use the axioms as a building block, which is fortunate since it would make it a circular argument otherwise, the text suggests so: \"Given these three axioms, we can show that:\".\n- The importance of section 4.2 should be clarified. More emphasis on the importance of the axioms (desirable properties) should be made.\n\nSection 5:\n- Choices for experiments should be explained. Why choosing layers mixed** rather than others? Why choosing filters?\n- Figures 1-4 are difficult to interpreted on a printed version. Since this is qualitative, I suggest to change the saturation of the images to make them easier to interpret. The absolute values are not important for a qualitative interpretation\n- Figure 4 could be more interesting if compared with other classes, like other animal faces. Anyhow, I understand that those were chosen based on the subset of classes used for the experiments.\n- Space should be added between figures to better divide the captions\n\nSection 6:\n- The difference between experiments of Figure 5 and 6 should be made more clear.\n\nSection 7-8:\n- Where are they? No discussion? No conclusion?", "title": "An important measure of Neuron Importance", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "HJxwToa927": {"type": "review", "replyto": "SylKoo0cKm", "review": "The authors propose a notion of conductance to attribute the deep neural network\u2019s prediction to its hidden units. The conductance is the flow of attribution via the hidden unit(s) in consideration. The paper proposes using conductance to not only evaluate importance of hidden unit to the prediction for a specific input but also over a set of inputs. The strongest part of the analysis of conductance is that conductance naturally couples  the path at the base features with that of the hidden layer.\n\nThe authors position their work well within the existing approaches in the community and generalizes the efficient use of measuring hidden activation wrt to specific input or set of inputs.\n\nThe analysis makes efficient use of mean value theorem in the context of  parametrization of the loss function.\n\nConductance seems to satisfy the completeness of hidden features. Further, it also satisfies the layer-wise conservation principle with the outputs completely redistributed  to the inputs.\n\nIt would be good to see more analysis on the axioms 1 through to 4 for the sake of completeness in the light of partial axiomatization of conductance.\n\nThe authors provide empirical evaluation of conductance over a variety of tasks. It would be good to see some more insight in order to relate to interpretability of the importance of neurons, although there has been no claims made on it as its hard to measure importance without interpretability.\n", "title": "Requested minor clarifications.", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "BkxH95gchQ": {"type": "review", "replyto": "SylKoo0cKm", "review": "The idea is nice. It is well aligned with tools that are needed to understand neural networks. However, the experiments feel like they are missing motivation as to why this method is being used. The paper does not provide very significant evidence that this method is useful. The negation example is nice but this doesn't seem to display the potential power of the method to understand a neural network.\n\nMore motivation for experimental section is needed. If the authors don't discuss a motivation then how will a reader know how to apply the tool? It seems there is no conclusion to take away from the experiments in section 5 (convolutions). \n\nThe authors should rethink the structure of the experimental section from the standpoint of convincing someone to use this method. In section 4.1 the authors have a good discussion on what is wrong with other methods in order to motivate their approach but then they don't deliver significant evidence in the later part of the section.\n\nThe paper needs more discussion and experiments to explain how and why to use this approach. \n\nWhile the authors say \"attributing a deep network\u2019s prediction to its input is well-studied\" they don't compare directly against these methods. \n\nThere are many typos and grammar errors\n\nWhile I think the paper could be much more impactful if the experimental section was greatly reworked; I believe the first 5 pages of the paper are a very good contribution and it should be accepted.\n", "title": "Could use more motivation but it is a good concept.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "SJe-HDDIn7": {"type": "rebuttal", "replyto": "BJgv0O6Snm", "comment": "First a word of caution for the reviewers: looking up the references mentioned below or in Avanti's remark or what follows will implicitly violate review blindness.\n\nAvanti's comment is partly about a prior version of this work on arxiv. That prior version contained a comment about inefficiency of computing all conductances in a given layer. Our implementation in tensorflow involved adding several gradient operators for this. Any implementation of that requires either doing a sequence of backprop/gradient operations (time inefficiency) or computing Jacobians (space inefficiency). The work by Shrikumar, Su & Kundaje did not address this inefficiency. Instead that work proposed a method similar to Remark 1 in our current submission. We will add a citation to that effect. However, as explained in Remark 1, it lacks an analogue to Equation 2.", "title": "Clarification on the missing citation"}}}