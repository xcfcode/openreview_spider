{"paper": {"title": "Behaviour Suite for Reinforcement Learning", "authors": ["Ian Osband", "Yotam Doron", "Matteo Hessel", "John Aslanides", "Eren Sezener", "Andre Saraiva", "Katrina McKinney", "Tor Lattimore", "Csaba Szepesvari", "Satinder Singh", "Benjamin Van Roy", "Richard Sutton", "David Silver", "Hado Van Hasselt"], "authorids": ["ian.osband@gmail.com", "ydoron@google.com", "mtthss@google.com", "jaslanides@google.com", "esezener@google.com", "andresnds@google.com", "mckinneyk@google.com", "lattimore@google.com", "szepi@google.com", "baveja@google.com", "benvanroy@google.com", "suttonr@google.com", "davidsilver@google.com", "hado@google.com"], "summary": "Bsuite is a collection of carefully-designed experiments that investigate the core capabilities of RL agents.", "abstract": "This paper introduces the Behaviour Suite for Reinforcement Learning, or bsuite for short. bsuite is a collection of carefully-designed experiments that investigate core capabilities of reinforcement learning (RL) agents with two objectives. First, to collect clear, informative and scalable problems that capture key issues in the design of general and efficient learning algorithms. Second, to study agent behaviour through their performance on these shared benchmarks. To complement this effort, we open source this http URL, which automates evaluation and analysis of any agent on bsuite. This library facilitates reproducible and accessible research on the core issues in RL, and ultimately the design of superior learning algorithms. Our code is Python, and easy to use within existing projects. We include examples with OpenAI Baselines, Dopamine as well as new reference implementations. Going forward, we hope to incorporate more excellent experiments from the research community, and commit to a periodic review of bsuite from a committee of prominent researchers.", "keywords": ["reinforcement learning", "benchmark", "core issues", "scalability", "reproducibility"]}, "meta": {"decision": "Accept (Spotlight)", "comment": "This paper proposes a platform for benchmarking and evaluating reinforcement learning algorithms.  While reviewers had some concerns about whether such a tool was necessary given existing tools, reviewers who interacted with the tool found it easy to use and useful. Making such tools is often an engineering task and rarely aligned with typical research value systems, despite potentially acting as a public good. The success or failure of similar tools rely on community acceptance and it is my belief that this tool surpasses the bar to be promoted to the community at a top tier venue.  "}, "review": {"SJgEVpbAFr": {"type": "review", "replyto": "rygf-kSYwH", "review": "This paper presents the \u00ab Behavior Suite for Reinforcement Learning \u00bb (bsuite), which is a set of RL tasks (called \u00ab experiments \u00bb) meant to evaluate an algorithm\u2019s ability to solve various key challenges in RL. Importantly, these experiments are designed to run fast enough that one can benchmark a new algorithm within a reasonable amount of time (and money). They can thus be seen as a \u00ab test suite \u00bb for RL, limited to small toy problems but very useful to efficiently debug RL algorithms and get an overview of some of their key properties. The paper describes the motivation behind bsuite, shows detailed results from some classical RL algorithms on a couple of experiments, and gives a high-level overview of how the code is structured.\n\nI really believe such a suite of RL tasks can indeed be extremely useful to RL researchers developing new algorithms, and as a result I would like to encourage this initiative and see it published at ICLR to help it gain additional traction within the RL community.\n\nThe paper is easy to read, motivates well the reasons behind bsuite, and shows some convincing examples. However, in my opinion there remain a few important issues with this submission:\n\n1.\tThere is no \u00ab related work \u00bb section to position bsuite within the landscape of RL benchmarks (ex: DMLab, ALE / MinAtar, MuJoCo tasks, etc.). I believe it is important to add one.\n\n2.\tThe current collection of experiments appears to be quite limited. The authors acknowledge the lack of hierarchical RL, but what about other aspects like continuous control, parameterized actions, multi-agent, state representation learning, continual learning, transfer learning, imitation learning / inverse RL, self-play, etc? It is unclear to me whether the goal is to grow bsuite in all these directions (and more) over time, or if there is some kind of \u00ab boundary \u00bb the authors have in mind regarding the scope of bsuite. Regardless, the fact is that in its current form, bsuite appears to be suited only to a limited subset of current RL research.\n\n3.\tI wish an anonymized version of the code had been provided, so that reviewers could test it. In particular I wonder (a) if it is easy to setup and run under Windows, and (b) if it is straighforward to plug a bsuite experiment within an algorithm based on the popular OpenAI gym API (I think the latter is true from what is said at the end of Section 4, but I would have appreciated being able to try it out myself).\n\nAdditional minor remarks:\n\u2022\tI noticed two anoymity-related issues with the provided links: (1) the Google Colab notebook revealed to me the name of its author when clicking the \u00ab Open in Playground \u00bb link to be able to run it, and (2) the bsuite-tutorial link asks for permission, which might let the authors access reviewer info. I would not hold it against the authors though as I believe these are genuine mistakes and they did their best to preserve anonymity.\n\u2022\tt > 2 in Section 2.1 should probably be t >= 2\n\u2022\tIn FIg. 2b the label for the y axis seems incorrect since good results are near 0\n\u2022\tPlease explain what is the dashed grey line in Fig. 4b\n\u2022\tI was unable to understand the last 2 sentences of Section 4\n\u2022\tSections C.2, D.2 and E.2 all have the same plots\n\u2022\tA few typos: incomplete sentence near bottom of p.3 (\u00ab the internal workings\u2026 \u00bb), \u00ab These assessment \u00bb, \u00ab expeirments \u00bb, \u00ab recurrant \u00bb, \u00ab length ? 1 \u00bb, \u00ab together with an analysis parses this data \u00bb, \u00ab anonimize \u00bb, \u00ab bsuite environments by implementing \u00bb, \u00ab even if require \u00bb\n\nReview update: the authors have addressed my concerns, and I look forward to using bsuite in my research => review score increased to \"Accept\"", "title": "Official Blind Review #2", "rating": "8: Accept", "confidence": 2}, "BJx_KB2tiH": {"type": "rebuttal", "replyto": "rygf-kSYwH", "comment": "Once again, we would like to thank the reviewers for their efforts and help in improving this paper.\n\nDuring the review process we have:\n\n1) Added an explicit related work section, which clarifies the position of bsuite with respect to prior work, and the novelty in this project.\n2) Clarified links to the opensource code, which reviewers have agreed is generally of high quality.\n3) Made the connections between theory and practice more explicit, together with surfacing the \"example reports\" more clearly in Section 3.\n\nOverall, although there is still one reviewer who tends towards rejection, even that reviewer says:\n- The paper is well written, easy to understand. \n- Provide an industry level code base that can be used efficiently and easily.\n- The project will be of great value to the research community in the near future.\n\nWe hope that following our productive discussion with reviewers, together with clarifications on the novelty of this project, that this means the positive aspects of the project shine through enough to recommend acceptance.\n\nMany thanks\n\n ", "title": "Review summary + thanks to the reviewers"}, "H1xBKQnFor": {"type": "rebuttal", "replyto": "HyxWDXpLsH", "comment": "Thank you again for your engagement.\n\n## Examples of bsuite for diagnosis\n\nMy belief is that we have already included three separate examples of how to use bsuite for diagnosis in Appendices C,D,E\n\n  C - A comparison of DQN, Actor Critic RNN, Bootstrapped DQN and Random agent\n  D - A comparison of \"optimizer\" algorithm in DQN (SGD, Adam, RmsProp)\n  E - A comparsion of ensemble size in Bootstrapped DQN (size=1, 3, 10, 30)\n\nThese show how running on bsuite you can get a snapshot of the agent performance across these targeted dimensions.\nOther common examples would include \"reimplementing\" a baseline agent, and then trying to compare the performance that you would expect to obtain.\n\nAre there other types of examples that you feel we should include?\n\n\n## Opinionated statements\n\nWe believe that part of the value of this paper is in arguing for a principled, focused methodology for research into the core issues in RL research.\nIt is clear that this specific sentence was not successful in your review, so we are happy to remove it.\n\nMany thanks", "title": "Clarifying requests"}, "rJlY979dsS": {"type": "rebuttal", "replyto": "BkeF_Lt_jH", "comment": "We are very glad to hear that the scripts live up to your expectation!\n\nRegarding difficulties running code on Windows... my understanding is that this should not be the case... but obviously offering tech support via anonymous review is a difficult proposal.\n\nI think it's important to separate the core bsuite code, which should work just fine as you say via the pip install, from the \"baseline\" agents that are examples of specific agent implementations, but not core to anyone else using bsuite with their own working agent.\n\nBy default, installing via:\npip install -e bsuite/\nWill *not* include the baseline dependencies... this is a conscious choice since TF versioning/Sonnet can be difficult to manage.\n\nFor example  the agents implemented in Sonnet will not work on windows, but there is not much we can do about that:\nhttps://github.com/deepmind/sonnet/issues/18\n\nIf you have a working implementation of an agent, hopefully the example scripts show that it can be very simple to plug this agent into bsuite.\nIf you are on Windows and really want to use our baseline agents, we do provide colabs that can allow you to run this without installing anything on your local machine... so maybe that is an option?\n\n\nOverall, we are really glad that you are engaging with this effort and hope that we can continue to make the user experience even more seemless.\nHopefully these aspects of the paper will make you keen to recommend our acceptance, either through raising your score, or pushing for acceptance in the post-rebuttal stage.\n\nMany thanks!\n", "title": "Windows support + \"baselines\" vs bsuite"}, "rJxjmH6otS": {"type": "review", "replyto": "rygf-kSYwH", "review": "In this paper, the authors propose a set of benchmarks for evaluating different aspects of reinforcement learning algorithms such as generalisation, exploration, and memory. The aim is to provide a set of simple environments to better understand the RL algorithms and also to provide a set of scores that summarise the performance in each respect. The code of the benchmark is also released.\n \nThe paper is well written and clear, and generally can provide a useful contribution. In particular, I like the idea of having a set of benchmarks which can be used for the diagnosis of RL algorithms. Having said this, I have the following concerns which are mostly related to the presentation of the paper. Given clarifications in an author response, I would be willing to increase the score. \n\n- Based on section 1.1 and elsewhere, it seems that the main driver for developing this benchmark has been connecting theory to practical algorithms (which in my opinion is an important step). However, how this can be achieved using the proposed benchmark is not shown in the paper. This can be for example showing how the generalisation score proposed here is linked to theoretical accounts. Or for example in section 2.1, by showing that the memory length 30 for RNN is related to the theoretical expectations. Alternatively, if linking theory and experiments is not the main driver of this work, then it seems a bit unclear what the point of presenting section 1.1 (and other related discussions) is within the context of the paper.\n\n- In terms of novelty, currently the differences between the current work and previous attempts to develop benchmarks is unclear (some examples are mentioned below). In general, a related work section is vital here, but missing in the paper. It should clearly state what the previous attempts in developing benchmarks are, their shortcomings, and how the current work addresses them. \n\n- Some statements in the paper sound more like opinions (which I happen to agree with) rather than something being based on the results of the paper. For example, \"We should not turn away from deep RL just because our current theory is not yet developed\". It is unclear how this statement is related to the results obtained in this work.\n\n- In section 3, I would like to see some real examples in which bsuite can be used for diagnosis. I find this application of bsuite (diagnosis) very interesting, but as it stands section 3 is more like a tutorial rather than providing a concrete example.\n\n- There are some aspects of RL which are specific to certain classes of RL. For example, in model-based RL, aspects such as the dynamics bottleneck and the planning horizon dilemma have been previously looked at, but are not presented in bsuite. How do the authors envision incorporating such aspects into their framework?\n\nMinor:\n- \"anything for length \u00bf 1\" -> replace \u00bf\n\n- what is the dashed grey line in Fig 4b?\n\nReferences:\nDuan, Yan, et al. \"Benchmarking deep reinforcement learning for continuous control.\" International Conference on Machine Learning. 2016.\n\nBenchmarking Model-Based Reinforcement Learning, Wang et al, 2019.\n", "title": "Official Blind Review #3", "rating": "6: Weak Accept", "confidence": 2}, "H1l-LcTGjS": {"type": "rebuttal", "replyto": "r1xvfq6WiH", "comment": "To be more specific regarding examples of using OpenAI Gym or Dopamine Frameworks:\n\nOpenAI DQN:\nhttps://anonymous.4open.science/repository/0a9b6721-69c6-42d6-b587-401e0898bfc8/bsuite/baselines/openai_dqn/run.py\n\nOpenAI PPO:\nhttps://anonymous.4open.science/repository/0a9b6721-69c6-42d6-b587-401e0898bfc8/bsuite/baselines/openai_ppo/run.py\n\nDopamine DQN:\nhttps://anonymous.4open.science/repository/0a9b6721-69c6-42d6-b587-401e0898bfc8/bsuite/baselines/dopamine_dqn/run.py\n\n\nGetting set up on Windows should actually be very simple.\nWe also provide example launch scripts for running on Google Cloud in the README.md section \"Running experiments on Google Cloud Platform\"\n\nThe inlcluded scripts provide a step by step way to run any of our baseline agents immediately.\nThis means that it should be possible to prototype an agent in Colab, then run the whole sweep via GCP.\n\n\nMany thanks", "title": "Examples of code with OpenAI Gym + Dopamine"}, "BJl7GyRZsr": {"type": "rebuttal", "replyto": "B1gnI0T-iH", "comment": "(forgot to mention this above)\n\nWe hope that our revision + response is able to answer your concerns... or if not, please know that we are eager to do this in a secondary revision.\n\nIf it is enough, then we hope that you will be happy to upgrade your score.\n\nMany thanks", "title": "Updating review score"}, "B1gnI0T-iH": {"type": "rebuttal", "replyto": "rJxjmH6otS", "comment": "Thank you very much for your review, we hope our revision will address your concerns.\n\nQ1 - Relating performance to theoretical accounts\n\nWe have added a clarification that our RNN agent was implemented with backprop through time of exactly 30 timesteps, so that the sharp performance transition is exactly evidence of this theory <-> practice interplay.\nWe had intended to make this clear in the paper, but somehow had forgot to make this explicit.\n\nSimilarly, the results of 2.2 are designed to highlight the role of theory-inspired algorithms that outperform the 2^N bound for dithering approaches to exploration.\nWe have clarified the meaning of this dashed line at 2^N to try to make this interplay more clear.\n\n\nQ2 - Novelty\n\nBased on your feedback, we have added Section 1.4 on Related Work.\nHere we make a better effort to place bsuite in the context of other benchmarks in RL, and to highlight the specific novelty that we offer.\n\nWe believe The Behaviour Suite for Reinforcement Learning offers a complementary approach to existing benchmarks in RL, with several novel components:\n\n- bsuite experiments enforce a specific methodology for agent evaluation beyond just the environment definition.\nThis is crucial for scientific comparisons and something that has become a major problem for many benchmark suites (Section 2).\n\n- bsuite aims to isolate core capabilities with targeted `unit tests', rather than integrate general learning ability.\nOther benchmarks evolve by increasing complexity, bsuite aims to remove all confounds from the core agent capabilities of interest (Section 3).\n\n- bsuite experiments are designed with an emphasis on scalability rather than final performance.\nPrevious `unit tests' (such as `Taxi' or `RiverSwim') are of fixed size, bsuite experiments are specifically designed to vary the complexity smoothly (Section 2). \n\n- Our open source code has an extraordinary emphasis on the ease of use, and compatibility with RL agents not specifically designed for bsuite\nEvaluating an agent on bsuite is practical even for agents designed for a different benchmark (Section 4).\n\n\nQ3 - Opinionated statements\n\nWe agree that, at points, we are making an opinionated case for the value of a certain style of research.\nWe hope that we make this clear that it is meant as a *complementary* approach, and that this does not hurt the clarity of our message.\nIf there are particular lines you would prefer us to remove or rewrite (potentially that one you highlight) then we will be happy to do this.\n\n\nQ4 - Example analyses\n\nWe have included several example bsuite analyses but, in the interests of space, we have relegated these to the Appendices C,D,E.\n\nThese include:\n  C - A comparison of DQN, Actor Critic RNN, Bootstrapped DQN and Random agent\n  D - A comparison of \"optimizer\" algorithm in DQN (SGD, Adam, RmsProp)\n  E - A comparsion of ensemble size in Bootstrapped DQN (size=1, 3, 10, 30)\n\nWe hope that these can provide examples of how bsuite can drive interesting research.\nWe have edited the section to make these analyses more prominent.\n\n\nQ5 - Other aspects of RL\n\nIt is clear that our release of bsuite does not cover all the interesting questions in RL.\nOur aim is to set up a tool that covers *some* interesting diagnostic tools, with the aim of collecting as many as possible of the *best* experiments going forward.\n\nWe would love to incorporate excellent experiments that instatiate the dynamics bottleneck, planning horizon and more... we just write an excellent experiment that really measures this well.\nIf you, or anyone else, can submit this to the bsuite.committee@gmail.com (or even via github pull) then we would be able to incorporate this very easily.\n\n\nMinor:\nWe have taken these into account .\n\n\nMany thanks!", "title": "Thank you for your review: we hope our revision will address your concerns"}, "ryx14o6WoH": {"type": "rebuttal", "replyto": "rkxk2BR3YH", "comment": "Thank you very much for your review!\n\nBased on your feedback we have added Section 1.4, which outlines the relation to prior work more explicitly.\nWe also hope that this section makes the *novelty* of our project much more clear.\n\nWe believe The Behaviour Suite for Reinforcement Learning offers a complementary approach to existing benchmarks in RL, with several novel components:\n\n- bsuite experiments enforce a specific methodology for agent evaluation beyond just the environment definition.\nThis is crucial for scientific comparisons and something that has become a major problem for many benchmark suites (Section 2).\n\n- bsuite aims to isolate core capabilities with targeted `unit tests', rather than integrate general learning ability.\nOther benchmarks evolve by increasing complexity, bsuite aims to remove all confounds from the core agent capabilities of interest (Section 3).\n\n- bsuite experiments are designed with an emphasis on scalability rather than final performance.\nPrevious `unit tests' (such as `Taxi' or `RiverSwim') are of fixed size, bsuite experiments are specifically designed to vary the complexity smoothly (Section 2). \n\n- Our open source code has an extraordinary emphasis on the ease of use, and compatibility with RL agents not specifically designed for bsuite\nEvaluating an agent on bsuite is practical even for agents designed for a different benchmark (Section 4).\n\n\nOverall, we are delighted that you agree:\n- The paper is well written, easy to understand. \n- Provide an industry level code base that can be used efficiently and easily.\n- The project will be of great value to the research community in the near future.\n\nWe believe that, following the changes we have made to the paper, there might be good reason for you to change your review to an \"accept\".\n\nMany thanks\n", "title": "Thank you for your review: we hope that our revision will make the value proposition more clear"}, "r1xvfq6WiH": {"type": "rebuttal", "replyto": "SJgEVpbAFr", "comment": "We thank you for your time and comments.\nTo address your main concerns:\n\n\n1 - Related work\n\nThis was a clear omission in paper and we have now added a section 1.4 on related work that hopefully clarifies some of these issues.\nIf this discussion is still insufficient then we are absolutely happy to improve this further.\n\nOne small thing to note is that we want to emphasize these bsuite \"experiments\" (or tasks) are more than just the RL environment... since they include both the interaction and the analysis.\n\n\n2 - Limited scope\n\nWe hope to grow the bsuite to incorporate as many *excellent* experiments for core RL capabilities as possible.\nHowever,  we also anticipate that many of the most difficult problems in RL will remain too complex to distill to a simple bsuite example.\n\nOur goal is to collect the best simple, diagnostic tests of Core RL capabilities.\nAll of the examples that you list are potential candidates for inclusion *if* we can make an excellent experiment that captures some essence of that problem.\nHowever, we erred on the side of including *less* where we were unsure of whether we could really make an excellent bsuite experiment.\n\nHowever, even if the set of bsuite tasks remains relatively simple, it might still play a useful role in the *other* parts of RL research where we don't currently have good experiments.\nA researcher interested in multi-agent RL might still gain some value when running their agent on bsuite... even if it currently does not include a specifically multi-agent experiment.\n\n\n3 - Anonymized code\n\nWe actually submitted an anonymized version of the code together with the initial paper submission. It is linked at the top of this page:\nhttps://anonymous.4open.science/r/0a9b6721-69c6-42d6-b587-401e0898bfc8/\n\nThe confusion may have come from our paper where the link says \"github.com/anon/bsuite\" but actually clicking the link would also have taken you to that address.\n\nWe believe that you will find both the answers (a) and (b) to be positive.\n\n\nMinor remarks:\n- We have taken each of these into account and made appropriate changes to the paper\n\n- Fig 2b grey line represents a baseline 2^N learning time, or a baseline scaling for agents that do not perform deep exploration.\n\n- We rewrote the last sentences of Section 4. This may make more sense when looking at the code, where we have a more explicit example of asking for bsuite environments with custom OBSERVATION_SPEC.\n\n\nOverall we are happy that you agreed with us on the value of our submission.\nWe hope that, through our revision, we are able to satisfy your remaining concerns and convert your score to an \"accept\".\n\nMany thanks\n", "title": "Thank you for your review - we hope to address your main concerns with this revision"}, "rkxk2BR3YH": {"type": "review", "replyto": "rygf-kSYwH", "review": "Behaviour Suite for Reinforcement Learning\n\nIn this paper the authors provide a set of light-weighted but dedicated designed environments, so that researchers can use the environments as a quick indication of the ability of the proposed (or existing) algorithms.\nI think the paper is well-written, with the intuition clearly demonstrated.\n\nI tend to vote for rejection though, given that the novelty in the project is relatively limited.\nBut I believe in general it is a very valuable project that will be beneficial to future research and I would like to recommend for a workshop publication.\n\nPros:\n- The paper is well written, easy to understand. \n- Provide an industry level code base that can be used efficiently and easily.\nThe project will be of great value to the research community in the near future.\n\nCons:\n- The novelty of the project is relatively limited. \nThe proposed and implemented environments have been studied before.\n- No explicit conclusion from the evaluation.\n", "title": "Official Blind Review #1", "rating": "3: Weak Reject", "confidence": 4}}}