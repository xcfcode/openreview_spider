{"paper": {"title": "A Deep Learning Approach for Survival Clustering without End-of-life Signals", "authors": ["S Chandra Mouli", "Bruno Ribeiro", "Jennifer Neville"], "authorids": ["chandr@purdue.edu", "ribeiro@cs.purdue.edu", "neville@cs.purdue.edu"], "summary": "The goal of survival clustering is to map subjects into clusters. Without end-of-life signals, this is a challenging task. To address this task we propose a new loss function by modifying the Kuiper statistics.", "abstract": "The goal of survival clustering is to map subjects (e.g., users in a social network, patients in a medical study) to $K$ clusters ranging from low-risk to high-risk. Existing survival methods assume the presence of clear \\textit{end-of-life} signals or introduce them artificially using a pre-defined timeout. In this paper, we forego this assumption and introduce a loss function that differentiates between the empirical lifetime distributions of the clusters using a modified Kuiper statistic. We learn a deep neural network by optimizing this loss, that performs a soft clustering of users into survival groups. We apply our method to a social network dataset with over 1M subjects, and show significant improvement in C-index compared to alternatives.", "keywords": ["Survival Analysis", "Kuiper statistics", "model-free"]}, "meta": {"decision": "Reject", "comment": "The submission proposes a Kuiper statistic based loss function for survival clustering.  This loss function is applied to train a deep network.  Results are presented on a Friendster dataset.\n\nThis submission received borderline/mixed reviews.  The primary concerns were: justification of the Kuiper loss, lack of details of the experimental setup, writing style.  In the end, these concerns remain.\n\nOf particular importance is the justification and experimental validation of the Kuiper statistic.  Although it seems a reasonable choice, from the authors' response to R3: \"We now also report results for Kolmogorov-Smirnov loss. Although the difference in performance between the two loss functions is not significant in the Friendster dataset, Kuiper loss has higher statistical power in distinguishing distribution tails [Tygert 2010].\"  If this theoretical result from [Tygert 2010] is relevant, it should be possible to demonstrate this experimentally.  If such differences are irrelevant for the data of interest, the paper should perhaps be reframed with a better discussion of available statistics and literature (cf. Reviewer 2), and a more general presentation de-emphasizing modeling choices that may have limited practical relevance.\n"}, "review": {"ry3ETTtxG": {"type": "review", "replyto": "SJme6-ZR-", "review": "Pros:\nThe paper is a nice read, clearly written, and its originality is well stated by the authors, \u201caddressing the lifetime clustering problem without end-of-life signals for the first time\u201d. I do not feel experienced enough in the field to evaluate the significance of this work.\n\nThe approach proposed in the manuscript is mainly based on a newly-designed nonparametric loss function using the Kuiper statistic and uses a feed-forward neural network to optimize the loss function. This approach does challenge some traditional assumptions, such as the presence of end-of-life signals or the artificial defined timeouts. Instead of giving a clear end-of-life signal, the authors specify a probability of end-of-life that permits us to take into account the associated uncertainty. By analyzing a large-scale social network dataset, it is shown that the proposed method performs better on average than the other two traditional models.\n\nCons:       \nI think that the main drawback of the paper is that the structure of the neural network and the deep learning techniques used for optimizing the loss function are not explained in sufficient detail. ", "title": "This manuscript presents a novel approach to survival clustering and compares it with some competing models.  ", "rating": "6: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}, "HyM5JWhgG": {"type": "review", "replyto": "SJme6-ZR-", "review": "This paper discusses an application of survival analysis  in social networks.\n\nWhile the application area seems to be pertinent, the statistics as presented in this paper are suboptimal at best. There is no useful statistical setup described (what is random? etc etc), the interplay between censoring and end-of-life is left rather fuzzy, and mentioned clustering approaches are extensively studied in the statistical literature in so-called frailty analysis. The setting is also covered in statistics in the extensive literature on repeated measurements  and even time-series analysis. It's up to the authors discuss similarities and differences of results of the present approach and those areas.\n\nThe numerical result is not assessing the different design decisions of the approach (why use a Kuyper loss?) in this empirical paper.\n\n", "title": "Brittle application of deep learning to statistical survival analysis", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "S1QsSa1-M": {"type": "review", "replyto": "SJme6-ZR-", "review": "Authors provide an interesting loss function approach for clustering using a deep neural network. They optimize Kuiper-based nonparametric loss and apply the approach on a large social network data-set.  However, the details of the deep learning approach are not well described. Some specific comments are given below.\n\n1.Further details on use of 10-fold cross validation need to be discussed including over-fitting aspect.\n2. Details on deep learning, number of hidden layers, number of hidden units, activation functions, weight adjustment details on each learning methods should be included.\n\n3. Conclusion section is very brief and can be expanded by including a discussion on results comparison and  over fitting aspects in cross validation. Use of Kuiper-based nonparametric loss should also be justified as there are other loss functions can be used under these settings.\n", "title": "A Deep Learning Approach for Survival Clustering without End-of-life Signals", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "BJqJHI67z": {"type": "rebuttal", "replyto": "ry3ETTtxG", "comment": "We are glad you enjoyed the paper. We have added the following paragraph describing the neural network architecture and the deep learning methods we use. We have also reported results for the different design choices in Appendix.\n\n\u201cWe experimented with different neural network architectures as shown in Table 2. In Table 1, we show the results for a simple neural network configuration with one fully-connected hidden layer with 128 hidden units and tanh activation function. We use a batch size of 8192 and a learning rate of 10^{-4}. We also use batch normalization to facilitate convergence, and regularize the weights of the neural network using an L2 penalty of 0.01. Appendix 8.2 shows a more detailed evaluation of different architecture choices.\u201d\n", "title": "Response to AnonReviewer1"}, "BJ4iN8p7M": {"type": "rebuttal", "replyto": "HyM5JWhgG", "comment": "Thanks for your comments. \n\n1.\tWe had described the underlying statistical setup in Appendix, essentially describing the activity times of a cluster of subjects using a Random Marked Point Process (RMPP). Following your feedback, we have moved it to a section in the paper called \u2018Formal Framework\u2019.\n\n2.\t(Frailty analysis) In our original draft, we followed prior work [Witten and Tibshirani, 2010; Gaynor and Bair, 2013] and refrained from comparing our approach with frailty models to avoid confusion w.r.t. the task at hand. But we now do see the benefit of clarifying the tasks, and thank the reviewer for asking us to do so. We added the following paragraph clarifying this difference. \n\n\u201cExtensive research has been done on what is known as frailty analysis, for predicting survival outcomes in the presence of clustered observations. Although frailty models provide more flexibility in the presence of clustered observations, they do not provide a mechanism for obtaining the clusters themselves, which is our primary goal. In addition, our approach does not assume proportional hazards unlike most frailty models.\u201d \n\n3.\tCensoring and \u2018end-of-life\u2019 are simply the two possibilities for each user. In the case where we have end-of-life signals, a subject could be \u201cdead\u201d or \u201ccensored\u201d based on the signal. Similarly, when we do not have an end-of-life signal, there is a probability of the subject being \u201cdead\u201d or \u201ccensored\u201d (in our case, we calculate this probability using S_u, the time till censoring).\n\n4.\tWe have reported the results for different choices for the loss function - Kuiper loss vs Kolmogorov-Smirnov loss. Although, the difference in performance between the two loss functions is not significant in the Friendster dataset, Kuiper loss is theoretically better due to its increased statistical power in distinguishing distribution tails. \n \n5.\tWe have also reported results for different neural network design choices (batch sizes, learning rates, number of hidden layers, and number of hidden units) in Appendix.\n", "title": "Response to AnonReviewer2"}, "S1hGEIa7f": {"type": "rebuttal", "replyto": "S1QsSa1-M", "comment": "Thanks for your comments.\n\n1.\tWe do not seem to be overfitting to the training data because: a) our loss function is not susceptible to outliers in the dataset (as it considers set distributions instead of the more standard approach of using a loss function defined over each individual data point), b) we monitor the validation loss while training the neural network, and c) we are able to generalize well in the test data.\n \n2.\tWe added the following paragraph describing the deep learning techniques we used. Moreover, we now report results for different neural network design choices (batch sizes, learning rates, number of hidden layers, and number of hidden units). \n\n\u201cWe experimented with different neural network architectures as shown in Table 2. In Table 1, we show the results for a simple neural network configuration with one fully-connected hidden layer with 128 hidden units and tanh activation function. We use a batch size of 8192 and a learning rate of 10^{-4}. We also use batch normalization to facilitate convergence, and regularize the weights of the neural network using an L2 penalty of 0.01. Appendix 8.2 shows a more detailed evaluation of different architecture choices.\u201d\n\n3.\tWe now also report results for Kolmogorov-Smirnov loss. Although the difference in performance between the two loss functions is not significant in the Friendster dataset, Kuiper loss has higher statistical power in distinguishing distribution tails [Tygert 2010]. \n", "title": "Response to AnonReviewer3"}}}